
@phdthesis{multipleReps,
	title = {Conceptual learning with multiple graphical representations: {Intelligent} tutoring systems support for sense-making and fluency-building processes},
	language = {en},
	school = {Carnegie Mellon University},
	author = {Rau, Martina A},
	year = {2013},
}

@misc{oli,
	title = {General chemistry 1},
	url = {https://oli.cmu.edu/courses/general-chemistry-1/},
	journal = {General chemistry 1 -- Open Learning Initiative},
	author = {{Open Learning Initiative}},
	year = {2024},
}

@article{ledo_evaluation_2018,
	title = {Evaluation strategies for {HCI} {Toolkit} research},
	volume = {2018-April},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173610},
	doi = {10.1145/3173574.3173610},
	abstract = {Toolkit research plays an important role in the field of HCI, as it can heavily influence both the design and implementa-tion of interactive systems. For publication, the HCI commu-nity typically expects toolkit research to include an evalua-tion component. The problem is that toolkit evaluation is challenging, as it is often unclear what 'evaluating' a toolkit means and what methods are appropriate. To address this problem, we analyzed 68 published toolkit papers. From our analysis, we provide an overview of, reflection on, and dis-cussion of evaluation methods for toolkit contributions. We identify and discuss the value of four toolkit evaluation strat-egies, including the associated techniques that each employs. We offer a categorization of evaluation strategies for toolkit researchers, along with a discussion of the value, potential limitations, and trade-offs associated with each strategy.},
	urldate = {2023-04-01},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Ledo, David and Houben, Steven and Vermeulen, Jo and Marquardt, Nicolai and Oehlberg, Lora and Greenberg, Saul},
	month = apr,
	year = {2018},
	note = {Publisher: Association for Computing Machinery
ISBN: 9781450356206},
	keywords = {Design, Evaluation, Prototyping, Toolkits, User interfaces},
}

@article{penrose,
	title = {Penrose: {From} {Mathematical} {Notation} to {Beautiful} {Diagrams}},
	volume = {39},
	issn = {0730-0301},
	shorttitle = {Penrose},
	url = {https://doi.org/10.1145/3386569.3392375},
	doi = {10.1145/3386569.3392375},
	abstract = {We introduce a system called Penrose for creating mathematical diagrams. Its basic functionality is to translate abstract statements written in familiar math-like notation into one or more possible visual representations. Rather than rely on a fixed library of visualization tools, the visual representation is user-defined in a constraint-based specification language; diagrams are then generated automatically via constrained numerical optimization. The system is user-extensible to many domains of mathematics, and is fast enough for iterative design exploration. In contrast to tools that specify diagrams via direct manipulation or low-level graphics programming, Penrose enables rapid creation and exploration of diagrams that faithfully preserve the underlying mathematical meaning. We demonstrate the effectiveness and generality of the system by showing how it can be used to illustrate a diverse set of concepts from mathematics and computer graphics.},
	number = {4},
	urldate = {2021-04-23},
	journal = {ACM Transactions on Graphics},
	author = {Ye, Katherine and Ni, Wode and Krieger, Max and Ma'ayan, Dor and Wise, Jenna and Aldrich, Jonathan and Sunshine, Joshua and Crane, Keenan},
	month = jul,
	year = {2020},
	keywords = {mathematical diagrams},
	pages = {144:144:1--144:144:16},
}

@book{simon_sciences_1969,
	address = {Cambridge, MA, US},
	series = {The sciences of the artificial},
	title = {The sciences of the artificial},
	abstract = {Discusses the thesis that "certain phenomena are "artificial' in a very specific sense: They are as they are only because of a system's being molded, by goals or purposes, to the environment in which it lives." (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {The MIT Press},
	author = {Simon, Herbert A.},
	year = {1969},
	note = {Pages: xii, 123},
	keywords = {Sciences, Theories},
}

@article{coulon_importance_2024,
	title = {On the importance of illustration for mathematical research},
	volume = {71},
	issn = {0002-9920, 1088-9477},
	url = {http://arxiv.org/abs/2307.04636},
	doi = {10.1090/noti2839},
	abstract = {Mathematical understanding is built in many ways. Among these, illustration has been a companion and tool for research for as long as research has taken place. We use the term illustration to encompass any way one might bring a mathematical idea into physical form or experience, including hand-made diagrams or models, computer visualization, 3D printing, and virtual reality, among many others. The very process of illustration itself challenges our mathematical understanding and forces us to answer questions we may not have posed otherwise. It can even make mathematics an experimental science, in which immersive exploration of data and representations drive the cycle of problem, conjecture, and proof. Today, modern technology for the first time places the production of highly complicated models within the reach of many individual mathematicians. Here, we sketch the rich history of illustration, highlight important recent examples of its contribution to research, and examine how it can be viewed as a discipline in its own right.},
	number = {01},
	urldate = {2024-08-19},
	journal = {Notices of the American Mathematical Society},
	author = {Coulon, Rémi and Dorfsman-Hopkins, Gabriel and Harriss, Edmund and Skrodzki, Martin and Stange, Katherine E. and Whitney, Glen},
	month = jan,
	year = {2024},
	note = {arXiv:2307.04636 [math]},
	keywords = {01-02, 01A65, 01A67, 00-02, Mathematics - History and Overview},
	pages = {1},
}

@inproceedings{ni_edgeworth_2024,
	address = {New York, NY, USA},
	series = {L@{S} '24},
	title = {Edgeworth: {Efficient} and {Scalable} {Authoring} of {Visual} {Thinking} {Activities}},
	isbn = {9798400706332},
	shorttitle = {Edgeworth},
	url = {https://dl.acm.org/doi/10.1145/3657604.3662034},
	doi = {10.1145/3657604.3662034},
	abstract = {Visual thinking with diagrams is a crucial skill for learning and problem-solving in STEM subjects. To improve in this area, students need a variety of visual problems for deliberate practice. However, in our interviews, educators shared that they struggle to create these practice exercises because of limitations of existing tools. We introduce Edgeworth, a tool designed to help educators easily create visual problems. Edgeworth works in two main ways: firstly, it takes a single diagram from the user and systematically alters it to produce many variations, which the educator can then choose from to create multiple problems. Secondly, it automates the layout of diagrams, ensuring consistent high quality without the need for manual adjustments. To assess Edgeworth, we carried out case studies, a technical evaluation, and expert walkthrough demonstrations. We show that Edgeworth can create problems in three domains: geometry, chemistry, and discrete math. These problems were authored in just 15 lines of Edgeworth code on average. Edgeworth generated usable answer options within the first 10 diagram variations in 87\% of authored problems. Finally, educators gave positive feedback on Edgeworth's utility and the real-world applicability of its outputs.},
	urldate = {2024-08-14},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Ni, Wode and Estep, Sam and Harriman, Hwei-Shin and Koedinger, Kenneth R. and Sunshine, Joshua},
	month = jul,
	year = {2024},
	pages = {98--109},
}

@article{liu_tool_nodate,
	title = {Tool {Support} for {Knowledge} {Foraging}, {Structuring}, and {Transfer} {During} {Online} {Sensemaking}},
	language = {en},
	author = {Liu, Michael Xieyang},
}

@inproceedings{penrosellm,
	address = {New York, NY, USA},
	series = {{SPLASH}'23},
	title = {Generating domain-specific programs for diagram authoring with large language models},
	isbn = {9798400703843},
	url = {https://doi.org/10.1145/3618305.3623612},
	doi = {10.1145/3618305.3623612},
	booktitle = {Companion proceedings of the 2023 {ACM} {SIGPLAN} international conference on systems, programming, languages, and applications: {Software} for humanity},
	publisher = {Association for Computing Machinery},
	author = {Jain, Rijul and Ni, Wode and Sunshine, Joshua},
	year = {2023},
	note = {Number of pages: 2
Place: Cascais, Portugal},
	pages = {70--71},
}

@article{kurdi2020systematic,
	title = {A systematic review of automatic question generation for educational purposes},
	volume = {30},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Kurdi, Ghader and Leo, Jared and Parsia, Bijan and Sattler, Uli and Al-Emari, Salam},
	year = {2020},
	note = {Publisher: Springer},
	pages = {121--204},
}

@inproceedings{rho2022preparing,
	title = {Preparing future learning with novel visuals by supporting representational competencies},
	booktitle = {Artificial intelligence in education: 23rd international conference, {AIED} 2022, durham, {UK}, july 27–31, 2022, proceedings, part {I}},
	publisher = {Springer},
	author = {Rho, Jihyun and Rau, Martina A and Van Veen, Barry D},
	year = {2022},
	pages = {66--77},
}

@inproceedings{ghosh2022adaptive,
	title = {Adaptive scaffolding in block-based programming via synthesizing new tasks as pop quizzes},
	booktitle = {Artificial intelligence in education: 23rd international conference, {AIED} 2022, durham, {UK}, july 27–31, 2022, proceedings, part {I}},
	publisher = {Springer},
	author = {Ghosh, Ahana and Tschiatschek, Sebastian and Devlin, Sam and Singla, Adish},
	year = {2022},
	pages = {28--40},
}

@inproceedings{QG-Net,
	address = {New York, NY, USA},
	series = {L@{S} '18},
	title = {{QG}-net: a data-driven question generation model for educational content},
	isbn = {978-1-4503-5886-6},
	url = {https://doi.org/10.1145/3231644.3231654},
	doi = {10.1145/3231644.3231654},
	abstract = {The ever growing amount of educational content renders it increasingly difficult to manually generate sufficient practice or quiz questions to accompany it. This paper introduces QG-Net, a recurrent neural network-based model specifically designed for automatically generating quiz questions from educational content such as textbooks. QG-Net, when trained on a publicly available, general-purpose question/answer dataset and without further fine-tuning, is capable of generating high quality questions from textbooks, where the content is significantly different from the training data. Indeed, QG-Net outperforms state-of-the-art neural network-based and rules-based systems for question generation, both when evaluated using standard benchmark datasets and when using human evaluators. QG-Net also scales favorably to applications with large amounts of educational content, since its performance improves with the amount of training data.},
	booktitle = {Proceedings of the fifth annual {ACM} conference on learning at scale},
	publisher = {Association for Computing Machinery},
	author = {Wang, Zichao and Lan, Andrew S. and Nie, Weili and Waters, Andrew E. and Grimaldi, Phillip J. and Baraniuk, Richard G.},
	year = {2018},
	note = {Number of pages: 10
Place: London, United Kingdom
tex.articleno: 7},
}

@article{rau2017representational,
	title = {A framework for educational technologies that support representational competencies},
	volume = {10},
	doi = {10.1109/TLT.2016.2623303},
	number = {3},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Rau, Martina Angela},
	year = {2017},
	pages = {290--305},
}

@inproceedings{van2022evaluating,
	title = {Evaluating {AI}-generated questions: a mixed-methods analysis using question data and student perceptions},
	booktitle = {Artificial intelligence in education: 23rd international conference, {AIED} 2022, durham, {UK}, july 27–31, 2022, proceedings, part {I}},
	publisher = {Springer},
	author = {Van Campenhout, Rachel and Hubertz, Martha and Johnson, Benny G},
	year = {2022},
	pages = {344--353},
}

@inproceedings{wang2022towards,
	title = {Towards human-like educational question generation with large language models},
	booktitle = {Artificial intelligence in education: 23rd international conference, {AIED} 2022, durham, {UK}, july 27–31, 2022, proceedings, part {I}},
	publisher = {Springer},
	author = {Wang, Zichao and Valdez, Jakob and Basu Mallick, Debshila and Baraniuk, Richard G},
	year = {2022},
	pages = {153--166},
}

@inproceedings{michaelis2022robot,
	address = {New York, NY, USA},
	series = {Chi '22},
	title = {Embodied geometric reasoning with a robot: {The} impact of robot gestures on student reasoning about geometrical conjectures},
	isbn = {978-1-4503-9157-3},
	url = {https://doi.org/10.1145/3491102.3517556},
	doi = {10.1145/3491102.3517556},
	abstract = {In this paper, we explore how the physically embodied nature of robots can influence learning through non-verbal communication, such as gesturing. We take an embodied cognition perspective to examine student interactions with a NAO robot that uses gestures while reasoning about geometry conjectures. College aged students (N = 30) were randomly assigned to either a dynamic condition, where the robot uses dynamic gestures that represent and manipulate geometric shapes in the conjectures, or control condition, where the robot uses beat gestures that match the rhythm of speech. Students in the dynamic condition: (1) use more gestures when they reason about geometry conjectures, (2) look more at the robot as it speaks, (3) feel the robot is a better study partner and uses effective gestures, but (4) were not more successful in correctly reasoning about geometry conjectures. We discuss implications for socially supported and embodied learning with a physically present robot.},
	booktitle = {Proceedings of the 2022 {CHI} conference on human factors in computing systems},
	publisher = {Association for Computing Machinery},
	author = {Michaelis, Joseph E and Di Canio, Daniela},
	year = {2022},
	note = {Number of pages: 14
Place: New Orleans, LA, USA
tex.articleno: 224},
	keywords = {embodied cognition, gesture, human-robot interaction, mathematics learning},
}

@inproceedings{CheckIt,
	title = {{CheckIt} - {A} low cost mobile {OMR} system},
	doi = {10.1109/TENCON.2015.7372983},
	booktitle = {{TENCON} 2015 - 2015 {IEEE} region 10 conference},
	author = {Patel, Rahul and Sanghavi, Shashwat and Gupta, Dhruv and Raval, Mehul S},
	year = {2015},
	pages = {1--5},
}

@article{cummins1991,
	title = {Children's interpretations of arithmetic word problems},
	volume = {8},
	url = {https://doi.org/10.1207/s1532690xci0803_2},
	doi = {10.1207/s1532690xci0803\_2},
	number = {3},
	journal = {Cognition and Instruction},
	author = {Cummins, Denise Dellarosa},
	year = {1991},
	note = {Publisher: Routledge
tex.eprint: https://doi.org/10.1207/s1532690xci0803{\textbackslash}\_2},
	pages = {261--289},
}

@article{bah2011inkscape,
	title = {Inkscape},
	journal = {Guide to a Vector Drawing Program, 4th ed. Prenctice Hall, Upper Saddle River},
	author = {Bah, Tavmjong},
	year = {2011},
}

@article{cohen1960coefficient,
	title = {A coefficient of agreement for nominal scales},
	volume = {20},
	number = {1},
	journal = {Educational and psychological measurement},
	author = {Cohen, Jacob},
	year = {1960},
	note = {Publisher: Sage Publications Sage CA: Thousand Oaks, CA},
	pages = {37--46},
}

@book{heiberg2007euclid,
	title = {Euclid's elements},
	publisher = {Lulu. com},
	author = {Heiberg, Johan Ludvig},
	year = {2007},
}

@article{patra2019hybrid,
	title = {A hybrid approach for automatic generation of named entity distractors for multiple choice questions},
	volume = {24},
	journal = {Education and Information Technologies},
	author = {Patra, Rakesh and Saha, Sujan Kumar},
	year = {2019},
	note = {Publisher: Springer},
	pages = {973--993},
}

@article{HOLLING200971,
	title = {Automatic item generation of probability word problems},
	volume = {35},
	issn = {0191-491X},
	url = {https://www.sciencedirect.com/science/article/pii/S0191491X09000236},
	doi = {https://doi.org/10.1016/j.stueduc.2009.10.004},
	abstract = {Mathematical word problems represent a common item format for assessing student competencies. Automatic item generation (AIG) is an effective way of constructing many items with predictable difficulties, based on a set of predefined task parameters. The current study presents a framework for the automatic generation of probability word problems based on templates that allow for the generation of word problems involving different topics from probability theory. It was tested in a pilot study with N=146 German university students. The items show a good fit to the Rasch model. Item difficulties can be explained by the Linear Logistic Test Model (LLTM) and by the random-effects LLTM. The practical implications of these findings for future test development in the assessment of probability competencies are also discussed.},
	number = {2},
	journal = {Studies in Educational Evaluation},
	author = {Holling, Heinz and Bertling, Jonas P. and Zeuch, Nina},
	year = {2009},
	keywords = {Evaluation methods, LLTM, Probability word problems, Rule-based item design, Student evaluation},
	pages = {71--76},
}

@book{gierl2012automatic,
	title = {Automatic item generation: {Theory} and practice},
	publisher = {Routledge},
	author = {Gierl, Mark J and Haladyna, Thomas M},
	year = {2012},
}

@misc{geogebra5,
	title = {{GeoGebra} 5.0.507.0},
	author = {Hohenwarter, M. and Borcherds, M. and Ancsin, G. and Bencze, B. and Blossier, M. and Éliás, J. and Frank, K. and Gál, L. and Hofstätter, A. and Jordan, F. and Konečný, Z. and Kovács, Z. and Lettner, E. and Lizelfelner, S. and Parisse, B. and Solyom-Gecse, C. and Stadlbauer, C. and Tomaschko, M.},
	month = oct,
	year = {2018},
}

@phdthesis{ni_developing_2022,
	title = {Developing conceptual understanding through interactive diagramming},
	language = {English},
	school = {Carnegie Mellon University},
	author = {Ni, Wode},
	month = apr,
	year = {2022},
}

@phdthesis{nam_user-centered_2024,
	type = {thesis},
	title = {User-{Centered} {Intelligent} {Information} {Support} for {Programmers}},
	url = {https://kilthub.cmu.edu/articles/thesis/User-Centered_Intelligent_Information_Support_for_Programmers/25901368/1},
	abstract = {Software engineering is an information-intensive discipline. While building and maintaining software systems, programmers encounter a broad spectrum of questions ranging from implementation specifics to architectural concerns. However, satisfying their information needs is not easy, because the relevant information is often scattered across varying mediums in different formats. It becomes even more challenging when a programmer needs to work with unfamiliar code or libraries, without the necessary knowledge and experience to search for information effectively. In this thesis, I aim to address the challenges programmers face in seeking information by designing, building, and evaluating intelligent information support tools using user-centered approaches. To provide user-centered intelligent support, this thesis investigates both the users (i.e., programmers), and the intelligent techniques. To motivate the need for user-centered information support, I first present an exploratory, mixed-methods empirical study on documentation page-view logs, revealing discernible documentation page visit patterns. The study shows that programmers use documentation differently, and their contextual factors correlate with their documentation usage, highlighting the need for information support tailored to diverse user contexts instead of “one size fits all” solutions. I then introduce four prototype intelligent information support tools designed to assist developers working with unfamiliar code, concepts, application domains, and APIs. Evaluations of these tools demonstrate the effectiveness of intelligent solutions, compared with traditional baseline approaches. Furthermore, user studies conducted with these prototypes illustrate the benefits of designing information support tools that account for users’ current tasks and the broader context in which these tasks are situated. Motivated by these findings, this thesis finally explores the possibility of personalizing information support for programmers, by leveraging the programmers’ contextual factors (e.g., familiarity with application domains) to enhance information support. By investigating various intelligent techniques for different informationseeking scenarios, this thesis illustrates how a thorough understanding of the users not only yields valuable insights for designing more useful and usable tools but also improves the performance of intelligent techniques used in these tasks. The methodologies used for building user-centered information support tools, along with the insights gained from user studies in this thesis, will further our understanding of how developers with varying goals and backgrounds seek and use information. Taken together, the thesis will shed light on the design of future programming tools, especially those that will be built for a new programming paradigm that relies heavily on AI-based support.},
	language = {en},
	urldate = {2024-08-12},
	school = {Carnegie Mellon University},
	author = {Nam, Daye},
	month = jun,
	year = {2024},
	doi = {10.1184/R1/25901368.v1},
}

@phdthesis{lakhani_polarized_2024,
	title = {Polarized {Subtyping}},
	abstract = {Abstract
            Polarization of types in call-by-push-value naturally leads to the separation of inductively defined observable values (classified by positive types), and coinductively defined computations (classified by negative types), with adjoint modalities mediating between them. Taking this separation as a starting point, we develop a semantic characterization of typing with step indexing to capture observation depth of recursive computations. This semantics justifies a rich set of subtyping rules for an equirecursive variant of call-by-push-value, including variant and lazy records. We further present a bidirectional syntactic typing system for both values and computations that elegantly and pragmatically circumvents difficulties of type inference in the presence of width and depth subtyping for variant and lazy records. We demonstrate the flexibility of our system by systematically deriving related systems of subtyping for (a) isorecursive types, (b) call-by-name, and (c) call-by-value, all using a structural rather than a nominal interpretation of types.},
	language = {en},
	urldate = {2024-07-30},
	school = {Carnegie Mellon University},
	author = {Lakhani, Zeeshan},
	year = {2024},
}

@article{treisman_feature-integration_1980,
	title = {A feature-integration theory of attention},
	volume = {12},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/0010028580900055},
	doi = {10.1016/0010-0285(80)90005-5},
	abstract = {A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms including visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not.},
	number = {1},
	urldate = {2024-07-26},
	journal = {Cognitive Psychology},
	author = {Treisman, Anne M. and Gelade, Garry},
	month = jan,
	year = {1980},
	pages = {97--136},
}

@article{thorpe_speed_1996,
	title = {Speed of processing in the human visual system},
	volume = {381},
	copyright = {1996 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/381520a0},
	doi = {10.1038/381520a0},
	abstract = {How long does it take for the human visual system to process a complex natural image? Subjectively, recognition of familiar objects and scenes appears to be virtually instantaneous, but measuring this processing time experimentally has proved difficult. Behavioural measures such as reaction times can be used1, but these include not only visual processing but also the time required for response execution. However, event-related potentials (ERPs) can sometimes reveal signs of neural processing well before the motor output2. Here we use a go/no-go categorization task in which subjects have to decide whether a previously unseen photograph, flashed on for just 20 ms, contains an animal. ERP analysis revealed a frontal negativity specific to no-go trials that develops roughly 150 ms after stimulus onset. We conclude that the visual processing needed to perform this highly demanding task can be achieved in under 150 ms.},
	language = {en},
	number = {6582},
	urldate = {2024-07-26},
	journal = {Nature},
	author = {Thorpe, Simon and Fize, Denis and Marlot, Catherine},
	month = jun,
	year = {1996},
	note = {Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {520--522},
}

@inproceedings{meyer_intelligent_2009,
	title = {Intelligent diagramming in the electronic online classroom},
	url = {https://ieeexplore.ieee.org/document/5090975},
	doi = {10.1109/HSI.2009.5090975},
	abstract = {Digital white-boards promise to revolutionize the delivery of educational material. Like a traditional whiteboard, they support spontaneous and interactive teaching by allowing free-form editing and scribbling. However, digital white-boards also allow seamless integration of multi-media content and fit naturally into a web-based teaching environment. The e-chalk system has been built to support on-line teaching with digital white-boards in a university environment. An important feature of e-chalk is that hand drawn input is automatically interpreted. This allows sketching and scribbling to be used as an interface to powerful back-end applications. e-chalk also allows sketches and scribbles to be transcribed into semantic formats suited to flexible delivery. However, at present developing automatic sketch interpretation engines is extremely time consuming. We describe how we have extended the e-chalk system with a generic diagram interpretation component that makes development of new applications considerably faster and easier.},
	urldate = {2024-07-17},
	booktitle = {2009 2nd {Conference} on {Human} {System} {Interactions}},
	author = {Meyer, Bernd and Marriott, Kim and Bickerstaffe, Adrian and Knipping, Lars},
	month = may,
	year = {2009},
	note = {ISSN: 2158-2254},
	keywords = {Animation, Computer architecture, Education, Educational institutions, Engines, Information resources, Intelligent systems, Mathematics, Multimedia systems, Publishing},
	pages = {177--183},
}

@article{mccormack_authoring_2018,
	title = {Authoring diagrams that adapt to their viewing context},
	volume = {46},
	issn = {1045-926X},
	url = {https://www.sciencedirect.com/science/article/pii/S1045926X16302026},
	doi = {10.1016/j.jvlc.2016.11.001},
	abstract = {The Web and digital media require documents whose appearance and content adapt to the viewing context and to user interaction. While most previous research has focussed on adaptation for textual and multimedia content, this is also true for diagrammatic content. We (a) identify the reasons for adaptation and the different kinds of adaptation that make sense for diagrams; (b) present an aspect-oriented model for diagram adaptation that separates adaptation into different orthogonal components; (c) describe a diagram authoring tool based on this model; and (d) present the results of a user evaluation of the tool. Our model uses layout “configurations” to model significantly different layout alternatives and geometric constraints to perform minor layout adjustment. The author can also specify alternate representations for an object, alternate styles and alternate textual content. The resulting space of different versions of the diagram is the cross product of these different alternatives. At display time the version is selected from this cross product and constructed automatically, taking into account the author specified preference order on the alternatives, current viewing environment, and user interaction.},
	urldate = {2024-07-17},
	journal = {Journal of Visual Languages \& Computing},
	author = {McCormack, Cameron and Marriott, Kim and Meyer, Bernd},
	month = jun,
	year = {2018},
	keywords = {Adaptive layout, Authoring, Constraint-based graphics, Diagrams},
	pages = {20--34},
}

@article{bredeweg_learning_2023,
	title = {Learning with {Interactive} {Knowledge} {Representations}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/13/9/5256},
	doi = {10.3390/app13095256},
	abstract = {Computers are promising tools for providing educational experiences that meet individual learning needs. However, delivering this promise in practice is challenging, particularly when automated feedback is essential and the learning extends beyond using traditional methods such as writing and solving mathematics problems. We hypothesize that interactive knowledge representations can be deployed to address this challenge. Knowledge representations differ markedly from concept maps. Where the latter uses nodes (concepts) and arcs (links between concepts), a knowledge representation is based on an ontology that facilitates automated reasoning. By adjusting this reasoning towards interacting with learners for the benefit of learning, a new class of educational instruments emerges. In this contribution, we present three projects that use an interactive knowledge representation as their foundation. DynaLearn supports learners in acquiring system thinking skills. Minds-On helps learners to deepen their understanding of phenomena while performing experiments. Interactive Concept Cartoons engage learners in a science-based discussion about controversial topics. Each of these approaches has been developed iteratively in collaboration with teachers and tested in real classrooms, resulting in a suite of lessons available online. Evaluation studies involving pre-/post-tests and action-log data show that learners are easily capable of working with these educational instruments and that the instruments thus enable a semi-automated approach to constructive learning.},
	language = {en},
	number = {9},
	urldate = {2024-07-08},
	journal = {Applied Sciences},
	author = {Bredeweg, Bert and Kragten, Marco and Holt, Joanna and Kruit, Patricia and van Eijck, Tom and Pijls, Monique and Bouwer, Anders and Sprinkhuizen, Malou and Jaspar, Emile and de Boer, Muriel},
	month = jan,
	year = {2023},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {K-12, knowledge representation, learning by modelling, science education},
	pages = {5256},
}

@inproceedings{jiang_graphologue_2023,
	title = {Graphologue: {Exploring} {Large} {Language} {Model} {Responses} with {Interactive} {Diagrams}},
	shorttitle = {Graphologue},
	url = {http://arxiv.org/abs/2305.11473},
	doi = {10.1145/3586183.3606737},
	abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented ability to synthesize text responses to diverse user questions. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts textbased responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to ∗Both authors contributed equally to this research.},
	language = {en},
	urldate = {2024-07-01},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
	month = oct,
	year = {2023},
	note = {arXiv:2305.11473 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	pages = {1--20},
}

@inproceedings{jiang_graphologue_2023-1,
	title = {Graphologue: {Exploring} {Large} {Language} {Model} {Responses} with {Interactive} {Diagrams}},
	shorttitle = {Graphologue},
	url = {http://arxiv.org/abs/2305.11473},
	doi = {10.1145/3586183.3606737},
	abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented ability to synthesize text responses to diverse user questions. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.},
	urldate = {2024-07-01},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
	month = oct,
	year = {2023},
	note = {arXiv:2305.11473 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	pages = {1--20},
}

@inproceedings{jiang_graphologue_2023-2,
	title = {Graphologue: {Exploring} {Large} {Language} {Model} {Responses} with {Interactive} {Diagrams}},
	shorttitle = {Graphologue},
	url = {http://arxiv.org/abs/2305.11473},
	doi = {10.1145/3586183.3606737},
	abstract = {Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented ability to synthesize text responses to diverse user questions. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can interact with the diagrams to flexibly adjust the graphical presentation and to submit context-specific prompts to obtain more information. Utilizing diagrams, Graphologue enables graphical, non-linear dialogues between humans and LLMs, facilitating information exploration, organization, and comprehension.},
	urldate = {2024-07-01},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Jiang, Peiling and Rayan, Jude and Dow, Steven P. and Xia, Haijun},
	month = oct,
	year = {2023},
	note = {arXiv:2305.11473 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	pages = {1--20},
}

@article{gaillard_automatic_2022,
	title = {Automatic {Differentiable} {Procedural} {Modeling}},
	volume = {41},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14475},
	doi = {10.1111/cgf.14475},
	abstract = {Procedural modeling allows for an automatic generation of large amounts of similar assets, but there is limited control over the generated output. We address this problem by introducing Automatic Differentiable Procedural Modeling (ADPM). The forward procedural model generates a final editable model. The user modifies the output interactively, and the modifications are transferred back to the procedural model as its parameters by solving an inverse procedural modeling problem. We present an auto-differentiable representation of the procedural model that significantly accelerates optimization. In ADPM the procedural model is always available, all changes are non-destructive, and the user can interactively model the 3D object while keeping the procedural representation. ADPM provides the user with precise control over the resulting model comparable to non-procedural interactive modeling. ADPM is node-based, and it generates hierarchical 3D scene geometry converted to a differentiable computational graph. Our formulation focuses on the differentiability of high-level primitives and bounding volumes of components of the procedural model rather than the detailed mesh geometry. Although this high-level formulation limits the expressiveness of user edits, it allows for efficient derivative computation and enables interactivity. We designed a new optimizer to solve for inverse procedural modeling. It can detect that an edit is under-determined and has degrees of freedom. Leveraging cheap derivative evaluation, it can explore the region of optimality of edits and suggest various configurations, all of which achieve the requested edit differently. We show our system's efficiency on several examples, and we validate it by a user study.},
	language = {en},
	number = {2},
	urldate = {2024-06-24},
	journal = {Computer Graphics Forum},
	author = {Gaillard, Mathieu and Krs, Vojtěch and Gori, Giorgio and Měch, Radomír and Benes, Bedrich},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14475},
	keywords = {CCS Concepts, Interactive simulation, • Computing methodologies → Shape modeling},
	pages = {289--307},
}

@article{wickham_layered_2010,
	title = {A {Layered} {Grammar} of {Graphics}},
	volume = {19},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/jcgs.2009.07098},
	doi = {10.1198/jcgs.2009.07098},
	abstract = {A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g., the “scatterplot”) and gain insight into the deep structure that underlies statistical graphics. This article builds on Wilkinson, Anand, and Grossman (2005), describing extensions and refinements developed while building an open source implementation of the grammar of graphics for R, ggplot2. The topics in this article include an introduction to the grammar by working through the process of creating a plot, and discussing the components that we need. The grammar is then presented formally and compared to Wilkinson’s grammar, highlighting the hierarchy of defaults, and the implications of embedding a graphical grammar into a programming language. The power of the grammar is illustrated with a selection of examples that explore different components and their interactions, in more detail. The article concludes by discussing some perceptual issues, and thinking about how we can build on the grammar to learn how to create graphical “poems.” Supplemental materials are available online.},
	number = {1},
	urldate = {2024-06-10},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Wickham, Hadley},
	month = jan,
	year = {2010},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/jcgs.2009.07098},
	keywords = {Grammar of graphics, Statistical graphics},
	pages = {3--28},
}

@book{chiplunkar_diagrammatic_2023,
	title = {Diagrammatic notations for interactive theorem proving},
	abstract = {Diagrams are ubiquitous in the development and presentation of proofs, yet surprisingly uncommon in computerized mathematics. Instead, authors and developers rely almost exclusively on line-oriented notations (textual abbreviations and symbols). How might we enrich interactive theorem provers with on-the-fly visual aids that are just as usable? We answer this question by identifying a key challenge: designing declarative languages for composable diagram templates, that provide good-looking implementations of common patterns, and allow for rapid prototyping of diagrams that remain stable across transformations and proof steps},
	publisher = {EPFL},
	editor = {Chiplunkar, Shardul and Pit-Claudel, Clément},
	year = {2023},
	doi = {10.5075/epfl-SYSTEMF-305144},
	note = {Meeting Name: 4th International Workshop on Human Aspects of Types and Reasoning Assistants},
	keywords = {Human-centered computing → Visualization systems and tools, Software and its engineering → Software notations and tools, diagramming languages, diagrams, interactive theorem proving},
}

@misc{singh_assessing_2023,
	title = {Assessing {GPT4}-{V} on {Structured} {Reasoning} {Tasks}},
	url = {http://arxiv.org/abs/2312.11524},
	doi = {10.48550/arXiv.2312.11524},
	abstract = {Multi-modality promises to unlock further uses for large language models. Recently, the state-of-the-art language model GPT-4 was enhanced with vision capabilities. We carry out a prompting evaluation of GPT-4V and five other baselines on structured reasoning tasks, such as mathematical reasoning, visual data analysis, and code generation. We show that visual Chain-of-Thought, an extension of Chain-of-Thought to multi-modal LLMs, yields significant improvements over the vanilla model. We also present a categorized analysis of scenarios where these models perform well and where they struggle, highlighting challenges associated with coherent multimodal reasoning.},
	urldate = {2024-05-10},
	publisher = {arXiv},
	author = {Singh, Mukul and Cambronero, José and Gulwani, Sumit and Le, Vu and Verbruggen, Gust},
	month = dec,
	year = {2023},
	note = {arXiv:2312.11524 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{zhu-tian_sketch_2024,
	title = {Sketch {Then} {Generate}: {Providing} {Incremental} {User} {Feedback} and {Guiding} {LLM} {Code} {Generation} through {Language}-{Oriented} {Code} {Sketches}},
	shorttitle = {Sketch {Then} {Generate}},
	url = {http://arxiv.org/abs/2405.03998},
	doi = {10.48550/arXiv.2405.03998},
	abstract = {Crafting effective prompts for code generation or editing with Large Language Models (LLMs) is not an easy task. Particularly, the absence of immediate, stable feedback during prompt crafting hinders effective interaction, as users are left to mentally imagine possible outcomes until the code is generated. In response, we introduce Language-Oriented Code Sketching, an interactive approach that provides instant, incremental feedback in the form of code sketches (i.e., incomplete code outlines) during prompt crafting. This approach converts a prompt into a code sketch by leveraging the inherent linguistic structures within the prompt and applying classic natural language processing techniques. The sketch then serves as an intermediate placeholder that not only previews the intended code structure but also guides the LLM towards the desired code, thereby enhancing human-LLM interaction. We conclude by discussing the approach's applicability and future plans.},
	urldate = {2024-05-09},
	publisher = {arXiv},
	author = {Zhu-Tian, Chen and Xiong, Zeyu and Yao, Xiaoshuo and Glassman, Elena},
	month = may,
	year = {2024},
	note = {arXiv:2405.03998 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
}

@misc{das_which_2024,
	title = {Which {Modality} should {I} use -- {Text}, {Motif}, or {Image}? : {Understanding} {Graphs} with {Large} {Language} {Models}},
	shorttitle = {Which {Modality} should {I} use -- {Text}, {Motif}, or {Image}?},
	url = {http://arxiv.org/abs/2311.09862},
	doi = {10.48550/arXiv.2311.09862},
	abstract = {Our research integrates graph data with Large Language Models (LLMs), which, despite their advancements in various fields using large text corpora, face limitations in encoding entire graphs due to context size constraints. This paper introduces a new approach to encoding a graph with diverse modalities, such as text, image, and motif, coupled with prompts to approximate a graph's global connectivity, thereby enhancing LLMs' efficiency in processing complex graph structures. The study also presents GraphTMI, a novel benchmark for evaluating LLMs in graph structure analysis, focusing on homophily, motif presence, and graph difficulty. Key findings indicate that the image modality, especially with vision-language models like GPT-4V, is superior to text in balancing token limits and preserving essential information and outperforms prior graph neural net (GNN) encoders. Furthermore, the research assesses how various factors affect the performance of each encoding modality and outlines the existing challenges and potential future developments for LLMs in graph understanding and reasoning tasks. All data will be publicly available upon acceptance.},
	urldate = {2024-04-30},
	publisher = {arXiv},
	author = {Das, Debarati and Gupta, Ishaan and Srivastava, Jaideep and Kang, Dongyeop},
	month = mar,
	year = {2024},
	note = {arXiv:2311.09862 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
}

@misc{fu_isobench_2024,
	title = {{IsoBench}: {Benchmarking} {Multimodal} {Foundation} {Models} on {Isomorphic} {Representations}},
	shorttitle = {{IsoBench}},
	url = {http://arxiv.org/abs/2404.01266},
	doi = {10.48550/arXiv.2404.01266},
	abstract = {Current foundation models exhibit impressive capabilities when prompted either with text only or with both image and text inputs. But do their capabilities change depending on the input modality? In this work, we propose \${\textbackslash}textbf\{IsoBench\}\$, a benchmark dataset containing problems from four major areas: math, science, algorithms, and games. Each example is presented with multiple \${\textbackslash}textbf\{isomorphic representations\}\$ of inputs, such as visual, textual, and mathematical presentations. IsoBench provides fine-grained feedback to diagnose performance gaps caused by the form of the representation. Across various foundation models, we observe that on the same problem, models have a consistent preference towards textual representations. Most prominently, when evaluated on all IsoBench problems, Claude-3 Opus performs 28.7 points worse when provided with images instead of text; similarly, GPT-4 Turbo is 18.7 points worse and Gemini Pro is 14.9 points worse. Finally, we present two prompting techniques, \${\textbackslash}textit\{IsoCombination\}\$ and \${\textbackslash}textit\{IsoScratchPad\}\$, which improve model performance by considering combinations of, and translations between, different input representations.},
	urldate = {2024-04-29},
	publisher = {arXiv},
	author = {Fu, Deqing and Khalighinejad, Ghazal and Liu, Ollie and Dhingra, Bhuwan and Yogatama, Dani and Jia, Robin and Neiswanger, Willie},
	month = apr,
	year = {2024},
	note = {arXiv:2404.01266 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{chen_unigeo_2022,
	title = {{UniGeo}: {Unifying} {Geometry} {Logical} {Reasoning} via {Reformulating} {Mathematical} {Expression}},
	shorttitle = {{UniGeo}},
	url = {http://arxiv.org/abs/2212.02746},
	doi = {10.48550/arXiv.2212.02746},
	abstract = {Geometry problem solving is a well-recognized testbed for evaluating the high-level multi-modal reasoning capability of deep models. In most existing works, two main geometry problems: calculation and proving, are usually treated as two specific tasks, hindering a deep model to unify its reasoning capability on multiple math tasks. However, in essence, these two tasks have similar problem representations and overlapped math knowledge which can improve the understanding and reasoning ability of a deep model on both two tasks. Therefore, we construct a large-scale Unified Geometry problem benchmark, UniGeo, which contains 4,998 calculation problems and 9,543 proving problems. Each proving problem is annotated with a multi-step proof with reasons and mathematical expressions. The proof can be easily reformulated as a proving sequence that shares the same formats with the annotated program sequence for calculation problems. Naturally, we also present a unified multi-task Geometric Transformer framework, Geoformer, to tackle calculation and proving problems simultaneously in the form of sequence generation, which finally shows the reasoning ability can be improved on both two tasks by unifying formulation. Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that aims to predict the mathematical expressions in the problem solution, thus improving the Geoformer model. Experiments on the UniGeo demonstrate that our proposed Geoformer obtains state-of-the-art performance by outperforming task-specific model NGS with over 5.6\% and 3.2\% accuracies on calculation and proving problems, respectively.},
	urldate = {2024-04-26},
	publisher = {arXiv},
	author = {Chen, Jiaqi and Li, Tong and Qin, Jinghui and Lu, Pan and Lin, Liang and Chen, Chongyu and Liang, Xiaodan},
	month = dec,
	year = {2022},
	note = {arXiv:2212.02746 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{lewkowycz_solving_2022,
	title = {Solving {Quantitative} {Reasoning} {Problems} with {Language} {Models}},
	url = {http://arxiv.org/abs/2206.14858},
	doi = {10.48550/arXiv.2206.14858},
	abstract = {Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems at the college level. To help close this gap, we introduce Minerva, a large language model pretrained on general natural language data and further trained on technical content. The model achieves state-of-the-art performance on technical benchmarks without the use of external tools. We also evaluate our model on over two hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a third of them.},
	urldate = {2024-04-25},
	publisher = {arXiv},
	author = {Lewkowycz, Aitor and Andreassen, Anders and Dohan, David and Dyer, Ethan and Michalewski, Henryk and Ramasesh, Vinay and Slone, Ambrose and Anil, Cem and Schlag, Imanol and Gutman-Solo, Theo and Wu, Yuhuai and Neyshabur, Behnam and Gur-Ari, Guy and Misra, Vedant},
	month = jun,
	year = {2022},
	note = {arXiv:2206.14858 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{karpukhin_dense_2020,
	title = {Dense {Passage} {Retrieval} for {Open}-{Domain} {Question} {Answering}},
	url = {http://arxiv.org/abs/2004.04906},
	doi = {10.48550/arXiv.2004.04906},
	abstract = {Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9\%-19\% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.},
	urldate = {2024-04-25},
	publisher = {arXiv},
	author = {Karpukhin, Vladimir and Oğuz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
	month = sep,
	year = {2020},
	note = {arXiv:2004.04906 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{yang_leandojo_2023,
	title = {{LeanDojo}: {Theorem} {Proving} with {Retrieval}-{Augmented} {Language} {Models}},
	shorttitle = {{LeanDojo}},
	url = {http://arxiv.org/abs/2306.15626},
	doi = {10.48550/arXiv.2306.15626},
	abstract = {Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection: a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): an LLM-based prover augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's program analysis capability to identify accessible premises and hard negative examples, which makes retrieval much more effective. Furthermore, we construct a new benchmark consisting of 98,734 theorems and proofs extracted from Lean's math library. It features challenging data split requiring the prover to generalize to theorems relying on novel premises that are never used in training. We use this benchmark for training and evaluation, and experimental results demonstrate the effectiveness of ReProver over non-retrieval baselines and GPT-4. We thus provide the first set of open-source LLM-based theorem provers without any proprietary datasets and release it under a permissive MIT license to facilitate further research.},
	urldate = {2024-04-25},
	publisher = {arXiv},
	author = {Yang, Kaiyu and Swope, Aidan M. and Gu, Alex and Chalamala, Rahul and Song, Peiyang and Yu, Shixing and Godil, Saad and Prenger, Ryan and Anandkumar, Anima},
	month = oct,
	year = {2023},
	note = {arXiv:2306.15626 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{mckinzie_mm1_2024,
	title = {{MM1}: {Methods}, {Analysis} \& {Insights} from {Multimodal} {LLM} {Pre}-training},
	shorttitle = {{MM1}},
	url = {http://arxiv.org/abs/2403.09611},
	doi = {10.48550/arXiv.2403.09611},
	abstract = {In this work, we discuss building performant Multimodal Large Language Models (MLLMs). In particular, we study the importance of various architecture components and data choices. Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons. For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art (SOTA) few-shot results across multiple benchmarks, compared to other published pre-training results. Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance. By scaling up the presented recipe, we build MM1, a family of multimodal models up to 30B parameters, including both dense models and mixture-of-experts (MoE) variants, that are SOTA in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks. Thanks to large-scale pre-training, MM1 enjoys appealing properties such as enhanced in-context learning, and multi-image reasoning, enabling few-shot chain-of-thought prompting.},
	urldate = {2024-04-25},
	publisher = {arXiv},
	author = {McKinzie, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and Belyi, Anton and Zhang, Haotian and Singh, Karanjeet and Kang, Doug and Jain, Ankur and Hè, Hongyu and Schwarzer, Max and Gunter, Tom and Kong, Xiang and Zhang, Aonan and Wang, Jianyu and Wang, Chong and Du, Nan and Lei, Tao and Wiseman, Sam and Yin, Guoli and Lee, Mark and Wang, Zirui and Pang, Ruoming and Grasch, Peter and Toshev, Alexander and Yang, Yinfei},
	month = apr,
	year = {2024},
	note = {arXiv:2403.09611 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{collins_evaluating_2023,
	title = {Evaluating {Language} {Models} for {Mathematics} through {Interactions}},
	url = {http://arxiv.org/abs/2306.01694},
	doi = {10.48550/arXiv.2306.01694},
	abstract = {There is much excitement about the opportunity to harness the power of large language models (LLMs) when building problem-solving assistants. However, the standard methodology of evaluating LLMs relies on static pairs of inputs and outputs, and is insufficient for making an informed decision about which LLMs and under which assistive settings can they be sensibly used. Static assessment fails to account for the essential interactive element in LLM deployment, and therefore limits how we understand language model capabilities. We introduce CheckMate, an adaptable prototype platform for humans to interact with and evaluate LLMs. We conduct a study with CheckMate to evaluate three language models (InstructGPT, ChatGPT, and GPT-4) as assistants in proving undergraduate-level mathematics, with a mixed cohort of participants from undergraduate students to professors of mathematics. We release the resulting interaction and rating dataset, MathConverse. By analysing MathConverse, we derive a taxonomy of human behaviours and uncover that despite a generally positive correlation, there are notable instances of divergence between correctness and perceived helpfulness in LLM generations, amongst other findings. Further, we garner a more granular understanding of GPT-4 mathematical problem-solving through a series of case studies, contributed by expert mathematicians. We conclude with actionable takeaways for ML practitioners and mathematicians: models that communicate uncertainty respond well to user corrections, and are more interpretable and concise may constitute better assistants. Interactive evaluation is a promising way to navigate the capability of these models; humans should be aware of language models' algebraic fallibility and discern where they are appropriate to use.},
	urldate = {2024-04-24},
	publisher = {arXiv},
	author = {Collins, Katherine M. and Jiang, Albert Q. and Frieder, Simon and Wong, Lionel and Zilka, Miri and Bhatt, Umang and Lukasiewicz, Thomas and Wu, Yuhuai and Tenenbaum, Joshua B. and Hart, William and Gowers, Timothy and Li, Wenda and Weller, Adrian and Jamnik, Mateja},
	month = nov,
	year = {2023},
	note = {arXiv:2306.01694 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@misc{collins_structured_2022,
	title = {Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
	shorttitle = {Structured, flexible, and robust},
	url = {http://arxiv.org/abs/2205.05718},
	doi = {10.48550/arXiv.2205.05718},
	abstract = {Human language offers a powerful window into our thoughts -- we tell stories, give explanations, and express our beliefs and goals through words. Abundant evidence also suggests that language plays a developmental role in structuring our learning. Here, we ask: how much of human-like thinking can be captured by learning statistical patterns in language alone? We first contribute a new challenge benchmark for comparing humans and distributional large language models (LLMs). Our benchmark contains two problem-solving domains (planning and explanation generation) and is designed to require generalization to new, out-of-distribution problems expressed in language. We find that humans are far more robust than LLMs on this benchmark. Next, we propose a hybrid Parse-and-Solve model, which augments distributional LLMs with a structured symbolic reasoning module. We find that this model shows more robust adaptation to out-of-distribution planning problems, demonstrating the promise of hybrid AI models for more human-like reasoning.},
	urldate = {2024-04-24},
	publisher = {arXiv},
	author = {Collins, Katherine M. and Wong, Catherine and Feng, Jiahai and Wei, Megan and Tenenbaum, Joshua B.},
	month = may,
	year = {2022},
	note = {arXiv:2205.05718 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Symbolic Computation},
}

@misc{saparov_language_2023,
	title = {Language {Models} {Are} {Greedy} {Reasoners}: {A} {Systematic} {Formal} {Analysis} of {Chain}-of-{Thought}},
	shorttitle = {Language {Models} {Are} {Greedy} {Reasoners}},
	url = {http://arxiv.org/abs/2210.01240},
	doi = {10.48550/arXiv.2210.01240},
	abstract = {Large language models (LLMs) have shown remarkable reasoning capabilities given chain-of-thought prompts (examples with intermediate reasoning steps). Existing benchmarks measure reasoning ability indirectly, by evaluating accuracy on downstream tasks such as mathematical reasoning. However, it is unclear how these models obtain the answers and whether they rely on simple heuristics rather than the generated chain-of-thought. To enable systematic exploration of the reasoning ability of LLMs, we present a new synthetic question-answering dataset called PrOntoQA, where each example is generated from a synthetic world model represented in first-order logic. This allows us to parse the generated chain-of-thought into symbolic proofs for formal analysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite capable of making correct individual deduction steps, and so are generally capable of reasoning, even in fictional contexts. However, they have difficulty with proof planning: When multiple valid deduction steps are available, they are not able to systematically explore the different options.},
	urldate = {2024-04-24},
	publisher = {arXiv},
	author = {Saparov, Abulhair and He, He},
	month = mar,
	year = {2023},
	note = {arXiv:2210.01240 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{ding_cycle_2024,
	title = {{CYCLE}: {Learning} to {Self}-{Refine} the {Code} {Generation}},
	shorttitle = {{CYCLE}},
	url = {http://arxiv.org/abs/2403.18746},
	doi = {10.48550/arXiv.2403.18746},
	abstract = {Pre-trained code language models have achieved promising performance in code generation and improved the programming efficiency of human developers. However, their self-refinement capability is typically overlooked by the existing evaluations of code LMs, which focus only on the accuracy of the one-time prediction. For the cases when code LMs fail to implement the correct program, developers actually find it hard to debug and fix the faulty prediction since it is not written by the developers themselves. Unfortunately, our study reveals that code LMs cannot efficiently self-refine their faulty generations as well. In this paper, we propose CYCLE framework, learning to self-refine the faulty generation according to the available feedback, such as the execution results reported by the test suites. We evaluate CYCLE on three popular code generation benchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLE successfully maintains, sometimes improves, the quality of one-time code generation, while significantly improving the self-refinement capability of code LMs. We implement four variants of CYCLE with varied numbers of parameters across 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistently boosts the code generation performance, by up to 63.5\%, across benchmarks and varied model sizes. We also notice that CYCLE outperforms code LMs that have 3\${\textbackslash}times\$ more parameters in self-refinement.},
	urldate = {2024-04-01},
	publisher = {arXiv},
	author = {Ding, Yangruibo and Min, Marcus J. and Kaiser, Gail and Ray, Baishakhi},
	month = mar,
	year = {2024},
	note = {arXiv:2403.18746 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering},
}

@inproceedings{lemieux_codamosa_2023,
	title = {{CodaMosa}: {Escaping} {Coverage} {Plateaus} in {Test} {Generation} with {Pre}-trained {Large} {Language} {Models}},
	shorttitle = {{CodaMosa}},
	url = {https://ieeexplore.ieee.org/document/10172800},
	doi = {10.1109/ICSE48619.2023.00085},
	abstract = {Search-based software testing (SBST) generates high-coverage test cases for programs under test with a combination of test case generation and mutation. SBST's performance relies on there being a reasonable probability of generating test cases that exercise the core logic of the program under test. Given such test cases, SBST can then explore the space around them to exercise various parts of the program. This paper explores whether Large Language Models (LLMs) of code, such as OpenAI's Codex, can be used to help SBST's exploration. Our proposed algorithm, CodaMosa, conducts SBST until its coverage improvements stall, then asks Codex to provide example test cases for under-covered functions. These examples help SBST redirect its search to more useful areas of the search space. On an evaluation over 486 benchmarks, CodaMosa achieves statistically significantly higher coverage on many more benchmarks (173 and 279) than it reduces coverage on (10 and 4), compared to SBST and LLM-only baselines.},
	urldate = {2024-04-01},
	booktitle = {2023 {IEEE}/{ACM} 45th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Lemieux, Caroline and Inala, Jeevana Priya and Lahiri, Shuvendu K. and Sen, Siddhartha},
	month = may,
	year = {2023},
	note = {ISSN: 1558-1225},
	keywords = {Benchmark testing, Codes, Software, Software engineering, Software testing, Space exploration, Test pattern generators, automated testing, codex, large language model, python, search based software testing, test suite generation},
	pages = {919--931},
}

@misc{CodeGen2,
	title = {{CodeGen2}: {Lessons} for {Training} {LLMs} on {Programming} and {Natural} {Languages}},
	shorttitle = {{CodeGen2}},
	url = {http://arxiv.org/abs/2305.02309},
	doi = {10.48550/arXiv.2305.02309},
	abstract = {Large language models (LLMs) have demonstrated remarkable abilities in representation learning for program synthesis and understanding tasks. The quality of the learned representations appears to be dictated by the neural scaling laws as a function of the number of model parameters and observations, while imposing upper bounds on the model performance by the amount of available data and compute, which is costly. In this study, we attempt to render the training of LLMs for program synthesis more efficient by unifying four key components: (1) model architectures, (2) learning methods, (3) infill sampling, and, (4) data distributions. Specifically, for the model architecture, we attempt to unify encoder and decoder-based models into a single prefix-LM. For learning methods, (i) causal language modeling, (ii) span corruption, (iii) infilling are unified into a simple learning algorithm. For infill sampling, we explore the claim of a "free lunch" hypothesis. For data distributions, the effect of a mixture distribution and multi-epoch training of programming and natural languages on model performance is explored. We conduct a comprehensive series of empirical experiments on 1B LLMs, for which failures and successes of this exploration are distilled into five lessons. We will provide a final recipe for training and release CodeGen2 models in size 1B, 3.7B, 7B, and, 16B parameters, along with the training framework as open-source: https://github.com/salesforce/CodeGen.},
	urldate = {2024-04-01},
	publisher = {arXiv},
	author = {Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
	month = jul,
	year = {2023},
	note = {arXiv:2305.02309 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{whyDiagramWorth,
	title = {Why a {Diagram} is ({Sometimes}) {Worth} {Ten} {Thousand} {Words}},
	volume = {11},
	issn = {0364-0213},
	url = {http://www.sciencedirect.com/science/article/pii/S0364021387800265},
	doi = {10.1016/S0364-0213(87)80026-5},
	abstract = {We distinguish diagrammatic from sentential paper-and-pencil representations of information by developing alternative models of information-processing systems that are informationally equivalent and that can be characterized as sentential or diagrammatic. Sentential representations are sequential, like the propositions in a text. Diagrammatic representations are indexed by location in a plane. Diagrammatic representations also typically display information that is only implicit in sentential representations and that therefore has to be computed, sometimes at great cost, to make it explicit for use. We then contrast the computational efficiency of these representations for solving several illustrative problems in mathematics and physics. When two representations are informationally equivalent, their computational efficiency depends on the information-processing operators that act on them. Two sets of operators may differ in their capabilities for recognizing patterns, in the inferences they can carry out directly, and in their control strategies (in particular, the control of search). Diagrammatic and sentential representations support operators that differ in all of these respects. Operators working on one representation may recognize features readily or make inferences directly that are difficult to realize in the other representation. Most important, however, are differences in the efficiency of search for information and in the explicitness of information. In the representations we call diagrammatic, information is organized by location, and often much of the information needed to make an inference is present and explicit at a single location. In addition, cues to the next logical step in the problem may be present at an adjacent location. Therefore problem solving can proceed through a smooth traversal of the diagram, and may require very little search or computation of elements that had been implicit.},
	number = {1},
	urldate = {2019-05-11},
	journal = {Cognitive Science},
	author = {Larkin, Jill H. and Simon, Herbert A.},
	month = jan,
	year = {1987},
	pages = {65--100},
}

@article{myers_garnet_1990,
	title = {Garnet: {Comprehensive} {Support} for {Graphical}, {Highly} {Interactive} {User} {Interfaces}},
	volume = {23},
	issn = {00189162},
	doi = {10.1109/2.60882},
	number = {11},
	journal = {Computer},
	author = {Myers, Brad A. and Giuse, Dario A. and Dannenberg, Roger B. and Vander Zanden, Brad and Kosbie, David S. and Pervin, Edward and Mickish, Andrew and Marchal, Philippe},
	year = {1990},
	pages = {71--85},
}

@article{gulwani_example-based_2014,
	title = {Example-based {Learning} in {Computer}-aided {STEM} {Education}},
	volume = {57},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2634273},
	doi = {10.1145/2634273},
	abstract = {Human learning is often structured around examples. Interestingly, example-based reasoning has also been heavily used in computer-aided programming. In this article, we describe how techniques inspired from example-based program analysis and synthesis can be used for various tasks in Education including problem generation, solution generation, and feedback generation. We illustrate this using recent research results …},
	number = {8},
	urldate = {2018-11-07},
	journal = {Commun. ACM},
	author = {Gulwani, Sumit},
	month = aug,
	year = {2014},
	keywords = {Program synthesis},
	pages = {70--80},
}

@inproceedings{falleri_fine-grained_2014,
	title = {Fine-grained and accurate source code differencing},
	url = {https://dl.acm.org/doi/10.1145/2642937.2642982},
	doi = {10.1145/2642937.2642982},
	abstract = {At the heart of software evolution is a sequence of edit actions, called an edit script, made to a source code file. Since software systems are stored version by version, the edit script has to be computed from these versions, which is known as a complex task. Existing approaches usually compute edit scripts at the text granularity with only add line and delete line actions. However, inferring syntactic changes from such an edit script is hard. Since moving code is a frequent action performed when editing code, it should also be taken into account. In this paper, we tackle these issues by introducing an algorithm computing edit scripts at the abstract syntax tree granularity including move actions. Our objective is to compute edit scripts that are short and close to the original developer intent. Our algorithm is implemented in a freely-available and extensible tool that has been intensively validated.},
	booktitle = {{ASE} 2014 - {Proceedings} of the 29th {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Falleri, Jean Rémy and Morandat, Floréal and Blanc, Xavier and Martinez, Matias and Monperrus, Martin},
	year = {2014},
	keywords = {AST, Program comprehension, Software evolution, Tree differencing},
	pages = {313--323},
}

@article{rittle-johnson_developing_2001,
	title = {Developing conceptual understanding and procedural skill in mathematics: {An} iterative process},
	volume = {93},
	issn = {1939-2176(Electronic),0022-0663(Print)},
	shorttitle = {Developing conceptual understanding and procedural skill in mathematics},
	doi = {10.1037/0022-0663.93.2.346},
	abstract = {The authors propose that conceptual and procedural knowledge develop in an iterative fashion and that improved problem representation is 1 mechanism underlying the relations between them. Two experiments were conducted with 5th- and 6th-grade students learning about decimal fractions. In Experiment 1, children's initial conceptual knowledge predicted gains in procedural knowledge, and gains in procedural knowledge predicted improvements in conceptual knowledge. Correct problem representations mediated the relation between initial conceptual knowledge and improved procedural knowledge. In Experiment 2, amount of support for correct problem representation was experimentally manipulated, and the manipulations led to gains in procedural knowledge. Thus, conceptual and procedural knowledge develop iteratively, and improved problem representation is 1 mechanism in this process. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Journal of Educational Psychology},
	author = {Rittle-Johnson, Bethany and Siegler, Robert S. and Alibali, Martha Wagner},
	year = {2001},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cognitive Development, Concept Formation, Declarative Knowledge, Elementary School Students, Mathematics (Concepts), Mathematics Education, Middle School Students, Procedural Knowledge},
	pages = {346--362},
}

@article{rau_conditions_2017,
	title = {Conditions for the {Effectiveness} of {Multiple} {Visual} {Representations} in {Enhancing} {STEM} {Learning}},
	volume = {29},
	issn = {1573-336X},
	url = {https://doi.org/10.1007/s10648-016-9365-3},
	doi = {10.1007/s10648-016-9365-3},
	abstract = {Visual representations play a critical role in enhancing science, technology, engineering, and mathematics (STEM) learning. Educational psychology research shows that adding visual representations to text can enhance students’ learning of content knowledge, compared to text-only. But should students learn with a single type of visual representation or with multiple different types of visual representations? This article addresses this question from the perspective of the representation dilemma, namely that students often learn content they do not yet understand from representations they do not yet understand. To benefit from visual representations, students therefore need representational competencies, that is, knowledge about how visual representations depict information about the content. This article reviews literature on representational competencies involved in students’ learning of content knowledge. Building on this review, this article analyzes how the number of visual representations affects the role these representational competencies play during students’ learning of content knowledge. To this end, the article compares two common scenarios: text plus a single type of visual representations (T+SV) and text plus multiple types of visual representations (T+MV). The comparison yields seven hypotheses that describe under which conditions T+MV scenarios are more effective than T+SV scenarios. Finally, the article reviews empirical evidence for each hypothesis and discusses open questions about the representation dilemma.},
	language = {en},
	number = {4},
	urldate = {2019-04-08},
	journal = {Educational Psychology Review},
	author = {Rau, Martina A.},
	month = dec,
	year = {2017},
	keywords = {Conceptual and perceptual knowledge , Inductive learning processes , Multiple external representations , Sense-making processes , Visualizations },
	pages = {717--761},
}

@article{kern_automation_2008,
	title = {Automation and the {Map} {Label} {Placement} {Problem}: {A} {Comparison} of {Two} {GIS} {Implementations} of {Label} {Placement}},
	issn = {1048-9053},
	url = {https://cartographicperspectives.org/index.php/journal/article/view/cp60-kern-brewer},
	doi = {10.14714/CP60.230},
	abstract = {The placement of feature name labels on maps has challenged mapmakers throughout history. Before the development of mapping software, placing labels in manual map production could consume up to half or more of overall map production time. This paper explores the extent to which current GIS software can place labels legibly, without overlap, and with good visual association between features and labels. This evaluation takes place in the context of a densely featured municipal sewer utility map book. The primary research objective is to evaluate the ability of current GIS software to automate label placement; the research also identifies factors that make manual refinement of automated label placement necessary in order to complete the labeling process. The research compares map-labeling tools from ESRI TM ’s ArcMap TM 9.2: the Standard Labeling Engine and the Maplex TM labeling extension. Label placement success is assessed by both quantity and quality metrics, using a methodology developed and tailored specifically for evaluation of sewer map label placement. The research found that Maplex placed almost seven percent more labels overall than the Standard Labeling Engine. For the labels they did place, both products provided equally good quality label placement: About 93 percent of labels were placed with no overlap, and virtually 100 percent of labels were placed in their preferred position. After conversion to annotation, manual label position refinement eliminated all overlaps but at the cost of a nine percent decline in the preferred position metric.},
	number = {60},
	journal = {Cartographic Perspectives},
	author = {Kern, Jill Phelps and Brewer, Cynthia A.},
	year = {2008},
	keywords = {Automated label placement, GIS mapping, Map design, Map label placement, Utility map labeling, automated label placement, map design, utility map  labeling},
	pages = {22--45},
}

@article{pane_assessing_1996,
	title = {Assessing dynamics in computer-based instruction},
	doi = {10.1145/238386.238482},
	abstract = {We present an evaluation of a multimedia educational software system that includes text, graphics, animations, and simulations. When compared with an informationally equivalent control environment that used text and carefully selected still images, we found little evidence that the dynamic presentations enhanced student understanding of the declarative information in this lesson. Furthermore, students cannot be relied on to take full advantage of exploratory opportunities in computer-based instruction. These results prescribe further investigation of whether and how computer-based multimedia can be used effectively in education and training.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Pane, John F. and Corbett, Albert T. and John, Bonnie E.},
	year = {1996},
	keywords = {animation, computer-based leaming, multimedia, simulation},
	pages = {197--204},
}

@article{green_usability_1996,
	title = {Usability {Analysis} of {Visual} {Programming} {Environments}: {A} ‘{Cognitive} {Dimensions}’ {Framework}},
	volume = {7},
	issn = {1045-926X},
	shorttitle = {Usability {Analysis} of {Visual} {Programming} {Environments}},
	url = {http://www.sciencedirect.com/science/article/pii/S1045926X96900099},
	doi = {10.1006/jvlc.1996.0009},
	abstract = {The cognitive dimensions framework is a broad-brush evaluation technique for interactive devices and for non-interactive notations. It sets out a small vocabulary of terms designed to capture the cognitively-relevant aspects of structure, and shows how they can be traded off against each other. The purpose of this paper is to propose the framework as an evaluation technique for visual programming environments. We apply it to two commercially-available dataflow languages (with further examples from other systems) and conclude that it is effective and insightful; other HCI-based evaluation techniques focus on different aspects and would make good complements. Insofar as the examples we used are representative, current VPLs are successful in achieving a good ‘closeness of match’, but designers need to consider the ‘viscosity ’ (resistance to local change) and the ‘secondary notation’ (possibility of conveying extra meaning by choice of layout, colour, etc.).},
	number = {2},
	urldate = {2019-09-15},
	journal = {Journal of Visual Languages \& Computing},
	author = {Green, T. R. G. and Petre, M.},
	month = jun,
	year = {1996},
	pages = {131--174},
}

@article{yi_toward_2007,
	title = {Toward a deeper understanding of the role of interaction in information visualization},
	volume = {13},
	issn = {10772626},
	doi = {10.1109/TVCG.2007.70515},
	abstract = {Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction. © 2007 IEEE.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yi, Ji Soo and Kang, Youn Ah and Stasko, John T. and Jacko, Julie A.},
	year = {2007},
	keywords = {Information visualization, Interaction, Interaction techniques, Taxonomy, Visual analytics},
	pages = {1224--1231},
}

@article{kriz_top-down_2007,
	title = {Top-down and bottom-up influences on learning from animations},
	volume = {65},
	issn = {1071-5819},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581907000869},
	doi = {10.1016/j.ijhcs.2007.06.005},
	abstract = {To evaluate how top-down and bottom-up processes contribute to learning from animated displays, we conducted four experiments that varied either in the design of animations or the prior knowledge of the learners. Experiments 1–3 examined whether adding interactivity and signaling to an animation benefits learners in developing a mental model of a mechanical system. Although learners utilized interactive controls and signaling devices, their comprehension of the system was no better than that of learners who saw animations without these design features. Furthermore, the majority of participants developed a mental model of the system that was incorrect and inconsistent with information displayed in the animation. Experiment 4 tested effects of domain knowledge and found, surprisingly, that even some learners with high domain knowledge initially constructed the incorrect mental model. After multiple exposures to the materials, the high knowledge learners revised their mental models to the correct one, while the low-knowledge learners maintained their erroneous models. These results suggest that learning from animations involves a complex interplay between top-down and bottom-up processes and that more emphasis should be placed on how prior knowledge is applied to interpreting animations.},
	number = {11},
	urldate = {2024-03-19},
	journal = {International Journal of Human-Computer Studies},
	author = {Kriz, Sarah and Hegarty, Mary},
	month = nov,
	year = {2007},
	keywords = {Animations, Interactivity, Learning, Mental Models},
	pages = {911--930},
}

@techreport{roegel_editing_2015,
	type = {report},
	title = {Editing ancient technical and mathematical figures: {Tools} and traps},
	shorttitle = {Editing ancient technical and mathematical figures},
	url = {https://inria.hal.science/hal-01198446},
	abstract = {This study examines a number of problems and issues in the edition of ancient technical and mathematical figures, and review a number of solutions and possible extensions to better suit the needs of historians.},
	language = {en},
	urldate = {2024-03-27},
	institution = {LORIA - Université de Lorraine},
	author = {Roegel, Denis},
	month = jun,
	year = {2015},
	keywords = {ancient diagrams},
}

@article{hearst_show_2023,
	title = {Show {It} or {Tell} {It}? {Text}, {Visualization}, and {Their} {Combination}},
	volume = {66},
	issn = {0001-0782},
	shorttitle = {Show {It} or {Tell} {It}?},
	url = {https://dl.acm.org/doi/10.1145/3593580},
	doi = {10.1145/3593580},
	abstract = {When communicating information, language should be considered as co-equal with visualization.},
	number = {10},
	urldate = {2024-03-26},
	journal = {Communications of the ACM},
	author = {Hearst, Marti A.},
	month = sep,
	year = {2023},
	pages = {68--75},
}

@misc{noauthor_show_2023,
	title = {Show {It} or {Tell} {It}? {Text}, {Visualization}, and {Their} {Combination} – {Communications} of the {ACM}},
	shorttitle = {Show {It} or {Tell} {It}?},
	url = {https://cacm.acm.org/research/show-it-or-tell-it-text-visualization-and-their-combination/},
	language = {en-US},
	urldate = {2024-03-26},
	month = oct,
	year = {2023},
}

@article{lake_human-like_2023,
	title = {Human-like systematic generalization through a meta-learning neural network},
	volume = {623},
	copyright = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06668-3},
	doi = {10.1038/s41586-023-06668-3},
	abstract = {The power of human language and thought arises from systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. Fodor and Pylyshyn1 famously argued that artificial neural networks lack this capacity and are therefore not viable models of the mind. Neural networks have advanced considerably in the years since, yet the systematicity challenge persists. Here we successfully address Fodor and Pylyshyn’s challenge by providing evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills. To do so, we introduce the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. To compare humans and machines, we conducted human behavioural experiments using an instruction learning paradigm. After considering seven different models, we found that, in contrast to perfectly systematic but rigid probabilistic symbolic models, and perfectly flexible but unsystematic neural networks, only MLC achieves both the systematicity and flexibility needed for human-like generalization. MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks. Our results show how a standard neural network architecture, optimized for its compositional skills, can mimic human systematic generalization in a head-to-head comparison.},
	language = {en},
	number = {7985},
	urldate = {2024-03-26},
	journal = {Nature},
	author = {Lake, Brenden M. and Baroni, Marco},
	month = nov,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, GPT, Human behaviour},
	pages = {115--121},
}

@article{weiser_computer_1999,
	title = {The computer for the 21 $^{\textrm{st}}$ century},
	volume = {3},
	issn = {1559-1662, 1931-1222},
	url = {https://dl.acm.org/doi/10.1145/329124.329126},
	doi = {10.1145/329124.329126},
	abstract = {Specialized elements of hardware and software, connected by wires, radio waves and infrared, will be so ubiquitous that no one will notice their presence.},
	language = {en},
	number = {3},
	urldate = {2024-03-26},
	journal = {ACM SIGMOBILE Mobile Computing and Communications Review},
	author = {Weiser, Mark},
	month = jul,
	year = {1999},
	pages = {3--11},
}

@article{lakhani_what_nodate,
	title = {What {If} {Schools} {Started} {With} {Debugging}?},
	abstract = {Introductory Computer Science (CS) courses at many well-established universities often prioritize the development of program application and synthesis skills, with a predominant focus on writing code. The rapid progression from topics like arrays to binary search trees and graph search tends to bypass fundamental comprehension and analysis skills. Consequently, students entering computer science education at this level face the challenge of not only keeping up with assignments and grasping underlying concepts but also independently debugging errors without the knowledge of how to do so. For some novice learners, the absence of a foundation in decomposing problems before writing code and iteratively addressing errors can lead to difficulties, occasionally resulting in course withdrawal, holding them back from advancing to other courses. In response to this issue, we implemented an intervention, piloted as a course at Carnegie Mellon University, aimed at providing struggling learners in introductory CS courses with the tools to succeed and enhance their overall learning experiences. In this quasi-experimental study, addressing a substantial and long-standing problem space, we present estimations demonstrating that our debugging-focused, software engineering-laden pilot course can improve student scores by up to 38\% on average if taken before other foundational CS classes. We also explore the challenges faced by novice learners in these introductory curricula, using survey results from those who qualified for our piloted course based on their struggles in a required foundation course.},
	language = {en},
	author = {Lakhani, Zeeshan},
}

@article{diaz_survey_2002,
	title = {A survey of graph layout problems},
	volume = {34},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/568522.568523},
	doi = {10.1145/568522.568523},
	abstract = {Graph layout problems are a particular class of combinatorial optimization problems whose goal is to find a linear layout of an input graph in such way that a certain objective cost is optimized. This survey considers their motivation, complexity, approximation properties, upper and lower bounds, heuristics and probabilistic analysis on random graphs. The result is a complete view of the current state of the art with respect to layout problems from an algorithmic point of view.},
	number = {3},
	urldate = {2024-03-22},
	journal = {ACM Computing Surveys},
	author = {Díaz, Josep and Petit, Jordi and Serna, Maria},
	month = sep,
	year = {2002},
	keywords = {Approximation algorithms, complexity, embedding, heuristics, layout, parameterized complexity, random graphs},
	pages = {313--356},
}

@inproceedings{clark_homotopy_2023,
	address = {New York, NY, USA},
	series = {{FARM} 2023},
	title = {Homotopy {Type} {Theory} for {Sewn} {Quilts}},
	isbn = {9798400702952},
	url = {https://dl.acm.org/doi/10.1145/3609023.3609803},
	doi = {10.1145/3609023.3609803},
	abstract = {This paper introduces PieceWork, an imperative programming language for the construction of designs for sewn quilts, whose semantics are inspired by Homotopy Type Theory. The goals of PieceWork include improving the diversity of sewn designs that can be represented in computational methods, demonstrating a creative application of Homotopy Type Theory, and demonstrating that the craft of quilting is a worthy object of study in programming language theory. We develop an operational semantics, provide a prototype implementation and examples, and provide initial theoretical results. Type system design is in-progress.},
	urldate = {2024-03-21},
	booktitle = {Proceedings of the 11th {ACM} {SIGPLAN} {International} {Workshop} on {Functional} {Art}, {Music}, {Modelling}, and {Design}},
	publisher = {Association for Computing Machinery},
	author = {Clark, Charlotte and Bohrer, Rose},
	month = aug,
	year = {2023},
	keywords = {computational craft, creative coding, homotopy type theory, quilts},
	pages = {32--43},
}

@inproceedings{Nawrocki2023,
	address = {Białystok},
	title = {An {Extensible} {User} {Interface} for {Lean} 4},
	volume = {268},
	isbn = {978-3-95977-284-6},
	url = {https://github.com/EdAyers/ProofWidgets4/tree/itp23},
	doi = {10.4230/LIPIcs.ITP.2023.24},
	abstract = {Contemporary proof assistants rely on complex automation and process libraries with millions of lines of code. At these scales, understanding the emergent interactions between components can be a serious challenge. One way of managing complexity, long established in informal practice, is through varying external representations. For instance, algebraic notation facilitates term-based reasoning whereas geometric diagrams invoke spatial intuition. Objects viewed one way become much simpler than when viewed differently. In contrast, modern general-purpose ITP systems usually only support limited, textual representations. Treating this as a problem of human-computer interaction, we aim to demonstrate that presentations - UI elements that store references to the objects they are displaying - are a fruitful way of thinking about ITP interface design. They allow us to make headway on two fronts - introspection of prover internals and support for diagrammatic reasoning. To this end we have built an extensible user interface for the Lean 4 prover with an associated ProofWidgets 4 library of presentation-based UI components. We demonstrate the system with several examples including type information popups, structured traces, contextual suggestions, a display for algebraic reasoning, and visualizations of red-black trees. Our interface is already part of the core Lean distribution.},
	urldate = {2024-03-14},
	booktitle = {14th {International} {Conference} on {Interactive} {Theorem} {Proving}},
	publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
	author = {Nawrocki, Wojciech and Ayers, Edward W. and Ebner, Gabriel},
	month = jul,
	year = {2023},
	note = {Series Title: ITP 2023
ISSN: 18688969},
	keywords = {Lean, human-computer interaction, user interfaces},
}

@article{barrett_constrained_2015,
	title = {Constrained interactivity for relating multiple representations in science: {When} virtual is better than real},
	volume = {81},
	issn = {0360-1315},
	shorttitle = {Constrained interactivity for relating multiple representations in science},
	url = {https://www.sciencedirect.com/science/article/pii/S0360131514002097},
	doi = {10.1016/j.compedu.2014.09.009},
	abstract = {Virtual models are increasingly used in science education, especially in spatially demanding domains. However, few studies have directly compared the effectiveness of virtual and concrete models, or systematically characterized differences between them. Here, we compared students' accuracy and efficiency using virtual and concrete models to align and produce different representations in the domain of organic chemistry. Naïve undergraduate students learned the conventions of different molecular representations (diagrams and models) and then performed tasks that involved matching models to diagrams and using models to complete diagrams. The results indicated similar levels of accuracy for virtual and concrete models and greater efficiency for virtual models. Students preferred virtual models, but rated the usability of the two model types about equally. The efficiency benefit associated with using virtual models can be explained by their constrained interactivity, which prevented students from making task-irrelevant manipulations and increased the salience of the task-relevant information in the models.},
	urldate = {2024-03-19},
	journal = {Computers \& Education},
	author = {Barrett, Trevor J. and Stull, Andrew T. and Hsu, Ted M. and Hegarty, Mary},
	month = feb,
	year = {2015},
	keywords = {Chemistry, Constrained interactivity, Diagrams, Models, Virtual},
	pages = {69--81},
}

@article{rolandi_brief_2011,
	title = {A {Brief} {Guide} to {Designing} {Effective} {Figures} for the {Scientific} {Paper}},
	volume = {23},
	copyright = {Copyright © 2011 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {1521-4095},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.201102518},
	doi = {10.1002/adma.201102518},
	abstract = {Figures are an essential part of the scientific paper. Scientists often learn how to create figures by trial and error. A scientist, a graphic designer, and a cognitive psychologist have teamed up to write a brief guide to ease this process. This guide, aimed at researchers in scientific fields, provides an easy-to-follow set of instructions to design effective figures.},
	number = {38},
	urldate = {2024-03-19},
	journal = {Advanced Materials},
	author = {Rolandi, Marco and Cheng, Karen and Pérez-Kriz, Sarah},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adma.201102518},
	pages = {4343--4346},
}

@incollection{shin_diagrams_2018,
	edition = {Winter 2018},
	title = {Diagrams},
	url = {https://plato.stanford.edu/archives/win2018/entries/diagrams/},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Shin, Sun-Joo and Lemon, Oliver and Mumma, John},
	editor = {Zalta, Edward N.},
	year = {2018},
}

@phdthesis{miller_diagrammatic_nodate,
	address = {United States -- New York},
	type = {Ph.{D}.},
	title = {A diagrammatic formal system for {Euclidean} geometry},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/304688729/abstract/EA615FAFA1840C9PQ/1},
	abstract = {It has long been commonly assumed that geometric diagrams can only be used as aids to human intuition and cannot be used in rigorous proofs of theorems of Euclidean geometry. This work gives a formal system FG whose basic syntactic objects are geometric diagrams and which is strong enough to formalize most if not all of what is contained in the first several books of Euclid's Elements. This formal system is much more natural than other formalizations of geometry have been. Most correct informal geometric proofs using diagrams can be translated fairly easily into this system, and formal proofs in this system are not significantly harder to understand than the corresponding informal proofs. It has also been adapted into a computer system called CDEG (Computerized Diagrammatic Euclidean Geometry) for giving formal geometric proofs using diagrams. The formal system FG is used here to prove meta-mathematical and complexity theoretic results about the logical structure of Euclidean geometry and the uses of diagrams in geometry.},
	language = {English},
	urldate = {2024-03-19},
	school = {Cornell University},
	author = {Miller, Nathaniel Gregory},
	note = {ISBN: 9780493200637},
	keywords = {Diagrammatic formal system, Euclidean geometry, Foundations of geometry, Geometry, Pure sciences},
}

@article{avigad_formal_2009,
	title = {A formal system for {Euclid}'s {Elements}},
	volume = {2},
	issn = {1755-0203, 1755-0211},
	url = {http://arxiv.org/abs/0810.4315},
	doi = {10.1017/S1755020309990098},
	abstract = {We present a formal system, E, which provides a faithful model of the proofs in Euclid's Elements, including the use of diagrammatic reasoning.},
	number = {4},
	urldate = {2024-03-19},
	journal = {The Review of Symbolic Logic},
	author = {Avigad, Jeremy and Dean, Edward and Mumma, John},
	month = dec,
	year = {2009},
	note = {arXiv:0810.4315 [math]},
	keywords = {03B30, 51M05, 03B35, Mathematics - Logic},
	pages = {700--768},
}

@article{miller_computational_2006,
	title = {Computational complexity of diagram satisfaction in {Euclidean} geometry},
	volume = {22},
	issn = {0885-064X},
	url = {https://www.sciencedirect.com/science/article/pii/S0885064X05000932},
	doi = {10.1016/j.jco.2005.09.003},
	abstract = {In this paper, it is shown that the problem of deciding whether or not a geometric diagram in Euclidean Geometry is satisfiable is NP-hard and in PSPACE, and in fact has the same complexity as the satisfaction problem for a fragment of the existential theory of the real numbers. The related problem of finding all of the possible (satisfiable) diagrams that can result when a segment of a diagram is extended is also shown to be NP-hard.},
	number = {2},
	urldate = {2024-03-19},
	journal = {Journal of Complexity},
	author = {Miller, Nathaniel},
	month = apr,
	year = {2006},
	keywords = {Computational complexity, Diagrams, Euclidean geometry},
	pages = {250--274},
}

@incollection{manders_euclidean_2008,
	title = {The {Euclidean} {Diagram}},
	booktitle = {The {Philosophy} of {Mathematical} {Practice}},
	publisher = {Oxford University Press},
	author = {Manders, Kenneth},
	editor = {Mancosu, Paolo},
	year = {2008},
	pages = {80--133},
}

@misc{noauthor_symbolic_nodate,
	title = {Symbolic {Logic}},
	url = {https://www.gutenberg.org/files/28696/28696-h/28696-h.htm},
	urldate = {2024-03-19},
}

@incollection{tversky_visualizing_2014,
	address = {New York, NY},
	title = {Visualizing {Thought}},
	isbn = {978-1-4614-7485-2},
	url = {https://doi.org/10.1007/978-1-4614-7485-2_1},
	abstract = {Depictive expressions of thought predate written language by thousands of years. They have evolved in communities through a kind of informal user testing that has refined them. Analyzing common visual communications reveals consistencies that illuminate how people think as well as guide design; the process can be brought into the laboratory and accelerated. Like language, visual communications abstract and schematize; unlike language, they use properties of the page (e.g., proximity and place: center, horizontal/up-down, vertical/left-right) and the marks on it (e.g., dots, lines, arrows, boxes, blobs, likenesses, symbols) to convey meanings. The visual expressions of these meanings (e.g., individual, category, order, relation, correspondence, continuum, hierarchy) have analogs in language, gesture, and especially in the patterns that are created when people design the world around them, arranging things into piles and rows and hierarchies and arrays, spatial-abstraction-action interconnections termed spractions. The designed world is a diagram.},
	language = {en},
	urldate = {2024-03-19},
	booktitle = {Handbook of {Human} {Centric} {Visualization}},
	publisher = {Springer},
	author = {Tversky, Barbara},
	editor = {Huang, Weidong},
	year = {2014},
	doi = {10.1007/978-1-4614-7485-2_1},
	keywords = {Asymmetric Relation, External Representation, Route Direction, Visual Communication, Visual Vocabulary},
	pages = {3--40},
}

@article{dyer_applying_2022,
	title = {Applying cognitive principles to model-finding output: {The} positive value of negative information},
	volume = {6},
	issn = {24751421},
	url = {https://dl.acm.org/doi/10.1145/3527323},
	doi = {10.1145/3527323},
	abstract = {Model-finders, such as SAT/SMT-solvers and Alloy, are used widely both directly and embedded in domain-specific tools. They support both conventional verification and, unlike other verification tools, property-free exploration. To do this effectively, they must produce output that helps users with these tasks. Unfortunately, the output of model-finders has seen relatively little rigorous human-factors study. Conventionally, these tools tend to show one satisfying instance at a time. Drawing inspiration from the cognitive science literature, we investigate two aspects of model-finder output: how many instances to show at once, and whether all instances must actually satisfy the input constraints. Using both controlled studies and open-ended talk-alouds, we show that there is benefit to showing negative instances in certain settings; the impact of multiple instances is less clear. Our work is a first step in a theoretically grounded approach to understanding how users engage cognitively with model-finder output, and how those tools might better support users in doing so.},
	number = {OOPSLA1},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Dyer, Tristan and Nelson, Tim and Fisler, Kathi and Krishnamurthi, Shriram},
	year = {2022},
	keywords = {Alloy, cognitive science, model finding, user studies},
}

@article{perceptualChunks,
	title = {Abstract planning and perceptual chunks: {Elements} of expertise in geometry},
	volume = {14},
	issn = {0364-0213},
	shorttitle = {Abstract planning and perceptual chunks},
	url = {http://www.sciencedirect.com/science/article/pii/036402139090008K},
	doi = {10.1016/0364-0213(90)90008-K},
	abstract = {We present a new model of skilled performance in geometry proof problem solving called the Diagram Configuration model (DC). While previous models plan proofs in a step-by-step fashion, we observed that experts plan at a more abstract level: They focus on the key steps and skip the less important ones. DC models this abstract planning behavior by parsing geometry problem diagrams into perceptual chunks, called diagram configurations, which cue relevant schematic knowledge. We provide verbal protocol evidence that DC's schemas correspond with the step-skipping inferences experts make in their initial planning. We compare DC with other models of geometry expertise and then, in the final section, we discuss more general implications of our research. DC's reasoning has important similarities with Larkin's (1988) display-based reasoning approach and Johnson-Laird's (1983) mental model approach. DC's perceptually based schemas are a step towards a unified explanation of (1) experts' superior problem-solving effectiveness, (2) experts' superior problem-state memory, and (3) experts' ability, in certain domains, to solve relatively simple problems by pure forward inferencing. We also argue that the particular and efficient knowledge organization of DC challenges current theories of skill acquisition as it presents an end-state of learning that is difficult to explain within such theories. Finally, we discuss the implications of DC for geometry instruction.},
	number = {4},
	urldate = {2019-04-16},
	journal = {Cognitive Science},
	author = {Koedinger, Kenneth R. and Anderson, John R.},
	month = oct,
	year = {1990},
	pages = {511--550},
}

@inproceedings{rho_preparing_2022,
	title = {Preparing {Future} {Learning} with {Novel} {Visuals} by {Supporting} {Representational} {Competencies}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-11644-5_6},
	doi = {10.1007/978-3-031-11644-5_6},
	abstract = {Many STEM problems involve visuals. To benefit from these problems, students need representational competencies: the ability to understand and appropriately use visuals. Support for representational competencies enhances students’ learning outcomes. However, it is infeasible to design representational-competency supports for entire curricula. This raises the question of whether these supports enhance future learning from novel problems. We addressed this question with an experiment with 120 undergraduates in an engineering class. All students worked with an intelligent tutoring system (ITS) that provided problems with interactive visual representations. The experiment varied which types of representational-competency supports the problems provided. We assessed future learning from a subsequent set of novel problems that involved a novel visual representation. Results show that representational-competency support can enhance future learning from the novel problems. We discuss implications for the integration of these supports in educational technologies.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	author = {Rho, Jihyun and Rau, Martina A. and Van Veen, Barry D.},
	year = {2022},
	keywords = {Future learning, Representational competencies, Visualizations},
	pages = {66--77},
}

@article{ellson_graphviz_2001,
	title = {Graphviz— {Open} {Source} {Graph} {Drawing} {Tools}},
	volume = {2265 LNCS},
	issn = {16113349},
	doi = {10.1007/3-540-45848-4_57},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Ellson, John and Gansner, Emden and Koutsofios, Lefteris and North, Stephen C. and Woodhull, Gordon},
	year = {2001},
	pages = {483--484},
}

@article{halpern_learning_2007,
	title = {Learning principles to guide pedagogy and the design of learning environments},
	journal = {Association for Psychological Science},
	author = {Halpern, D F and Graesser, A and Hakel, M},
	year = {2007},
}

@misc{kay_doing_1987,
	title = {Doing with images makes symbols},
	url = {https://archive.org/details/AlanKeyD1987},
	author = {Kay, Alan},
	year = {1987},
}

@article{pike_science_2009,
	title = {The {Science} of {Interaction}:},
	volume = {8},
	issn = {14738716},
	url = {https://journals.sagepub.com/doi/abs/10.1057/ivs.2009.22},
	doi = {10.1057/IVS.2009.22},
	abstract = {There is a growing recognition within the visual analytics community that interaction and inquiry are inextricable. It is through the interactive manipulation of a visual interface–the analytic dis...},
	number = {4},
	journal = {http://dx.doi.org/10.1057/ivs.2009.22},
	author = {Pike, William A. and Stasko, John and Chang, Remco and O'Connell, Theresa A.},
	year = {2009},
	keywords = {collaboration, interaction theory, reasoning, visual analytics},
	pages = {263--274},
}

@article{hutchins_direct_2009,
	title = {Direct {Manipulation} {Interfaces}},
	volume = {1},
	issn = {15327051},
	url = {https://www.tandfonline.com/doi/abs/10.1207/s15327051hci0104_2},
	doi = {10.1207/S15327051HCI0104_2},
	abstract = {Direct manipulation has been lauded as a good form of interface design, and some interfaces that have this property have been well received by users. In this article we seek a cognitive account of ...},
	number = {4},
	journal = {https://doi.org/10.1207/s15327051hci0104\_2},
	author = {Hutchins, Edwin L. and Hollan, James D. and Norman, Donald A.},
	year = {2009},
	pages = {311--338},
}

@book{krathwohl_taxonomy_2009,
	title = {A taxonomy for learning, teaching, and assessing: {A} revision of {Bloom}'s taxonomy of educational objectives},
	publisher = {Longman},
	author = {Krathwohl, David R and Anderson, Lorin W},
	year = {2009},
}

@inproceedings{ahmed_automatically_2013,
	title = {Automatically {Generating} {Problems} and {Solutions} for {Natural} {Deduction}},
	url = {https://www.microsoft.com/en-us/research/publication/automatically-generating-problems-solutions-natural-deduction/},
	abstract = {Natural deduction, which is a method for establishing validity of propositional type arguments, helps develop important reasoning skills and is thus a key ingredient in a course on introductory logic. We present two core components, namely solution generation and practice problem generation, for enabling computer-aided education for this important subject domain. The key enabling technology is use of an offline-computed data-structure called Universal Proof Graph (UPG) that encodes all possible applications of inference rules over all small propositions abstracted using their bitvector-based truth-table representation. This allows an efficient forward search for solution generation. More interestingly, this allows generating fresh practice problems that have given solution characteristics by performing a backward search in UPG. We obtained around 300 natural deduction problems from various textbooks. Our solution generation procedure can solve many more problems than the traditional forward-chaining based procedure, while our problem generation procedure can efficiently generate several variants with desired characteristics.},
	booktitle = {{IJCAI} '13 {Proceedings} of the {Twenty}-{Third} international joint conference on {Artificial} {Intelligence}},
	author = {Ahmed, Umair Z and Gulwani, Sumit and Karkare, Amey},
	year = {2013},
	pages = {1968--1975},
}

@article{myers_scripting_1998,
	title = {Scripting graphical applications by demonstration},
	volume = {98},
	url = {http://www.cs.cmu.edu/-barn},
	doi = {10.1145/274644.274716},
	abstract = {Writing scripts (often called `macros') can be helpful for automating repetitive tasks. Scripting facilities for text editors like Emacs and Microsoft Word have been widely used and available. However, for graphical applications, scripting has been tried many times but has never been successful. This is mainly due to the data description problem of determining how to generalize the particular objects selected at demonstration time. Previous systems have mostly tried to solve this using inferencing, but this has a number of problems, including guessing wrong and providing appropriate feedback and control to users. Therefore, the Topaz framework does not use inferencing and instead allows the user to specify how the appropriate objects should be found. This is achieved by recording changes to which objects are selected and searches for objects, so that scripts can be written with respect to the selected object, in the same way as Emacs keyboard macros. Furthermore, all values can be explicitly generalized in a number of ways, and scripts can be invoked as a result of other commands. By leveraging off of Amulet's command object architecture, programmers get these capabilities for free in their applications. The result is that much more sophisticated scripting capabilities available in applications with no extra work for programmers.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Myers, Brad A.},
	year = {1998},
	keywords = {Amulet, Command Objects, Macros, Programming by Demon-stration (PBD), Scripting, Selection, Toolkits, User Interface Development Environments},
	pages = {534--541},
}

@article{pan_human-computer_2023,
	title = {A {Human}-{Computer} {Collaborative} {Editing} {Tool} for {Conceptual} {Diagrams}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580676},
	doi = {10.1145/3544548.3580676},
	journal = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
	author = {Pan, Lihang and Yu, Chun and He, Zhe and Shi, Yuanchun},
	year = {2023},
	pages = {1--29},
}

@article{fogel_exact_2009,
	title = {On the exact maximum complexity of {Minkowski} sums of polytopes},
	volume = {42},
	issn = {01795376},
	url = {https://link.springer.com/article/10.1007/s00454-009-9159-1},
	doi = {10.1007/s00454-009-9159-1},
	abstract = {We present a tight bound On the exact maximum complexity of Minkowski sums of polytopes in ℝ3. In particular, we prove that the maximum number of facets of the Minkowski sum of k polytopes with m1,m2,...,mk facets, respectively, is bounded from above by. Given k positive integers m1,m2,...,mk, we describe how to construct k polytopes with corresponding number of facets, such that the number of facets of their Minkowski sum is exactly. When k=2, for example, the expression above reduces to 4m1m2-9m1-9m2+26. © Springer Science+Business Media, LLC 2009.},
	number = {4},
	journal = {Discrete and Computational Geometry},
	author = {Fogel, Efi and Halperin, Dan and Weibel, Christophe},
	year = {2009},
	keywords = {Complexity, Gaussian maps, Minkowski sum, Polyhedra},
	pages = {654--669},
}

@misc{allen_james_e_and_guinn_curry_i_and_horvtz_mixed-initiative_1999,
	title = {Mixed-initiative interaction},
	abstract = {Research in mixed-initiative interaction is still in its infancy, and the research problems we will face are significant. The potential impact of such systems, however, cannot be overestimated. If we are ever to build computer systems that can seamlessly interact with humans as they perform complex tasks, these systems will need to support effective mixed-initiative interaction.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Allen, James E {and} Guinn, Curry I {and} Horvtz, Eric},
	year = {1999},
	doi = {10.1109/5254.796083},
}

@book{moktefi_visual_2013,
	title = {Visual reasoning with diagrams},
	isbn = {978-3-0348-0600-8},
	abstract = {Logic, the discipline that explores valid reasoning, does not need to be limited to a specific form of representation but should include any form as long as it allows us to draw sound conclusions from given information. The use of diagrams has a long but unequal history in logic: The golden age of diagrammatic logic of the 19th century thanks to Euler and Venn diagrams was followed by the early 20th century's symbolization of modern logic by Frege and Russell. Recently, we have been witnessing a revival of interest in diagrams from various disciplines - mathematics, logic, philosophy, cognitive science, and computer science. This book aims to provide a space for this newly debated topic - the logical status of diagrams - in order to advance the goal of universal logic by exploring common and/or unique features of visual reasoning.},
	publisher = {Springer Basel},
	author = {Moktefi, Amirouche and Shin, Sun Joo},
	year = {2013},
	doi = {10.1007/978-3-0348-0600-8},
}

@article{chugh_prodirect_2016,
	title = {Prodirect manipulation: {Bidirectional} programming for the masses},
	url = {http://dx.doi.org/10.1145/2889160.2889210},
	doi = {10.1145/2889160.2889210},
	abstract = {Software interfaces today generally fall at either end of a spectrum. On one end are programmable systems, which allow expert users (i.e. programmers) to write software artifacts that describe complex abstractions, but programs are disconnected from their eventual output. On the other end are domain-specific graphical user interfaces (GUIs), which allow end users (i.e. non-programmers) to easily create varied content but present insurmountable walls when a desired feature is not built-in. Both programmatic and direct manipulation have distinct strengths, but users must typically choose one over the other or use some ad-hoc combination of systems. Our goal, put simply, is to bridge this divide. We envision novel software systems that tightly couple programmatic and direct manipulation - - a combination we dub prodirect manipulation - - for a variety of use cases. This will require advances in a broad range of software engineering disciplines, from program analysis and program synthesis technology to user interface design and evaluation. In this extended abstract, we propose two general strategies - - real-time program synthesis and domain-specific synthesis of general-purpose programs - - that may prove fruitful for overcoming the technical challenges. We also discuss metrics that will be important in evaluating the usability and utility of prodirect manipulation systems.},
	journal = {Proceedings - International Conference on Software Engineering},
	author = {Chugh, Ravi},
	year = {2016},
	keywords = {Bidirectional programming, End user programming, Human-computer interaction, Prodirect manipulation, Program synthesis},
	pages = {781--784},
}

@article{sun_application_2023,
	title = {Application of {Mathematical} {Optimization} in {Data} {Visualization} and {Visual} {Analytics}: {A} {Survey}},
	volume = {9},
	issn = {23327790},
	doi = {10.1109/TBDATA.2023.3262151},
	abstract = {Mathematical optimization is the process of determining the set of globally or locally optimal parameters in a finite or infinite search space. It has been extensively employed in the research areas of computer science, engineering, operations research, and economics. The application of mathematical optimization has also been extended to data visualization, where it can enhance data processing, structure visualization, and facilitate exploration. However, the current state of summarization in the application of mathematical optimization in data visualization remains inadequate. In this article, we review and classify the existing techniques for advanced mathematical optimization in the fields of data visualization and visual analytics. The classification is conducted based on a classical visualization pipeline, including data enhancement and transformation, representation and rendering, as well as interactive exploration and analysis. We also discuss various mathematical optimization models and their solution methods to help readers gain a better understanding of the relationship among models, visualization, and application scenarios. We additionally provide an online exploration demo, which could enable users to interactively find relevant articles. Based on the limitations and potential trends revealed in the existing literature, we define future challenges in the cross-disciplinary of mathematical optimization and data visualization.},
	number = {4},
	journal = {IEEE Transactions on Big Data},
	author = {Sun, Guodao and Zhu, Zihao and Zhang, Gefei and Xu, Chaoqing and Wang, Yunchao and Zhu, Sujia and Chang, Baofeng and Liang, Ronghua},
	year = {2023},
	keywords = {Data visualization, mathematical optimization, scientific visualization, visual analytics},
	pages = {1018--1037},
}

@article{dreyfus_exemplification_2006,
	title = {Exemplification in mathematics education},
	url = {http://users.mct.open.ac.uk/jhm3/PME30RF/PME30RFPaper.pdf},
	abstract = {There is evidence from earliest historical records that examples play a central role in both the development of mathematics as a discipline and in the teaching of mathematics. It is not surprising therefore that examples have found a place in many theories of learning mathematics. Many would argue that the use of examples is an integral part of the discipline of mathematics and not just an aid for teaching and learning. The forum takes as its background both the variety of ways in which examples are construed within different theories of learning and the contribution that attention to examples can make to the learning and teaching processes. Consequently the forum can be seen as addressing issues at the very heart of mathematics education, both drawing upon and informing many other research topics. We argue that paying attention to examples offers both a practically useful and an important theoretical perspective on the design of teaching activities, on the appreciation of learners’ experiences and on the professional development of mathematics teachers. The importance of these ideas does not actually depend on the framework used for analysing teachers’ intentions, nor on any terms used to describe forms of teaching, such as: ‘analytic-inductive’ or ‘synthetic-deductive’, ‘traditional’ or ‘reform’, ‘rote- learning’ or ‘teaching for understanding’, ‘authentic’ or ‘investigative’. Issues in exemplification are relevant to all kinds of engagement with mathematics. This paper positions exemplification on the research agenda for the community by giving a historical overview of the way examples have been seen in mathematics education; an account of associated literature; an exploration of how exemplification ‘fits’ with various perspectives on learning mathematics; accounts of issues relating to teachers’ and learners’ use of examples; and directions for future research.},
	number = {Leinhardt 2001},
	journal = {30th Conference of the International Group for the Psychology of Mathematics Education},
	author = {Dreyfus, Tommy and Mason, John and Tsamir, Pessia and Watson, Anne and Zaslavsky, Orit},
	year = {2006},
	keywords = {Aviv, Open, Oxford, Technion-Israel), Tel-Aviv},
	pages = {126--154},
}

@article{ainsworth_drawing_2011,
	title = {Drawing to learn in science},
	volume = {333},
	issn = {00368075},
	url = {https://www.science.org/doi/abs/10.1126/science.1204153},
	doi = {10.1126/SCIENCE.1204153/SUPPL_FILE/1204153.AINSWORTH.SOM.PDF},
	abstract = {Emerging research suggests drawing should be explicitly recognized as a key element in science education.},
	number = {6046},
	journal = {Science},
	author = {Ainsworth, Shaaron and Prain, Vaughan and Tytler, Russell},
	year = {2011},
	pages = {1096--1097},
}

@article{yang_automatic_2022,
	title = {Automatic {Item} {Generation} of {Figural} {Analogy} {Problems}: {A} {Review} and {Outlook}},
	url = {https://arxiv.org/abs/2201.08450v1http://arxiv.org/abs/2201.08450},
	abstract = {Figural analogy problems have long been a widely used format in human intelligence tests. In the past four decades, more and more research has investigated automatic item generation for figural analogy problems, i.e., algorithmic approaches for systematically and automatically creating such problems. In cognitive science and psychometrics, this research can deepen our understandings of human analogical ability and psychometric properties of figural analogies. With the recent development of data-driven AI models for reasoning about figural analogies, the territory of automatic item generation of figural analogies has further expanded. This expansion brings new challenges as well as opportunities, which demand reflection on previous item generation research and planning future studies. This paper reviews the important works of automatic item generation of figural analogies for both human intelligence tests and data-driven AI models. From an interdisciplinary perspective, the principles and technical details of these works are analyzed and compared, and desiderata for future research are suggested.},
	author = {Yang, Yuan and Sanyal, Deepayan and Michelson, Joel and Ainooson, James and Kunda, Maithilee},
	year = {2022},
}

@article{catley_seeing_2008,
	title = {Seeing the {Wood} for the {Trees}: {An} {Analysis} of {Evolutionary} {Diagrams} in {Biology} {Textbooks}},
	volume = {58},
	issn = {0006-3568},
	url = {https://academic.oup.com/bioscience/article/58/10/976/245951},
	doi = {10.1641/B581011},
	abstract = {This study presents the findings of an analysis of evolutionary diagrams found in 31 biology textbooks for students ranging from middle school to the undergraduate level. Since the early 1990s, cladograms have found their way into high school biology textbooks, yet we know little about their effectiveness as interpretive and instructional tools in biology education. In this article we document the frequency and types of cladograms found in 31 textbooks, and classify and survey the other types of evolutionary diagrams used in the texts. Although cladograms comprised approximately 72 percent of the diagrams overall, we found virtually no attempt to explain their structure and theoretical underpinnings. Various other noncladogenic evolutionary diagrams, comprising 28 percent of the total, were distributed throughout all textbooks studied. On the basis of our analysis, we conclude that many of these evolutionary diagrams are confusing and may reinforce alternative conceptions of macroevolution. Biology educators should therefore recognize these problems and take measures to ameliorate their effects. © 2008 American Institute of Biological Sciences.},
	number = {10},
	journal = {BioScience},
	author = {Catley, Kefyn M. and Novick, Laura R.},
	year = {2008},
	keywords = {Alternative conceptions, Biology textbooks, Cladograms, Evolutionary diagrams, Macroevolution},
	pages = {976--987},
}

@incollection{kellman_perceptual_2013,
	title = {Perceptual {Learning}, {Cognition}, and {Expertise}},
	abstract = {Recent research indicates that perceptual learning (PL)-experience-induced changes in the way perceivers extract information-plays a larger role in complex cognitive tasks, including abstract and symbolic domains, than has been understood in theory or implemented in instruction. Here, we describe the involvement of PL in complex cognitive tasks and why these connections, along with contemporary experimental and neuroscientific research in perception, challenge widely held accounts of the relationships among perception, cognition, and learning. We outline three revisions to common assumptions about these relations: 1) Perceptual mechanisms provide complex and abstract descriptions of reality; 2) Perceptual representations are often. amodal, not limited to modality-specific sensory features; and 3) Perception is selective. These three properties enable relations between perception and cognition that are both synergistic and dynamic, and they make possible PL processes that adapt information extraction to optimize task performance. While PL is pervasive in natural learning and in expertise, it has largely been neglected in formal instruction. We describe an emerging PL technology that has already produced dramatic learning gains in a variety of academic and professional learning contexts, including mathematics, science, aviation, and medical learning. © 2013 Elsevier Inc.},
	booktitle = {Psychology of {Learning} and {Motivation} - {Advances} in {Research} and {Theory}},
	publisher = {Academic Press},
	author = {Kellman, Philip J. and Massey, Christine M.},
	year = {2013},
	doi = {10.1016/B978-0-12-407237-4.00004-9},
	keywords = {Abstract ideas, Amodal perception, Cognition, Expertise, Instruction, Learning, Perception, Perceptual learning, Perceptual learning modules},
	pages = {117--165},
}

@article{hiroshi_primal-dual_2010,
	title = {A {Primal}-{Dual} {Exterior} {Point} {Method} for {Nonlinear} {Optimization}},
	volume = {20},
	issn = {10526234},
	url = {https://epubs.siam.org/doi/abs/10.1137/060676970},
	doi = {10.1137/060676970},
	abstract = {In this paper, primal-dual methods for general nonconvex nonlinear optimization problems are considered. The proposed methods are exterior point type methods that permit primal variables to violate...},
	number = {6},
	journal = {http://dx.doi.org/10.1137/060676970},
	author = {Hiroshi, Yamashita and Tanabe, Takahito},
	year = {2010},
	keywords = {49M37, 90C30, exterior point method, parametric programming, primal-dual method, warm start},
	pages = {3335--3363},
}

@article{ackermann_-contextualized_nodate,
	title = {From {De}-contextualized to {Situated} {Knowledge}: {Revisiting} {Piaget}'s {Water}-{Level} {Experiment}},
	author = {Ackermann, Edith K},
}

@article{lim_ply_2018,
	title = {Ply: {A} visual web inspector for learning from professional webpages},
	doi = {10.1145/3242587.3242660},
	abstract = {While many online resources teach basic web development, few are designed to help novices learn the CSS concepts and design patterns experts use to implement complex visual features. Professional webpages embed these design patterns and could serve as rich learning materials, but their stylesheets are complex and difficult for novices to understand. This paper presents Ply, a CSS inspection tool that helps novices use their visual intuition to make sense of professional webpages. We introduce a new visual relevance testing technique to identify properties that have visual effects on the page, which Ply uses to hide visually irrelevant code and surface unintuitive relationships between properties. In user studies, Ply helped novice developers replicate complex web features 50\% faster than those using Chrome Developer Tools, and allowed novices to recognize and explain unfamiliar concepts. These results show that visual inspection tools can support learning from complex professional webpages, even for novice developers.},
	journal = {UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
	author = {Lim, Sarah and Hibschman, Joshua and Zhang, Haoqi and O'Rourke, Eleanor},
	year = {2018},
	keywords = {Authentic learning, CSS, Developer tools, Web inspection},
	pages = {991--1002},
}

@article{andersen_trace-based_2013,
	title = {A trace-based framework for analyzing and synthesizing educational progressions},
	url = {https://dl.acm.org/doi/10.1145/2470654.2470764},
	doi = {10.1145/2470654.2470764},
	abstract = {A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods. Copyright © 2013 ACM.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Andersen, Erik and Gulwani, Sumit and Popović, Zoran},
	year = {2013},
	keywords = {Education, Execution traces, Games, Problem generation},
	pages = {773--782},
}

@article{singh_automatically_2012,
	title = {Automatically {Generating} {Algebra} {Problems}},
	volume = {26},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/8341},
	doi = {10.1609/AAAI.V26I1.8341},
	abstract = {We propose computer-assisted techniques for helping with pedagogy in Algebra. In particular, given a proof problem p (of the form “Left-hand-side-term = Right-hand-side-term”), we show how to automatically generate problems that are similar to p. We believe that such a tool can be used by teachers in making examinations where they need to test students on problems similar to what they taught in class, and by students in generating practice problems tailored to their specific needs. Our first insight is that we can generalize p syntactically to a query Q that implicitly represents a set of problems [[Q]] (which includes p). Our second insight is that we can explore the space of problems [[Q]] automatically, use classical results from polynomial identity testing to generate only those problems in [[Q]] that are correct, and then use pruning techniques to generate only unique and interesting problems. Our third insight is that with a small amount of manual tuning on the query Q, the user can interactively guide the computer to generate problems of interest to her. We present the technical details of the above mentioned steps, and also describe a tool where these steps have been implemented. We also present an empirical evaluation on a wide variety of problems from various sub-fields of algebra including polynomials, trigonometry, calculus, determinants etc. Our tool is able to generate a rich corpus of similar problems from each given problem; while some of these similar problems were already present in the textbook, several were new!},
	number = {1},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Singh, Rohit and Gulwani, Sumit and Rajamani, Sriram},
	year = {2012},
	keywords = {Aided Education, Computer, HCI, Synthesis},
	pages = {1620--1628},
}

@inproceedings{wilson_combining_2005,
	title = {Combining dynamic geometry, automated geometry theorem proving and diagrammatic proofs},
	booktitle = {Workshop on {User} {Interfaces} for {Theorem} {Provers} ({UITP})},
	author = {Wilson, Sean and Fleuriot, Jacques D},
	year = {2005},
}

@article{aleven_instruction_2016,
	title = {Instruction based on adaptive learning technologies},
	journal = {Handbook of research on learning and instruction},
	author = {Aleven, Vincent and McLaughlin, Elizabeth A and Glenn, R Amos and Koedinger, Kenneth R},
	year = {2016},
	pages = {522--560},
}

@inproceedings{dwyer_layout_2010,
	title = {Layout with circular and other non-linear constraints using {Procrustes} projection},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-11805-0_37},
	doi = {10.1007/978-3-642-11805-0_37},
	abstract = {Recent work on constrained graph layout has involved projection of simple two-variable linear equality and inequality constraints in the context of majorization or gradient-projection based optimization. While useful classes of containment, alignment and rectangular non-overlap constraints could be built using this framework, a severe limitation was that the layout used an axis-separation approach such that all constraints had to be axis aligned. In this paper we use techniques from Procrustes Analysis to extend the gradient-projection approach to useful types of non-linear constraints. The constraints require subgraphs to be locally fixed into various geometries - such as circular cycles or local layout obtained by a combinatorial algorithm (e.g. orthogonal or layered-directed) - but then allow these sub-graph geometries to be integrated into a larger layout through translation, rotation and scaling. © 2010 Springer-Verlag.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Dwyer, Tim and Robertson, George},
	year = {2010},
	pages = {393--404},
}

@article{wilson_harnessing_2003,
	title = {Harnessing curiosity to increase correctness in end-user programming},
	url = {https://dl.acm.org/doi/10.1145/642611.642665},
	doi = {10.1145/642611.642665},
	abstract = {Despite their ability to help with program correctness, assertions have been notoriously unpopular-even with professional programmers. End-user programmers seem even less likely to appreciate the value of assertions; yet end-user programs suffer from serious correctness problems that assertions could help detect. This leads to the following question: can end users be enticed to enter assertions? To investigate this question, we have devised a curiosity-centered approach to eliciting assertions from end users, built on a surprise-explain-reward strategy. Our follow-up work with end-user participants shows that the approach is effective in encouraging end users to enter assertions that help them find errors. Copyright 2003 ACM.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Wilson, Aaron and Burnett, Margaret and Beckwith, Laura and Granatir, Orion and Casburn, Ledah and Cook, Curtis and Durham, Mike and Rothermel, Gregg},
	year = {2003},
	keywords = {Assertions, Curiosity, End-user software engineering},
	pages = {305--312},
}

@article{alper_visualization_2017,
	title = {Visualization literacy at elementary school},
	volume = {2017-May},
	url = {http://dx.doi.org/10.1145/3025453.3025877},
	doi = {10.1145/3025453.3025877},
	abstract = {This work advances our understanding of children's visualization literacy, and aims to improve it with a novel approach for teaching visualization at elementary schools. We first contribute an analysis of data graphics and activities employed in grade K to 4 educational materials, and the results of a survey conducted with 16 elementary school teachers. We find that visualization education could benefit from integrating pedagogical strategies for teaching abstract concepts with established interactive visualization techniques. Building on these insights, we develop and study design principles for novel interactive teaching material aimed at increasing chil-drens visualization literacy. We specifically contribute lest la Vis, an online platform for teachers and students to respectively teach and learn about pictographs and bar charts, and report on our initial observations of its use in grades K and 2. Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Alper, Basak and Riche, Nathalie Henry and Chevalier, Fanny and Boy, Jeremy and Sezgin, Metin},
	year = {2017},
	keywords = {Qualitative analysis, Visualization literacy},
	pages = {5485--5497},
}

@article{cascaval_differentiable_2022,
	title = {Differentiable {3D} {CAD} {Programs} for {Bidirectional} {Editing}},
	volume = {41},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14476https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14476https://onlinelibrary.wiley.com/doi/10.1111/cgf.14476},
	doi = {10.1111/CGF.14476},
	abstract = {Modern CAD tools represent 3D designs not only as geometry, but also as a program composed of geometric operations, each of which depends on a set of parameters. Program representations enable meaningful and controlled shape variations via parameter changes. However, achieving desired modifications solely through parameter editing is challenging when CAD models have not been explicitly authored to expose select degrees of freedom in advance. We introduce a novel bidirectional editing system for 3D CAD programs. In addition to editing the CAD program, users can directly manipulate 3D geometry and our system infers parameter updates to keep both representations in sync. We formulate inverse edits as a set of constrained optimization objectives, returning plausible updates to program parameters that both match user intent and maintain program validity. Our approach implements an automatically differentiable domain-specific language for CAD programs, providing derivatives for this optimization to be performed quickly on any expressed program. Our system enables rapid, interactive exploration of a constrained 3D design space by allowing users to manipulate the program and geometry interchangeably during design iteration. While our approach is not designed to optimize across changes in geometric topology, we show it is expressive and performant enough for users to produce a diverse set of design variants, even when the CAD program contains a relatively large number of parameters.},
	number = {2},
	journal = {Computer Graphics Forum},
	author = {Cascaval, D. and Shalah, M. and Quinn, P. and Bodik, R. and Agrawala, M. and Schulz, A.},
	year = {2022},
	keywords = {CCS Concepts, Graphics systems and interfaces, • Computing methodologies → Shape modeling},
	pages = {309--323},
}

@book{gulwani_program_2017,
	title = {Program {Synthesis}},
	isbn = {978-1-68083-292-1},
	url = {www.nowpublishers.com;},
	author = {Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh and -Delft, Boston},
	year = {2017},
}

@article{letondal_usability_2010,
	title = {Usability requirements for interaction-oriented development tools},
	journal = {Psychology of Programming},
	author = {Letondal, Catherine and Chatty, Stéphane and Phillips, W Greg and André, Fabien and Conversy, Stéphane},
	year = {2010},
	pages = {12--26},
}

@article{moreno_decreasing_2004,
	title = {Decreasing {Cognitive} {Load} for {Novice} {Students}: {Effects} of {Explanatory} versus {Corrective} {Feedback} in {Discovery}-{Based} {Multimedia}},
	volume = {32},
	issn = {1573-1952},
	url = {https://link.springer.com/article/10.1023/B:TRUC.0000021811.66966.1d},
	doi = {10.1023/B:TRUC.0000021811.66966.1D},
	abstract = {This paper examines one of the potentialroles that software agents may have inhelping students reduce working memoryload while learning from discovery-basedmultimedia environments: providingexplanatory feedback. Two studiesexamined the guided feedbackhypothesis according to which, discoverylearning environments that use explanatoryfeedback (EF) to guide novice students inthe process of meaning making promotedeeper learning than those that presentidentical materials using correctivefeedback (CF) alone. In both experiments,the EF group produced higher transferscores, rated the computer game as morehelpful, and gave comparable interest andmotivation ratings than the CF group. Mental load rating scales providedevidence in both experiments that EF waseffective due to reductions in cognitiveload. Results support the use of agentguidance in the form of EF for novicestudents who learn with discovery-basedmultimedia games.},
	number = {1},
	journal = {Instructional Science 2004 32:1},
	author = {Moreno, Roxana},
	year = {2004},
	keywords = {Educational Psychology, Learning and Instruction, Pedagogic Psychology},
	pages = {99--113},
}

@article{gobet_chunking_2005,
	title = {Chunking models of expertise: implications for education},
	volume = {19},
	issn = {1099-0720},
	doi = {10.1002/ACP.1110},
	abstract = {Chunking models offer a parsimonious explanation of how people acquire knowledge and have been validated in domains such as expert behaviour and the acquisition of language. In this paper, we review two computational theories based on chunking mechanisms (the chunking theory and the template theory) and show what insight they offer for instruction and training. The suggested implications include the importance of perception in learning, the cost of acquiring knowledge, the significance of segmenting and ordering instruction material, the role of the variability of the instructional material in acquiring schemata, and the importance of taking individual differences into account. Copyright © 2005 John Wiley \& Sons, Ltd.},
	number = {2},
	journal = {Applied Cognitive Psychology},
	author = {Gobet, Fernand},
	year = {2005},
	pages = {183--204},
}

@article{anshengwei_augmented_2019,
	title = {Augmented example-based synthesis using relational perturbation properties},
	volume = {4},
	url = {https://dl.acm.org/doi/abs/10.1145/3371124},
	doi = {10.1145/3371124},
	abstract = {Example-based specifications for program synthesis are inherently ambiguous and may cause synthesizers to generate programs that do not exhibit intended behavior on unseen inputs. Existing synthesi...},
	number = {POPL},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {AnShengwei and SinghRishabh and MisailovicSasa and SamantaRoopsha},
	year = {2019},
	keywords = {Ambiguity-resolution, Example-based Synthesis, Program Synthesis},
}

@inproceedings{onishi_waddlewalls_2022,
	title = {{WaddleWalls}: {Room}-scale {Interactive} {Partitioning} {System} using a {Swarm} of {Robotic} {Partitions}},
	url = {https://dl.acm.org/doi/10.1145/3526113.3545615},
	doi = {10.1145/3526113.3545615},
	abstract = {We propose WaddleWalls, a room-scale interactive partitioning system using a swarm of robotic partitions that allows occupants to interactively reconfigure workspace partitions to satisfy their privacy and interaction needs. The system can automatically arrange the partitions' layout designed by the user on demand. The user specifies the target partition's position, orientation, and height using the controller's 3D manipulations. In this work, we discuss the design considerations of the interactive partition system and implement WaddleWalls' proof-of-concept prototype assembled with off-the-shelf materials. We demonstrate the functionalities of WaddleWalls through several application scenarios in an open-planned office environment. We also conduct an initial user evaluation that compares WaddleWalls with conventional wheeled partitions, finding that WaddleWalls allows effective workspace partitioning and mitigates the physical and temporal efforts needed to fulfill ad hoc social and privacy requirements. Finally, we clarify the feasibility, potential, and future challenges of WaddleWalls through an interview with experts.},
	booktitle = {{UIST} 2022 - {Proceedings} of the 35th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Onishi, Yuki and Takashima, Kazuki and Higashiyama, Shoi and Fujita, Kazuyuki and Kitamura, Yoshifumi},
	year = {2022},
	keywords = {Robotic Furniture, Shape-Changing Device, Spatial Input},
}

@inproceedings{nathan_expert_2001,
	title = {Expert blind spot: {When} content knowledge eclipses pedagogical content knowledge},
	booktitle = {Proceedings of the third international conference on cognitive science},
	author = {Nathan, Mitchell J and Koedinger, Kenneth R and Alibali, Martha W and others},
	year = {2001},
}

@article{knoblich_constraint_1999,
	title = {Constraint {Relaxation} and {Chunk} {Decomposition} in {Insight} {Problem} {Solving}},
	volume = {25},
	issn = {02787393},
	url = {/record/1999-01477-011},
	doi = {10.1037/0278-7393.25.6.1534},
	abstract = {Insight problem solving is characterized by impasses, states of mind in which the thinker does not know what to do next. The authors hypothesized that impasses are broken by changing the problem representation, and 2 hypothetical mechanisms for representational change are described: the relaxation of constraints on the solution and the decomposition of perceptual chunks. These 2 mechanisms generate specific predictions about the relative difficulty of individual problems and about differential transfer effects. The predictions were tested in 4 experiments using matchstick arithmetic problems. The results were consistent with the predictions. Representational change is a more powerful explanation for insight than alternative hypotheses, if the hypothesized change processes are specified in detail. Overcoming impasses in insight is a special case of the general need to override the imperatives of past experience in the face of novel conditions.},
	number = {6},
	journal = {Journal of Experimental Psychology: Learning Memory and Cognition},
	author = {Knoblich, Günther and Ohlsson, Stellan and Haider, Hilde and Rhenius, Detlef},
	year = {1999},
	pages = {1534--1555},
}

@article{lubinjustin_program_2020,
	title = {Program sketching with live bidirectional evaluation},
	volume = {4},
	url = {https://dl.acm.org/doi/abs/10.1145/3408991},
	doi = {10.1145/3408991},
	abstract = {We present a system called Smyth for program sketching in a typed functional language whereby the concrete evaluation of ordinary assertions gives rise to input-output examples, which are then used...},
	number = {ICFP},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {LubinJustin and CollinsNick and OmarCyrus and ChughRavi},
	year = {2020},
	keywords = {Bidirectional Evaluation, Examples, Program Synthesis, Sketches},
	pages = {29},
}

@book{carter_visual_2009,
	title = {Visual {Group} {Theory}},
	isbn = {978-0-88385-757-1},
	url = {https://www.ams.org/clrm/032},
	abstract = {This book is ideal for a student beginning a first course in group theory. It can be used in place of a traditional textbook, or as a supplement to one, but its aim is quite different than that of a traditional text. Most textbooks present the theory of groups using theorems, proofs, and examples. Their exercises teach you how to make conjectures about groups and prove or refute them. This book, however, teaches you to know groups. You will see them, experiment with them, and understand their significance. The mental library of images and intuitions you gain from reading this book will enable you to appreciate far better the facts and proofs in a traditional text.},
	publisher = {American Mathematical Society},
	author = {Carter, Nathan},
	year = {2009},
	doi = {10.1090/clrm/032},
}

@article{mccoubrie_improving_2009,
	title = {Improving the fairness of multiple-choice questions: a literature review},
	volume = {26},
	issn = {0142159X},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01421590400013495},
	doi = {10.1080/01421590400013495},
	abstract = {The ubiquity of multiple-choice questions (MCQs) results from their efficiency and hence reliability. Cognitive knowledge assessed by MCQ predicts and correlates well with overall competence and pe...},
	number = {8},
	journal = {http://dx.doi.org/10.1080/01421590400013495},
	author = {McCoubrie, Paul},
	year = {2009},
	pages = {709--712},
}

@article{myers_amulet_1997,
	title = {The amulet environment: {New} models for effective user interface software development},
	volume = {23},
	issn = {00985589},
	doi = {10.1109/32.601073},
	abstract = {The Amulet user interface development environment makes it easier for programmers to create highly-interactive, graphical user interface software for Unix, Windows and the Macintosh. Amulet uses new models for objects, constraints, animation, input, output, commands, and undo. The object system is a prototype-instance model in which there is no distinction between classes and instances or between methods and data. The constraint system allows any value of any object to be computed by arbitrary code and supports multiple constraint solvers. Animations can be attached to existing objects with a single line of code. Input from the user is handled by "interactor" objects which support reuse of behavior objects. The output model provides a declarative definition of the graphics and supports automatic refresh. Command objects encapsulate all of the information needed about operations, including support for various ways to undo them. A key feature of the Amulet design is that all graphical objects and behaviors of those objects are explicitly represented at run-time, so the system can provide a number of high-level built-in functions, including automatic display and editing of objects, and external analysis and control of interfaces. Amulet integrates these capabilities in a flexible and effective manner. © 1997 IEEE.},
	number = {6},
	journal = {IEEE Transactions on Software Engineering},
	author = {Myers, Brad A. and McDaniel, Richard G. and Miller, Robert C. and Ferrency, Alan S. and Faulring, Andrew and Kyle, Bruce D.},
	year = {1997},
	keywords = {Toolkits, User interface development environments, User interface management systems (uimss), User interface tools},
	pages = {347--365},
}

@inproceedings{albarghouthi_recursive_2013,
	title = {Recursive program synthesis},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-39799-8_67},
	doi = {10.1007/978-3-642-39799-8_67},
	abstract = {Input-output examples are a simple and accessible way of describing program behaviour. Program synthesis from input-output examples has the potential of extending the range of computational tasks achievable by end-users who have no programming knowledge, but can articulate their desired computations by describing input-output behaviour. In this paper, we present Escher, a generic and efficient algorithm that interacts with the user via input-output examples, and synthesizes recursive programs implementing intended behaviour. Escher is parameterized by the components (instructions) that can be used in the program, thus providing a generic synthesis algorithm that can be instantiated to suit different domains. To search through the space of programs, Escher adopts a novel search strategy that utilizes special data structures for inferring conditionals and synthesizing recursive procedures. Our experimental evaluation of Escher demonstrates its ability to efficiently synthesize a wide range of programs, manipulating integers, lists, and trees. Moreover, we show that Escher outperforms a state-of-the-art SAT-based synthesis tool from the literature. © 2013 Springer-Verlag.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Albarghouthi, Aws and Gulwani, Sumit and Kincaid, Zachary},
	year = {2013},
	pages = {934--950},
}

@article{moody_physics_2009,
	title = {The physics of notations: {Toward} a scientific basis for constructing visual notations in software engineering},
	volume = {35},
	issn = {00985589},
	doi = {10.1109/TSE.2009.67},
	abstract = {Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields. © 2009 IEEE.},
	number = {6},
	journal = {IEEE Transactions on Software Engineering},
	author = {Moody, Daniel},
	year = {2009},
	keywords = {Analysis, Communication, Concrete syntax, Diagrams, Modeling, Visual syntax, Visualization},
	pages = {756--779},
}

@inproceedings{wang_seeing_2021,
	title = {Seeing beyond expert blind spots: {Online} learning design for scale and qality},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445045},
	doi = {10.1145/3411764.3445045},
	abstract = {Maximizing system scalability and quality are sometimes at odds. This work provides an example showing scalability and quality can be achieved at the same time in instructional design, contrary to what instructors may believe or expect. We situate our study in the education of HCI methods, and provide suggestions to improve active learning within the HCI education community. While designing learning and assessment activities, many instructors face the choice of using open-ended or close-ended activities. Close-ended activities such as multiple-choice questions (MCQs) enable automated feedback to students. However, a survey with 22 HCI professors revealed a belief that MCQs are less valuable than open-ended questions, and thus, using them entails making a quality sacrifce in order to achieve scalability. A study with 178 students produced no evidence to support the teacher belief. This paper indicates more promise than concern in using MCQs for scalable instruction and assessment in at least some HCI domains.},
	booktitle = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xu and Rose, Carolyn and Koedinger, Kenneth R.},
	year = {2021},
	keywords = {Hci education, Instructor belief, Learning experience design, Learning@scale, Matched assessment comparison, Multiple-choice questions},
}

@article{larive_using_2004,
	title = {Using {Meta}-{Heuristics} for {Constraint}-{Based} {3D} {Objects} {Layout}},
	journal = {Intelligenza Artificiale - IA},
	author = {Larive, Mathieu and Roux, Olivier and Gaildrat, Véronique},
	year = {2004},
}

@inproceedings{nawrocki_extensible_2023,
	address = {Białystok},
	title = {An {Extensible} {User} {Interface} for {Lean} 4},
	url = {https://github.com/leanprover/vscode-},
	doi = {10.4230/LIPIcs.ITP.2023.24},
	abstract = {Contemporary proof assistants rely on complex automation and process libraries with millions of lines of code. At these scales, understanding the emergent interactions between components can be a serious challenge. One way of managing complexity, long established in informal practice, is through varying external representations. For instance, algebraic notation facilitates term-based reasoning whereas geometric diagrams invoke spatial intuition. Objects viewed one way become much simpler than when viewed differently. In contrast, modern general-purpose ITP systems usually only support limited, textual representations. Treating this as a problem of human-computer interaction, we aim to demonstrate that presentations - UI elements that store references to the objects they are displaying - are a fruitful way of thinking about ITP interface design. They allow us to make headway on two fronts - introspection of prover internals and support for diagrammatic reasoning. To this end we have built an extensible user interface for the Lean 4 prover with an associated ProofWidgets 4 library of presentation-based UI components. We demonstrate the system with several examples including type information popups, structured traces, contextual suggestions, a display for algebraic reasoning, and visualizations of red-black trees. Our interface is already part of the core Lean distribution.},
	booktitle = {14th {International} {Conference} on {Interactive} {Theorem} {Proving}},
	publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
	author = {Nawrocki, Wojciech and Ayers, Edward W. and Ebner, Gabriel},
	year = {2023},
	keywords = {Lean, human-computer interaction, user interfaces},
}

@article{tippett_what_2016,
	title = {What recent research on diagrams suggests about learning with rather than learning from visual representations in science},
	volume = {38},
	issn = {14645289},
	url = {https://www.tandfonline.com/doi/abs/10.1080/09500693.2016.1158435},
	doi = {10.1080/09500693.2016.1158435},
	abstract = {The move from learning science from representations to learning science with representations has many potential and undocumented complexities. This thematic analysis partially explores the trends of representational uses in science instruction, examining 80 research studies on diagram use in science. These studies, published during 2000-2014, were located through searches of journal databases and books. Open coding of the studies identified 13 themes, 6 of which were identified in at least 10\% of the studies: eliciting mental models, classroom-based research, multimedia principles, teaching and learning strategies, representational competence, and student agency. A shift in emphasis on learning with rather than learning from representations was evident across the three 5-year intervals considered, mirroring a pedagogical shift from science instruction as transmission of information to constructivist approaches in which learners actively negotiate understanding and construct knowledge. The themes and topics in recent research highlight areas of active interest and reveal gaps that may prove fruitful for further research, including classroom-based studies, the role of prior knowledge, and the use of eye-tracking. The results of the research included in this thematic review of the 2000-2014 literature suggest that both interpreting and constructing representations can lead to better understanding of science concepts.},
	number = {5},
	journal = {International Journal of Science Education},
	author = {Tippett, Christine D.},
	year = {2016},
	keywords = {Diagram, Language, Metasynthesis, Science literacy, Visual representation},
	pages = {725--746},
}

@article{bobek_creating_2016,
	title = {Creating visual explanations improves learning},
	volume = {1},
	issn = {23657464},
	url = {https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-016-0031-6},
	doi = {10.1186/S41235-016-0031-6/FIGURES/7},
	abstract = {Many topics in science are notoriously difficult for students to learn. Mechanisms and processes outside student experience present particular challenges. While instruction typically involves visualizations, students usually explain in words. Because visual explanations can show parts and processes of complex systems directly, creating them should have benefits beyond creating verbal explanations. We compared learning from creating visual or verbal explanations for two STEM domains, a mechanical system (bicycle pump) and a chemical system (bonding). Both kinds of explanations were analyzed for content and learning assess by a post-test. For the mechanical system, creating a visual explanation increased understanding particularly for participants of low spatial ability. For the chemical system, creating both visual and verbal explanations improved learning without new teaching. Creating a visual explanation was superior and benefitted participants of both high and low spatial ability. Visual explanations often included crucial yet invisible features. The greater effectiveness of visual explanations appears attributable to the checks they provide for completeness and coherence as well as to their roles as platforms for inference. The benefits should generalize to other domains like the social sciences, history, and archeology where important information can be visualized. Together, the findings provide support for the use of learner-generated visual explanations as a powerful learning tool.},
	number = {1},
	journal = {Cognitive Research: Principles and Implications},
	author = {Bobek, Eliza and Tversky, Barbara},
	year = {2016},
	keywords = {Complex system, Diagrammatic reasoning, Dynamic system, Learning, Process, STEM, Spatial ability, Structure, Visual communication},
	pages = {1--14},
}

@incollection{barwise_visual_2019,
	title = {Visual information and valid reasoning},
	isbn = {978-0-429-30162-9},
	url = {https://academic.oup.com/book/40816/chapter/348782106},
	booktitle = {Philosophy {And} {The} {Computer}},
	author = {Barwise, Jon and Etchemendy, John},
	year = {2019},
	doi = {10.1093/oso/9780195104271.003.0005},
	pages = {160--182},
}

@article{tversky_representing_2012,
	title = {Representing category and continuum: {Visualizing} thought},
	volume = {7352 LNAI},
	issn = {03029743},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-31223-6_8},
	doi = {10.1007/978-3-642-31223-6_8/COVER},
	abstract = {Abstract thought has roots in the spatial world. Abstractions are expressed in the ways things are arranged in the world as well as the ways people talk and gesture. Mappings to the page should be better when they are congruent, that is, when the abstract concept matches the spatial one. Congruent mappings can be revealed in people's performance and preferences. Congruence is supported here for visual representations of continuum and category. Congruently mapping a continuous concept, frequency, to a continuous visual variable and mapping a categorical concept, class inclusion, to a categorical visual variable were preferred and led to better performance than the reverse mappings. © 2012 Springer-Verlag.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Tversky, Barbara and Corter, James E. and Yu, Lixiu and Mason, David L. and Nickerson, Jeffrey V.},
	year = {2012},
	keywords = {design, diagrams, information systems, networks, reasoning, spatial metaphors},
	pages = {23--34},
}

@article{kellman_perceptual_2010,
	title = {Perceptual learning modules in mathematics: {Enhancing} students' pattern recognition, structure extraction, and fluency},
	volume = {2},
	issn = {17568757},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1756-8765.2009.01053.xhttps://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2009.01053.xhttps://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2009.01053.x},
	doi = {10.1111/j.1756-8765.2009.01053.x},
	abstract = {Learning in educational settings emphasizes declarative and procedural knowledge. Studies of expertise, however, point to other crucial components of learning, especially improvements produced by experience in the extraction of information: perceptual learning (PL). We suggest that such improvements characterize both simple sensory and complex cognitive, even symbolic, tasks through common processes of discovery and selection. We apply these ideas in the form of perceptual learning modules (PLMs) to mathematics learning. We tested three PLMs, each emphasizing different aspects of complex task performance, in middle and high school mathematics. In the MultiRep PLM, practice in matching function information across multiple representations improved students' abilities to generate correct graphs and equations from word problems. In the Algebraic Transformations PLM, practice in seeing equation structure across transformations (but not solving equations) led to dramatic improvements in the speed of equation solving. In the Linear Measurement PLM, interactive trials involving extraction of information about units and lengths produced successful transfer to novel measurement problems and fraction problem solving. Taken together, these results suggest (a) that PL techniques have the potential to address crucial, neglected dimensions of learning, including discovery and fluent processing of relations; (b) PL effects apply even to complex tasks that involve symbolic processing; and (c) appropriately designed PL technology can produce rapid and enduring advances in learning. © 2009 Cognitive Science Society, Inc.},
	number = {2},
	journal = {Topics in Cognitive Science},
	author = {Kellman, Philip J. and Massey, Christine M. and Son, Ji Y.},
	year = {2010},
	keywords = {Algebra, Expertise, Fluency, Learning technology, Mathematics instruction, Mathematics learning, Pattern recognition, Perceptual learning, perceptual learning},
	pages = {285--305},
}

@article{hottelier_programming_2014,
	title = {Programming by {Manipulation} for layout},
	url = {http://dx.doi.org/10.1145/2642918.2647378},
	doi = {10.1145/2642918.2647378},
	abstract = {We present Programming by Manipulation, a new programming methodology for specifying the layout of data visualizations, targeted at non-programmers. We address the two central sources of bugs that arise when programming with constraints: ambiguities and conflicts (inconsistencies). We rule out conflicts by design and exploit ambiguity to explore possible layout designs. Our users design layouts by highlighting undesirable aspects of a current design, effectively breaking spurious constraints and introducing ambiguity by giving some elements freedom to move or resize. Subsequently, the tool indicates how the ambiguity can be removed, by computing how the free elements can be fixed with available constraints. To support this workflow, our tool computes the ambiguity and summarizes it visually. We evaluate our work with two user-studies demonstrating that both non-programmers and programmers can effectively use our prototype. Our results suggest that our tool is 5-times more productive than direct programming with constraints.},
	journal = {UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
	author = {Hottelier, Thibaud and Bodik, Ras and Ryokai, Kimiko},
	year = {2014},
	keywords = {Constraint-based layout, Layout editing, Programming by demonstration},
	pages = {231--242},
}

@article{schnackenberg_learner_1998,
	title = {Learner preferences and achievement under differing amounts of learner practice},
	volume = {46},
	issn = {10421629},
	url = {https://link.springer.com/article/10.1007/BF02299786},
	doi = {10.1007/bf02299786},
	abstract = {This study examined the effects of program mode (i.e., a lean program version containing a basic amount of learner practice vs. a full mode containing expanded practice) and learner preference (matched or unmatched) for amount of practice on the achievement, time-in-program, and attitudes of university undergraduate students. Subjects completed a 10-item Likert-type prequestionnaire to indicate the amount of practice they preferred, then were randomly assigned to either the type of program they preferred or to the opposite type. Subjects who used the full version of the instructional program scored significantly higher on the posttest than those who used the lean version. Matching subjects to their preferred amount of practice did not yield a significant achievement difference over assigning subjects to their less-preferred amount. Subjects preferred the lean version of the program over the full one, even though the full version produced better test performance.},
	number = {2},
	journal = {Educational Technology Research and Development},
	author = {Schnackenberg, Heidi L. and Sullivan, Howard J. and Leader, Lars F. and Jones, Elizabeth E.K.},
	year = {1998},
	keywords = {Educational Technology, Learning and Instruction},
	pages = {5--16},
}

@article{fogh_explorable_2018,
	title = {Explorable {Explanations}: {What} are they? {What} do they explain? {How} do we work with them? {Let}\&apos;s find out},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:mau:diva-23326},
	abstract = {In this paper, the author examines the concept of explorable explanations. It has emerged as a genre of educational software within the last 7 years, yet descriptions of it are vague at best. The a ...},
	author = {Fogh, Jesper Hyldahl},
	year = {2018},
	keywords = {Engineering and Technology, Teknik och teknologier, educational software, interaction design, neural networks},
}

@article{chugh_programmatic_2016,
	title = {Programmatic and direct manipulation, together at last},
	volume = {13-17-June},
	doi = {10.1145/2908080.2908103},
	abstract = {Direct manipulation interfaces and programmatic systems have distinct and complementary strengths. The former provide intuitive, immediate visual feedback and enable rapid prototyping, whereas the latter enable complex, reusable abstractions. Unfortunately, existing systems typically force users into just one of these two interaction modes. We present a system called SKETCH-N-SKETCH that integrates programmatic and direct manipulation for the particular domain of Scalable Vector Graphics (SVG). In SKETCH-N-SKETCH, the user writes a program to generate an output SVG canvas. Then the user may directly manipulate the canvas while the system immediately infers a program update in order to match the changes to the output, a workflow we call live synchronization. To achieve this, we propose (i) a technique called trace-based program synthesis that takes program execution history into account in order to constrain the search space and (ii) heuristics for dealing with ambiguities. Based on our experience with examples spanning 2,000 lines of code and from the results of a preliminary user study, we believe that SKETCH-N-SKETCH provides a novel workflow that can augment traditional programming systems. Our approach may serve as the basis for live synchronization in other application domains, as well as a starting point for yet more ambitious ways of combining programmatic and direct manipulation.},
	journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
	author = {Chugh, Ravi and Hempel, Brian and Spradlin, Mitchell and Albers, Jacob},
	year = {2016},
	keywords = {Prodirect manipulation, SVG, Sketch-n-sketch},
	pages = {341--354},
}

@article{sevimli_exemplification_2022,
	title = {Exemplification process in online education: a longitudinal study of mathematics teachers},
	issn = {15731855},
	url = {https://link.springer.com/article/10.1007/s10984-022-09440-y},
	doi = {10.1007/s10984-022-09440-y},
	abstract = {The examples used in the teaching–learning process of mathematics have a crucial role in fostering conceptual understanding, and some variables can affect instructors' qualified example usage. This longterm study focused on mathematics teachers’ exemplification process in face-to-face and online learning environments. In this regard, the change in examples used by mathematics teachers were evaluated in terms of content preparation and presentation during the shift from face-to-face lectures to online classes. A longitudinal design was used in the study and the teaching processes of 14 middle-school mathematics teachers were observed over two semesters. Observation notes, course documents, and semi-structured interview data were analyzed, and content analysis findings were presented through descriptive statistics in order to compare content preferences in two different learning environments. The use of worked examples decreased, while the use of conceptual examples increased with the shift from face-to-face lectures to online classes. Also the length of time devoted to examples in online classes decreased, and examples were more teacher-centered. The interview revealed that mathematics teachers need support in terms of example preparation and presentation aspects in online learning environments. The other technological-pedagogical competencies that teachers might need to choose qualified examples in different teaching–learning environments are discussed in the light of relevant literature.},
	journal = {Learning Environments Research},
	author = {Sevimli, Eyüp},
	year = {2022},
	keywords = {Exemplification, Mathematics teachers, Online education, Teaching practices},
	pages = {1--24},
}

@article{weitzman_automatic_1994,
	title = {Automatic presentation of multimedia documents using relational grammars},
	doi = {10.1145/192593.192718},
	abstract = {This paper describes an approach to the automatic presentation of multimedia documents based on parsing and syntax-directed translation using Relational Grammars. This translation is followed by a constraint solving mechanism to create the final layout. Grammatical rules provide the mechanism for mapping from a representation of the content of a presentation to forms that specify the media objects to be realized. These realization forms include sets of spatial and temporal constraints between elements of the presentation. Individual grammars encapsulate the "look and feel" of a presentation and can be used as generators of that style. By making the grammars sensitive to the requirements of the output medium, parsing can introduce flexibility into the information realization process.},
	journal = {Proceedings of the 2nd ACM International Conference on Multimedia, MULTIMEDIA 1994},
	author = {Weitzman, Louis and Wittenburg, Kent},
	year = {1994},
	keywords = {Automatic design, Constraints, Grammar-directed design, Parsing, Relational grammars, Visual languages},
	pages = {443--451},
}

@article{blum_combining_1998,
	title = {Combining labeled and unlabeled data with co-training},
	doi = {10.1145/279943.279962},
	abstract = {The problem of using a large unlabeled sample is considered to boost the performance of a learning algorithm when only a small set of labeled examples is available. In particular, a problem setting is considered to classify web pages, in which the description of each example can be partitioned into two distinct views. A PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data are presented. Also, empirical results on real web-page is giving, indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice.},
	journal = {Proceedings of the Annual ACM Conference on Computational Learning Theory},
	author = {Blum, Avrim and Mitchell, Tom},
	year = {1998},
	pages = {92--100},
}

@article{gleicher_drawing_1994,
	title = {Drawing with constraints},
	volume = {11},
	issn = {1432-2315},
	url = {https://link.springer.com/article/10.1007/BF01900698},
	doi = {10.1007/BF01900698},
	abstract = {The success of constraint-based approaches to drawing has been limited by difficulty in creating constraints, solving them, and presenting them to users. In this paper, we discuss techniques used in theBriar drawing program to address all of these issues. Briar's approach separates the problem of initially establishing constraints from the problem of maintaining them during subsequent editing. We describe how non-constraint-based drawing tools can be augmented to specify constraints in addition to positions. These constraints are then maintained as the user drags the model, which allows the user to explore configurations consistent with the constraints. Visual methods are provided for displaying and editing the constraints.},
	number = {1},
	journal = {The Visual Computer 1994 11:1},
	author = {Gleicher, Michael and Witkin, Andrew},
	year = {1994},
	keywords = {Artificial Intelligence, Computer Graphics, Computer Science, Image Processing and Computer Vision, general},
	pages = {39--51},
}

@article{ni_developing_2022,
	title = {Developing conceptual understanding through interactive diagramming},
	abstract = {“Mental pictures” and “visual intuition” capture how people make sense of ab- stract concepts and see solutions to hard problems in a visual way. Learning research suggests that visual representations of knowledge are powerful tools for thought. Visual representations like diagrams enable more robust learning and flexible problem solving. Existing diagramming tools often require hours of low-level tweaking of geometric primitives and do not capture the core task of diagramming: representing ideas visually. PENROSE is a diagramming platform that explicitly encodes visual representations in domain-specific languages. In this thesis proposal, I argue that this explicit encoding can be leveraged to (1) reduce the programming effort of pro- ducing diagrammatic problems at scale and (2) simplify the workflow of authoring interactive diagrams. The resulting diagrams also carry rich semantics, and I’ll dis- cuss how to use them to (3) provide useful, automated feedback to students.},
	author = {Ni, Wode},
	year = {2022},
	pages = {24},
}

@article{koedinger_learning_2015,
	title = {Learning is not a spectator sport: {Doing} is better than watching for learning from a {MOOC}},
	url = {https://dl.acm.org/doi/10.1145/2724660.2724681},
	doi = {10.1145/2724660.2724681},
	abstract = {The printing press long ago and the computer today have made widespread access to information possible. Learning theorists have suggested, however, that mere information is a poor way to learn. Instead, more effective learning comes through doing. While the most popularized element of today's MOOCs are the video lectures, many MOOCs also include interactive activities that can afford learning by doing. This paper explores the learning benefits of the use of informational assets (e.g., videos and text) in MOOCs, versus the learning by doing opportunities that interactive activities provide. We find that students doing more activities learn more than students watching more videos or reading more pages. We estimate the learning benefit from extra doing (1 SD increase) to be more than six times that of extra watching or reading. Our data, from a psychology MOOC, is correlational in character, however we employ causal inference mechanisms to lend support for the claim that the associations we find are causal.},
	journal = {L@S 2015 - 2nd ACM Conference on Learning at Scale},
	author = {Koedinger, Kenneth R. and McLaughlin, Elizabeth A. and Kim, Jihee and Jia, Julianna Zhuxin and Bier, Norman L.},
	year = {2015},
	keywords = {Course effectiveness, Learning by doing, Learning prediction, MOOCs, OER, Open education},
	pages = {111--120},
}

@article{goldstone_education_2010,
	title = {The {Education} of {Perception}},
	volume = {2},
	issn = {1756-8765},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1756-8765.2009.01055.xhttps://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2009.01055.xhttps://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2009.01055.x},
	doi = {10.1111/J.1756-8765.2009.01055.X},
	abstract = {Although the field of perceptual learning has mostly been concerned with low- to middle-level changes to perceptual systems due to experience, we consider high-level perceptual changes that accompany learning in science and mathematics. In science, we explore the transfer of a scientific principle (competitive specialization) across superficially dissimilar pedagogical simulations. We argue that transfer occurs when students develop perceptual interpretations of an initial simulation and simply continue to use the same interpretational bias when interacting with a second simulation. In arithmetic and algebraic reasoning, we find that proficiency in mathematics involves executing spatially explicit transformations to notational elements. People learn to attend mathematical operations in the order in which they should be executed, and the extent to which students employ their perceptual attention in this manner is positively correlated with their mathematical experience. For both science and mathematics, relatively sophisticated performance is achieved not by ignoring perceptual features in favor of deep conceptual features, but rather by adapting perceptual processing so as to conform with and support formally sanctioned responses. These "rigged-up perceptual systems" offer a promising approach to educational reform. © 2009 Cognitive Science Society, Inc.},
	number = {2},
	journal = {Topics in Cognitive Science},
	author = {Goldstone, Robert L. and Landy, David H. and Son, Ji Y.},
	year = {2010},
	keywords = {Complex systems, Education, Mathematical reasoning, Perceptual learning, Scientific reasoning},
	pages = {265--284},
}

@article{gierl_role_2012,
	title = {The {Role} of {Item} {Models} in {Automatic} {Item} {Generation}},
	volume = {12},
	issn = {15305058},
	url = {https://www.tandfonline.com/doi/abs/10.1080/15305058.2011.635830},
	doi = {10.1080/15305058.2011.635830},
	abstract = {Automatic item generation represents a relatively new but rapidly evolving research area where cognitive and psychometric theories are used to produce tests that include items generated using computer technology. Automatic item generation requires two steps. First, test development specialists create item models, which are comparable to templates or prototypes, that highlight the features or elements in the assessment task that must be manipulated. Second, these item model elements are manipulated to generate new items with the aid of computer-based algorithms. With this two-step process, hundreds or even thousands of new items can be created from a single item model. The purpose of our article is to describe seven different but related topics that are central to the development and use of item models for automatic item generation. We start by defining item model and highlighting some related concepts; we describe how item models are developed; we present an item model taxonomy; we illustrate how item models can be used for automatic item generation; we outline some benefits of using item models; we introduce the idea of an item model bank; and finally, we demonstrate how statistical procedures can be used to estimate the parameters of the generated items without the need for extensive field or pilot testing. © 2012 Copyright Taylor and Francis Group, LLC.},
	number = {3},
	journal = {International Journal of Testing},
	author = {Gierl, Mark J. and Lai, Hollis},
	year = {2012},
	keywords = {automatic item generation, computer based testing, test development},
	pages = {273--298},
}

@article{embretson_cognitive_1998,
	title = {A {Cognitive} {Design} {System} {Approach} to {Generating} {Valid} {Tests}: {Application} to {Abstract} {Reasoning}},
	volume = {3},
	issn = {1082989X},
	doi = {10.1037/1082-989X.3.3.380},
	abstract = {The actual impact of cognitive theory on testing contrasts sharply with its potential impact, which suggests some deep incompatibilities between the areas. This article describes and illustrates a cognitive design system approach that centralizes cognitive theory in developing valid tests. To resolve incompatibilities between cognitive and testing, the cognitive design system approach includes both conceptual and procedural frameworks. To illustrate the cognitive design approach, an item bank for measuring abstract reasoning was generated from cognitive theory (i.e., P. A. Carpenter, M. A. Just, \& P. Shell's, 1990, processing theory). The construct validity of the generating item bank was strongly supported by several studies from the cognitive design system approach.},
	number = {3},
	journal = {Psychological Methods},
	author = {Embretson, Susan E.},
	year = {1998},
	pages = {380--396},
}

@article{marton_sameness_2006,
	title = {Sameness and {Difference} in {Transfer}},
	volume = {15},
	issn = {10508406},
	url = {https://www.tandfonline.com/doi/abs/10.1207/s15327809jls1504_3},
	doi = {10.1207/S15327809JLS1504_3},
	abstract = {Discussions about transfer have mainly dealt with how people manage to do something in a situation thanks to having done something similar in a previous situation. From an educational point of view...},
	number = {4},
	journal = {Journal of the Learning Sciences},
	author = {Marton, Ference},
	year = {2006},
	pages = {499--535},
}

@article{beaudouin-lafon_mathmap_2021,
	title = {{MathMap}: {Supporting} {Exploratory} {Problem} {Solving} with {Algebra}},
	url = {https://doi.org/10.1145/3474349.3480226},
	doi = {10.1145/3474349.3480226},
	abstract = {Tools that support problem-solving in mathematics tend to focus on reaching a solution directly. In practice, it is common to go down paths that do not obviously lead to the solution. This part of the process should be reflected in the tools students use to help them better learn problem-solving strategies. MathMap is an application designed to help high-school students learn how to solve algebraic problems by encouraging them to use multiple strategies, maintain the history of previous attempts, and allows them to meaningfully compare methods with other students.},
	journal = {Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology, UIST 2021},
	author = {Beaudouin-Lafon, Matthew and Xia, Haijun},
	year = {2021},
	keywords = {Computer Algebra Systems, Exploration, Math},
	pages = {47--50},
}

@article{liu_mental_2010,
	title = {Mental models, visual reasoning and interaction in information visualization: {A} top-down perspective},
	volume = {16},
	issn = {10772626},
	doi = {10.1109/TVCG.2010.177},
	abstract = {Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development. © 2006 IEEE.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Zhicheng and Stasko, John},
	year = {2010},
	keywords = {Mental model, distributed cognition, information visualization, interaction, model-based reasoning, theory},
	pages = {999--1008},
}

@inproceedings{satyanarayan_declarative_2014,
	address = {New York, NY, USA},
	title = {Declarative interaction design for data visualization},
	url = {http://dx.doi.org/10.1145/2642918.2647360},
	doi = {10.1145/2642918.2647360},
	abstract = {Declarative visualization grammars can accelerate development, facilitate retargeting across platforms, and allow language-level optimizations. However, existing declarative visualization languages are primarily concerned with visual encoding, and rely on imperative event handlers for interactive behaviors. In response, we introduce a model of declarative interaction design for data visualizations. Adopting methods from reactive programming, we model low-level events as composable data streams from which we form higher-level semantic signals. Signals feed predicates and scale inversions, which allow us to generalize interactive selections at the level of item geometry (pixels) into interactive queries over the data domain. Production rules then use these queries to manipulate the visualization's appearance. To facilitate reuse and sharing, these constructs can be encapsulated as named interactors: standalone, purely declarative specifications of interaction techniques. We assess our model's feasibility and expressivity by instantiating it with extensions to the Vega visualization grammar. Through a diverse range of examples, we demonstrate coverage over an established taxonomy of visualization interaction techniques.},
	booktitle = {{UIST} 2014 - {Proceedings} of the 27th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Satyanarayan, Arvind and Wongsuphasawat, Kanit and Heer, Jeffrey},
	year = {2014},
	keywords = {Declarative design, Interaction design, Toolkits, Visualization},
	pages = {669--678},
}

@article{clark_dual_1991,
	title = {Dual coding theory and education},
	volume = {3},
	issn = {1573-336X},
	doi = {10.1007/BF01320076},
	abstract = {Dual coding theory (DCT) explains human behavior and experience in terms of dynamic associative processes that operate on a rich network of modality-specific verbal and nonverbal (or imagery) representations. We first describe the underlying premises of the theory and then show how the basic DCT mechanisms can be used to model diverse educational phenomena. The research demonstrates that concreteness, imagery, and verbal associative processes play major roles in various educational domains: the representation and comprehension of knowledge, learning and memory of school material, effective instruction, individual differences, achievement motivation and test anxiety, and the learning of motor skills. DCT also has important implications for the science and practice of educational psychology — specifically, for educational research and teacher education. We show not only that DCT provides a unified explanation for diverse topics in education, but also that its mechanistic framework accommodates theories cast in terms of strategies and other high-level psychological processes. Although much additional research needs to be done, the concrete models that DCT offers for the behavior and experience of students, teachers, and educational psychologists further our understanding of educational phenomena and strengthen related pedagogical practices.},
	number = {3},
	journal = {Educational Psychology Review 1991 3:3},
	author = {Clark, James M. and Paivio, Allan},
	year = {1991},
	keywords = {Child and School Psychology, Educational Psychology, Learning and Instruction},
	pages = {149--210},
}

@article{scaife_external_1996,
	title = {External cognition: how do graphical representations work?},
	volume = {45},
	issn = {1071-5819},
	doi = {10.1006/IJHC.1996.0048},
	abstract = {Advances in graphical technology have now made it possible for us to interact with information in innovative ways, most notably by exploring multimedia environments and by manipulating three-dimensional virtual worlds. Many benefits have been claimed for this new kind of interactivity, a general assumption being that learning and cognitive processing are facilitated. We point out, however, that little is known about the cognitive value of any graphical representations, be they good old-fashioned (e.g. diagrams) or more advanced (e.g. animations, multimedia, virtual reality). In our paper, we critique the disparate literature on graphical representations, focusing on four representative studies. Our analysis reveals a fragmented and poorly understood account of how graphical representations work, exposing a number of assumptions and fallacies. As an alternative we propose a new agenda for graphical representation research. This builds on the nascent theoretical approach within cognitive science that analyses the role played by external representations in relation to internal mental ones. We outline some of the central properties of this relationship that are necessary for the processing of graphical representations. Finally, we consider how this analysis can inform the selection and design of both traditional and advanced forms of graphical technology. © 1996 Academic Press Limited.},
	number = {2},
	journal = {International Journal of Human-Computer Studies},
	author = {Scaife, Mike and Rogers, Yvonne},
	year = {1996},
	pages = {185--213},
}

@inproceedings{he_parameterized_2022,
	title = {Parameterized {Interior} {Floor} {Plan} {Design} {Based} on {Differentiable} {Renderer}},
	url = {https://link.springer.com/chapter/10.1007/978-981-19-6226-4_14},
	doi = {10.1007/978-981-19-6226-4_14},
	abstract = {Creating floor plans for indoor scenes is a fundamental task of architecture and interior design. Since a high-quality floor plan requires proper space division and location distribution for rooms inside the scene, such a task always require professional designers to spend huge efforts and workloads. In this paper, we intend to leverage the artificial intelligence method to relieve the manual work of interior floor plan design. Specifically, we employ the differentiable renderer, which is an optimizer that adjusts the parameters of certainly given mesh primitives. The optimization process is under the constraints of the input outer boundary, overlap, and weights, to ensure the design is parameterized, and suitable for interior floor plans with plausible space division. We also provide post-processing to refine the optimized mesh primitives and convert them to an interior floor plan. We conduct both ablation and controlled experiments to verify the effectiveness of our method in floor plan design.},
	booktitle = {Lecture {Notes} in {Electrical} {Engineering}},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	author = {He, Shuhan and Fu, Qiang and Li, Xueming},
	year = {2022},
	keywords = {Computer-aided design, Differentiable renderer, Floor plan synthesis},
	pages = {132--141},
}

@article{imhof_positioning_1975,
	title = {Positioning names on maps},
	volume = {2},
	issn = {00941689},
	url = {https://www.tandfonline.com/doi/abs/10.1559/152304075784313304},
	doi = {10.1559/152304075784313304},
	abstract = {Prof. Dr. Eduard Imhof, dean of European cartographers, has been an astute student of the esthetic-scientific characteristics of the cartographic method. In this paper published 13 years ago, he draws upon his long experience in map design and production to formulate a series of precepts about positioning or locating the lettering on maps in relation to the various functional aspects of the map and the individual named features. Noting that legibility and clarity of the map depend on good name positioning—each name having only one optimum position on the map—he encourages the use of a graphic draft of lettering to determine this position. © 1975 Taylor \& Francis Group, LLC.},
	number = {2},
	journal = {American Cartographer},
	author = {Imhof, Eduard},
	year = {1975},
	pages = {128--144},
}

@inproceedings{cohen_designing_2019,
	title = {Designing declarative language tutorials: {A} guided and individualized approach},
	doi = {10.4230/OASIcs.PLATEAU.2019.4},
	abstract = {The ability to declare what a program should include rather than how these features should be implemented makes declarative languages very useful in many visual output programs. The wide-ranging uses of these programs, in domains ranging from architecture to web programming to data visualization, encourages us to find an effective method to teach them. Traditional tutorial systems are usually non-interactive and have a gap between the learning and application. This can leave the user frustrated without a way to move forward in the learning process. A general lack of guidance can lead the student down an incorrect path. To prevent these difficulties, we propose a guided tour followed by novel question types that both direct the student’s learning and creates a focused environment to practice individual skills. Lastly, we propose a study to test the hypothesis that this tutorial is quicker to complete and results in a greater understanding of the declarative language.},
	booktitle = {10th {Workshop} on {Evaluation} and {Usability} of {Programming} {Languages} and {Tools} ({PLATEAU} 2019)},
	author = {Cohen, A.K. and Ni, W. and Sunshine, J.},
	year = {2019},
	keywords = {Declarative programming, Programming language tutorial, Visualizations},
}

@article{wang_upgrade_2019,
	title = {Upgrade: {Sourcing} student open-ended solutions to create scalable learning opportunities},
	url = {https://doi.org/10.1145/3330430.3333614},
	doi = {10.1145/3330430.3333614},
	abstract = {In schools and colleges around the world, open-ended homework assignments are commonly used. However, such assignments require substantial instructor effort for grading, and tend not to support opportunities for repeated practice. We propose UpGrade, a novel learnersourcing approach that generates scalable learning opportunities using prior student solutions to open-ended problems. UpGrade creates interactive questions that offer automated and real-time feedback, while enabling repeated practice. In a two-week experiment in a college-level HCI course, students answering UpGrade-created questions instead of traditional open-ended assignments achieved indistinguishable learning outcomes in {\textasciitilde}30\% less time. Further, no manual grading effort is required. To enhance quality control, UpGrade incorporates a psychometric approach using crowd workers’ answers to automatically prune out low quality questions, resulting in a question bank that exceeds reliability standards for classroom use.},
	journal = {Proceedings of the 6th 2019 ACM Conference on Learning at Scale, L@S 2019},
	author = {Wang, Xu and Talluri, Srinivasa Teja and Rose, Carolyn and Koedinger, Kenneth},
	year = {2019},
	keywords = {Crowdsourcing, Deliberate practice, Multiple-choice question, Online education, Open-ended assignment},
}

@book{mayer_multimedia_2020,
	title = {Multimedia {Learning}},
	isbn = {978-1-316-94135-5},
	abstract = {Advances in computer graphic technologies have inspired new efforts to understand the potential of multimedia instruction as a means of promoting human learning. In Multimedia Learning, Third Edition, Richard E. Mayer takes an evidence-based approach to improving education using well-designed multimedia instruction. He reviews 15 principles of multimedia instructional design that are based on more than 200 experimental research studies and grounded in a cognitive theory of how people learn from words and graphics. The result is the latest instalment of what Mayer calls the Cognitive Theory of Multimedia Learning, a theory introduced in previous editions of Multimedia Learning and in The Cambridge Handbook of Multimedia Learning, Second Edition. This edition provides an up-to-date and systematic summary of research studies on multimedia learning, supplemented with complementary evidence from around the globe. It is well-suited to graduate and undergraduate courses in psychology, education, computer science, communication, instructional design, and game design.},
	publisher = {Cambridge University Press},
	author = {Mayer, Richard},
	year = {2020},
	doi = {10.1017/9781316941355},
}

@article{cox_representation_1999,
	title = {Representation construction, externalised cognition and individual differences},
	volume = {9},
	issn = {0959-4752},
	doi = {10.1016/S0959-4752(98)00051-6},
	abstract = {This article discusses the cognitive differences between reasoning with self-constructed external representations (ERs) and reasoning with presented representations (e.g. textbook diagrams). Examples of ERs produced by subjects solving reasoning problems are provided. It is argued that effective reasoning with ERs involves a three-way interaction between (a) the cognitive and semantic properties of the representation; (b) the match between the demands of the task and the type of information read-off afforded by the representation and (c) the effects of within-subject factors (e.g. prior knowledge, cognitive style). It is suggested that providing direct instruction in the use of ERs could usefully address each factor.},
	number = {4},
	journal = {Learning and Instruction},
	author = {Cox, Richard},
	year = {1999},
	keywords = {Diagrammatic reasoning, External representations, Human problem solving, Individual differences},
	pages = {343--363},
}

@article{matzen_recreating_2010,
	title = {Recreating raven's: {Software} for systematically generating large numbers of raven-like matrix problems with normed properties},
	volume = {42},
	issn = {1554351X},
	doi = {10.3758/BRM.42.2.525},
	abstract = {Raven's Progressive Matrices is a widely used test for assessing intelligence and reasoning ability (Raven, Court, \& Raven, 1998). Since the test is nonverbal, it can be applied to many different populations and has been used all over the world (Court \& Raven, 1995). However, relatively few matrices are in the sets developed by Raven, which limits their use in experiments requiring large numbers of stimuli. For the present study, we analyzed the types of relations that appear in Raven's original Standard Progressive Matrices (SPMs) and created a software tool that can combine the same types of relations according to parameters chosen by the experimenter, to produce very large numbers of matrix problems with specific properties. We then conducted a norming study in which the matrices we generated were compared with the actual SPMs. This study showed that the generated matrices both covered and expanded on the range of problem difficulties provided by the SPMs. © 2010 The Psychonomic Society, Inc.},
	number = {2},
	journal = {Behavior Research Methods},
	author = {Matzen, Laura E. and Benz, Zachary O. and Dixon, Kevin R. and Posey, Jamie and Kroger, James K. and Speed, Ann E.},
	year = {2010},
	pages = {525--541},
}

@techreport{pashler_organizing_2007,
	address = {Washington, DC},
	title = {Organizing {Instruction} and {Study} to {Improve} {Student} {Learning}},
	institution = {NCER, IES,, U.S. Department of Education},
	author = {Pashler, Harold and Bain, Patrice M and Bottge, Brian A and Graesser, Arthur and Koedinger, Kenneth and McDaniel, Mark and Metcalfe, Janet},
	year = {2007},
}

@article{dix_starting_1998,
	title = {Starting simple - {Adding} value to static visualisation through simple interaction},
	url = {http://www.hiraeth.com/alan/papers/simple98/},
	doi = {10.1145/948496.948514},
	abstract = {Interactive visualisation has been one of the most exciting areas in HCI over recent years. The key term here is 'interactive', and in this paper we assert that virtually any static representation can become more powerful by the addition of simple interactive elements. This is demonstrated by adding interactivity to standard representations including stacked histograms, pie charts and scatter plots. We show how adding interactivity can help resolve many of the trade-offs inherent in static visualisations by allowing multiple options to be available and most importantly for them to be interactively related. Many years of creativity and effort have been invested in traditional generic and bespoke visualisations. Adding interactivity leverages this accumulated experience, but also adds an extra dimension.},
	journal = {Proceedings of the Workshop on Advanced Visual Interfaces AVI},
	author = {Dix, Alan and Ellis, Geoffrey},
	year = {1998},
	keywords = {Information visualisation, Interactive graphics, Visual interaction},
	pages = {124--134},
}

@article{weitekamp_interaction_2020,
	title = {An {Interaction} {Design} for {Machine} {Teaching} to {Develop} {AI} {Tutors}},
	url = {http://dx.doi.org/10.1145/3313831.3376226},
	doi = {10.1145/3313831.3376226},
	abstract = {Intelligent tutoring systems (ITSs) have consistently been shown to improve the educational outcomes of students when used alone or combined with traditional instruction. However, building an ITS is a time-consuming process which requires specialized knowledge of existing tools. Extant authoring methods, including the Cognitive Tutor Authoring Tools' (CTAT) example-tracing method and SimStudent's Authoring by Tutoring, use programming-by-demonstration to allow authors to build ITSs more quickly than they could by hand programming with model-tracing. Yet these methods still suffer from long authoring times or difficulty creating complete models. In this study, we demonstrate that Simulated Learners built with the Apprentice Learner (AL) Framework can be combined with a novel interaction design that emphasizes model transparency, input flexibility, and problem solving control to enable authors to achieve greater model completeness in less time than existing authoring methods.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Weitekamp, Daniel and Harpstead, Erik and Koedinger, Ken R.},
	year = {2020},
}

@article{rohrer_shuffling_2007,
	title = {The shuffling of mathematics problems improves learning},
	volume = {35},
	issn = {00204277},
	url = {https://link.springer.com/article/10.1007/s11251-007-9015-8},
	doi = {10.1007/s11251-007-9015-8},
	abstract = {In most mathematics textbooks, each set of practice problems is comprised almost entirely of problems corresponding to the immediately previous lesson. By contrast, in a small number of textbooks, the practice problems are systematically shuffled so that each practice set includes a variety of problems drawn from many previous lessons. The standard and shuffled formats differ in two critical ways, and each was the focus of an experiment reported here. In Experiment 1, college students learned to solve one kind of problem, and subsequent practice problems were either massed in a single session (as in the standard format) or spaced across multiple sessions (as in the shuffled format). When tested 1 week later, performance was much greater after spaced practice. In Experiment 2, students first learned to solve multiple types of problems, and practice problems were either blocked by type (as in the standard format) or randomly mixed (as in the shuffled format). When tested 1 week later, performance was vastly superior after mixed practice. Thus, the results of both experiments favored the shuffled format over the standard format. © 2007 Springer Science+Business Media, Inc.},
	number = {6},
	journal = {Instructional Science},
	author = {Rohrer, Doug and Taylor, Kelli},
	year = {2007},
	keywords = {Block, Distribute, Interleave, Mass, Mathematics, Mix, Practice, Spacing},
	pages = {481--498},
}

@article{mesbah_automated_2012,
	title = {Automated analysis of {CSS} rules to support style maintenance},
	issn = {02705257},
	doi = {10.1109/ICSE.2012.6227174},
	abstract = {CSS is a widely used language for describing the presentation semantics of HTML elements on the web. The language has a number of characteristics, such as inheritance and cascading order, which makes maintaining CSS code a challenging task for web developers. As a result, it is common for unused rules to be accumulated over time. Despite these challenges, CSS analysis has not received much attention from the research community. We propose an automated technique to support styling code maintenance, which (1) analyzes the runtime relationship between the CSS rules and DOM elements of a given web application (2) detects unmatched and ineffective selectors, overridden declaration properties, and undefined class values. Our technique, implemented in an open source tool called Cilla, has a high precision and recall rate. The results of our case study, conducted on fifteen open source and industrial web-based systems, show an average of 60\% unused CSS selectors in deployed applications, which points to the ubiquity of the problem. © 2012 IEEE.},
	journal = {Proceedings - International Conference on Software Engineering},
	author = {Mesbah, Ali and Mirshokraie, Shabnam},
	year = {2012},
	keywords = {CSS, Cascading style sheets, dynamic analysis, software maintenance, web applications},
	pages = {408--418},
}

@article{mayer_mikael_bidirectional_2018,
	title = {Bidirectional evaluation with direct manipulation},
	volume = {2},
	url = {https://dl.acm.org/doi/abs/10.1145/3276497},
	doi = {10.1145/3276497},
	abstract = {We present an evaluation update (or simply, update) algorithm for a full-featured functional programming language, which synthesizes program changes based on output changes. Intuitively, the update...},
	number = {OOPSLA},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Mayer Mikaël and Kuncak Viktor and Chugh Ravi},
	year = {2018},
	keywords = {Bidirectional Programming, Direct Manipulation, Sketch-n-Sketch},
	pages = {1--28},
}

@misc{belouadi_automatikz_2024,
	title = {{AutomaTikZ}: {Text}-{Guided} {Synthesis} of {Scientific} {Vector} {Graphics} with {TikZ}},
	author = {Belouadi, Jonas and Lauscher, Anne and Eger, Steffen},
	year = {2024},
	note = {Type of Work: misc},
}

@article{maras_client-side_2011,
	title = {Client-side web application slicing},
	doi = {10.1109/ASE.2011.6100110},
	abstract = {Highly interactive web applications that offer user experience and responsiveness of standard desktop applications are becoming prevalent in the web application domain. However, with these benefits come certain drawbacks. For example, the event-based architectural style, and poor support for code organization, often lead to a situation where code responsible for a certain behavior is intermixed with irrelevant code. This makes development, debugging and reuse difficult. One way of locating code implementing a certain behavior is program slicing, a method that, given a subset of a program's behavior, reduces the program to a minimal form that still produces that behavior. In this paper we present a semi-automatic client-side web application slicing method, describe the web page dependency graph, and show how it can be used to extract only the code implementing a certain behavior. © 2011 IEEE.},
	journal = {2011 26th IEEE/ACM International Conference on Automated Software Engineering, ASE 2011, Proceedings},
	author = {Maras, Josip and Carlson, Jan and Crnković, Ivica},
	year = {2011},
	keywords = {JavaScript, code reuse, dynamic program slicing, web application},
	pages = {504--507},
}

@inproceedings{conlen_idyll_2018,
	title = {{IdylL}: {A} markup language for authoring and publishing interactive articles on the web},
	doi = {10.1145/3242587.3242600},
	abstract = {The web has matured as a publishing platform: news outlets regularly publish rich, interactive stories while technical writers use animation and interaction to communicate complex ideas. This style of interactive media has the potential to engage a large audience and more clearly explain concepts, but is expensive and time consuming to produce. Drawing on industry experience and interviews with domain experts, we contribute design tools to make it easier to author and publish interactive articles. We introduce Idyll, a novel “compile-to-the-web” language for web-based interactive narratives. Idyll implements a flexible article model, allowing authors control over document style and layout, reader-driven events (such as button clicks and scroll triggers), and a structured interface to JavaScript components. Through both examples and first-use results from undergraduate computer science students, we show how Idyll reduces the amount of effort and custom code required to create interactive articles.},
	booktitle = {{UIST} 2018 - {Proceedings} of the 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Conlen, Matthew and Heer, Jeffrey},
	year = {2018},
	keywords = {Artifact or System, Interaction Design, Programming Languages, Programming/Development Support, Prototyping/Implementation, Storytelling, Visualization},
	pages = {977--989},
}

@article{carpenter_what_1990,
	title = {What one intelligence test measures: {A} theoretical account of the processing in the {Raven} progressive matrices test},
	volume = {97},
	issn = {0033295X},
	doi = {10.1037/0033-295X.97.3.404},
	abstract = {The cognitive processes in a widely used, nonverbal test of analytic intelligence, the Raven Progressive Matrices Test (Raven, 1962), are analyzed in terms of which processes distinguish between higher scoring and lower scoring subjects and which processes are common to all subjects and all items on the test. The analysis is based on detailed performance characteristics, such as verbal protocols, eye-fixation patterns, and errors. The theory is expressed as a pair of computer simulation models that perform like the median or best college students in the sample. The processing characteristic common to all subjects is an incremental, reiterative strategy for encoding and inducing the regularities in each problem. The processes that distinguish among individuals are primarily the ability to induce abstract relations and the ability to dynamically manage a large set of problem-solving goals in working memory.},
	number = {3},
	journal = {Psychological Review},
	author = {Carpenter, Patricia A. and Just, Marcel Adam and Shell, Peter},
	year = {1990},
	pages = {404--431},
}

@article{tversky_visualizing_2011,
	title = {Visualizing {Thought}},
	volume = {3},
	issn = {1756-8757},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2010.01113.x},
	doi = {10.1111/j.1756-8765.2010.01113.x},
	abstract = {{\textless}p{\textgreater} Depictive expressions of thought predate written language by thousands of years. They have evolved in communities through a kind of informal user testing that has refined them. Analyzing common visual communications reveals consistencies that illuminate how people think as well as guide design; the process can be brought into the laboratory and accelerated. Like language, visual communications abstract and schematize; unlike language, they use properties of the page (e.g., proximity and place: center, horizontal/up–down, vertical/left–right) and the marks on it (e.g., dots, lines, arrows, boxes, blobs, likenesses, symbols) to convey meanings. The visual expressions of these meanings (e.g., individual, category, order, relation, correspondence, continuum, hierarchy) have analogs in language, gesture, and especially in the patterns that are created when people design the world around them, arranging things into piles and rows and hierarchies and arrays, spatial‐abstraction‐action interconnections termed {\textless}italic{\textgreater}spractions{\textless}/italic{\textgreater} . The designed world is a diagram. {\textless}/p{\textgreater}},
	number = {3},
	journal = {Topics in Cognitive Science},
	author = {Tversky, Barbara},
	year = {2011},
	keywords = {Action, Analogy, Diagrams, Gesture, Metaphor, Spatial cognition, Visual communication},
	pages = {499--535},
}

@article{chi_icap_2014,
	title = {The {ICAP} {Framework}: {Linking} {Cognitive} {Engagement} to {Active} {Learning} {Outcomes}},
	volume = {49},
	issn = {00461520},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00461520.2014.965823},
	doi = {10.1080/00461520.2014.965823},
	abstract = {This article describes the ICAP framework that defines cognitive engagement activities on the basis of students’ overt behaviors and proposes that engagement behaviors can be categorized and differentiated into one of four modes: Interactive, Constructive, Active, and Passive. The ICAP hypothesis predicts that as students become more engaged with the learning materials, from passive to active to constructive to interactive, their learning will increase. We suggest possible knowledge-change processes that support the ICAP hypothesis and address the limitations and caveats of the hypothesis. In addition, empirical validation for the hypothesis is provided by examining laboratory and classroom studies that focus on three specific engagement activities: note taking, concept mapping and self-explaining. We also consider how ICAP can be used as a tool for explaining discrepant findings, dictate the proper choice of a control condition, and evaluate students’ outputs. Finally, we briefly compare ICAP to existing theories of learning.},
	number = {4},
	journal = {Educational Psychologist},
	author = {Chi, Michelene T.H. and Wylie, Ruth},
	year = {2014},
	pages = {219--243},
}

@inproceedings{polozov_personalized_2015,
	title = {Personalized mathematical word problem generation},
	booktitle = {Twenty-{Fourth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Polozov, Oleksandr and O'Rourke, Eleanor and Smith, Adam M and Zettlemoyer, Luke and Gulwani, Sumit and Popović, Zoran},
	year = {2015},
}

@book{boyd_convex_2004,
	title = {Convex optimization},
	publisher = {Cambridge university press},
	author = {Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
	year = {2004},
}

@article{mccracken_text_2001,
	title = {Text to diagram to symbol: {Representational} transformations in problem-solving},
	volume = {2},
	issn = {01905848},
	doi = {10.1109/FIE.2001.963721},
	abstract = {Central to engineering problem solving is what we call representational transformation. Such transformations are built upon community-sanctioned practices often referred to as "back of the envelope" calculations. First a problem statement (text) is translated into a sketch (diagram) which visually articulates the essential problem parts. Mechanical models and free-body diagrams are instances of this first transformation. The qualitative model is then transformed into a set of mathematical formulae (symbols), which drive the problem solution. Thus, the problem is solved using three types of representational systems: textual, diagrammatic and symbolic. At each step the engineer translates information from one representational system to another, enacting an abstract cultural algorithm. The knowledge necessary to undertake these transformation is described in this paper in the context of multi-literacies. We propose that a large part of learning engineering problem solving is in fact learning the relationships between the multiple languages of problem solving.},
	journal = {Proceedings - Frontiers in Education Conference},
	author = {McCracken, W. M. and Newstetter, W. C.},
	year = {2001},
	keywords = {Education, Learning, Literacy, Problem-solving},
}

@inproceedings{aleven_cognitive_2006,
	address = {Jhongli},
	title = {The cognitive tutor authoring tools ({CTAT}): {Preliminary} evaluation of efficiency gains},
	url = {https://link.springer.com/chapter/10.1007/11774303_7},
	doi = {10.1007/11774303_7},
	abstract = {Intelligent Tutoring Systems have been shown to be effective in a number of domains, but they remain hard to build, with estimates of 200-300 hours of development per hour of instruction. Two goals of the Cognitive Tutor Authoring Tools (CTAT) project are to (a) make tutor development more efficient for both programmers and non-programmers and (b) produce scientific evidence indicating which tool features lead to improved efficiency. CTAT supports development of two types of tutors, Cognitive Tutors and Example-Tracing Tutors, which represent different trade-offs in terms of ease of authoring and generality. In preliminary small-scale controlled experiments involving basic Cognitive Tutor development tasks, we found efficiency gains due to CTAT of 1.4 to 2 times faster. We expect that continued development of CTAT, informed by repeated evaluations involving increasingly complex authoring tasks, will lead to further efficiency gains. © Springer-Verlag Berlin Heidelberg 2006.},
	booktitle = {International {Conference} on {Intelligent} {Tutoring} {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Aleven, Vincent and McLaren, Bruce M. and Sewall, Jonathan and Koedinger, Kenneth R.},
	year = {2006},
	pages = {61--70},
}

@article{gleicher_differential_nodate,
	title = {Differential {Manipulation}},
	abstract = {Direct manipulation has proven to be an excellent method for interacting with geometric objects. Unfortunately , traditional approaches for implementing direct manipulation suffer from a lack of generality, requiring the system designer to hand craft interfaces to different types of objects. In this paper we present differential manipulation, a new paradigm for direct manipulation of geometric objects. By interpreting graphical entities as physical objects, we obtain a uniform interface to a wide variety of geometric objects, making it simple to add new types of complicated or compound objects. Geometric constraints fit neatly into the paradigm. Résumé La manipulation directe est une excellente méthode pour le traitement interactif des objets géométriques. Malheureusement, les approches traditionelles pour l'implémentation de la manipulation directe manquent de généralité en nécessitant que différentes interfaces soient associéesassociées`associéesà différents types d'objets. Dans cet article nous présentons un nouveau paradigme, la manipulation différentielle, pour la manipulation directe des ob-jets géométriques. En interprétant les entités graphiques comme des objets physiques, nous obtenons une seule interface pouvantêtrepouvantˆpouvantêtre utilisée pour une grande variété d'objets géométriques, facilitant ainsi l'addition de nou-veaux types d'objets complexes ou composés. Les con-traintes géométriques peuventêtrepeuventˆpeuventêtre proprement incluses avec ce paradigme.},
	author = {Gleicher, Michael and Witkin, Andrew},
	keywords = {Direct Manipulation, Geometric Modeling, Interaction Tech-niques},
}

@article{myers_garnet_1995,
	title = {Garnet {Comprehensive} {Support} for {Graphical}, {Highly} {Interactive} {User} {Interfaces}},
	doi = {10.1016/B978-0-08-051574-8.50037-6},
	journal = {Readings in Human–Computer Interaction},
	author = {Myers, Brad A. and Giuse, Dario A. and Dannenberg, Roger B. and Zanden, Brad Vander and Kosbie, David S. and Pervin, Edward and Mickish, Andrew and Marchal, Philippe},
	year = {1995},
	pages = {357--371},
}

@article{horvath_conceptual_2023,
	title = {Conceptual diagrams in {Quantum} {Mechanics}},
	issn = {1521-3994},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/asna.20230046https://onlinelibrary.wiley.com/doi/abs/10.1002/asna.20230046https://onlinelibrary.wiley.com/doi/10.1002/asna.20230046},
	doi = {10.1002/ASNA.20230046},
	abstract = {Quantum Mechanics (QM) stands alone as a (very) successful physical theory, but the meaning of its variables and the status of many quantities in the mathematical formalism is obscure. This unique situation prompted the need for attribution of a physical meaning to the latter, a procedure known as interpretation. On the other hand, the study of QM is usually presented, even to future scientists, within the only framework developed by Bohr and the Copenhagen researchers, known as the Copenhagen interpretation. As a contribution to the understanding and teaching of Quantum Mechanics, aimed to a broader and deeper appreciation of its fundamentals, including contemplating alternatives and updated interpretations for physicists and philosophers interested in the study of exact sciences (through Ontology, Epistemology, Logic or the Theory of Knowledge), we present a set of Conceptual Diagrams elaborated and designed to expose and facilitate the visualization of elements intervening in any interpretation of Quantum Mechanics and apply them to several well-developed cases of the latter.},
	journal = {Astronomische Nachrichten},
	author = {Horvath, Jorge E and Fernandes, Rodrigo Rosas and Paulo, São and Correspondence, Brazil},
	year = {2023},
	keywords = {Quantum Mechanics, diagrams, philosophy},
	pages = {e20230046},
}

@article{van_kreveld_automated_2005,
	title = {{AUTOMATED} {LABEL} {PLACEMENT} {FOR} {GROUPS} {OF} {ISLANDS}},
	abstract = {In his article "Positioning Names on Maps", Eduard Imhof describes label placement guidelines for three types of objects; point, line, and area objects. We describe how a label can be placed for a fourth type, namely groups of area objects. In particular we consider groups of islands. A suitable place for the label may be the position that minimizes the maximum distance from the label to each island of the group. We develop an efficient algorithm that computes this position for a given horizontal, two-dimensional label, and a set P of polygons representing the islands. The solution is based on geometric concepts like furthest site Voronoi diagrams and Minkowski sums. Furthermore, we give an implementation that determines good island label positions for fixed horizontal labels that may or may not overlap with the islands, and for horizontal labels with different letter spacing. Tests with various settings of the implementation show the quality of the results on several groups of islands.},
	author = {Van Kreveld, Marc and Schlechter, Tim},
	year = {2005},
}

@article{satyanarayan_critical_2020,
	title = {Critical reflections on visualization authoring systems},
	volume = {26},
	issn = {19410506},
	doi = {10.1109/TVCG.2019.2934281},
	abstract = {An emerging generation of visualization authoring systems support expressive information visualization without textual programming. As they vary in their visualization models, system architectures, and user interfaces, it is challenging to directly compare these systems using traditional evaluative methods. Recognizing the value of contextualizing our decisions in the broader design space, we present critical reflections on three systems we developed-Lyra, Data Illustrator, and Charticulator. This paper surfaces knowledge that would have been daunting within the constituent papers of these three systems. We compare and contrast their (previously unmentioned) limitations and trade-offs between expressivity and learnability. We also reflect on common assumptions that we made during the development of our systems, thereby informing future research directions in visualization authoring systems.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, Arvind and Lee, Bongshin and Ren, Donghao and Heer, Jeffrey and Stasko, John and Thompson, John and Brehmer, Matthew and Liu, Zhicheng},
	year = {2020},
	keywords = {Critical reflection, Expressivity, Learnability, Reusability, Visualization authoring},
	pages = {461--471},
}

@article{aleven_rapid_2006,
	title = {Rapid authoring of {Intelligent} {Tutors} for real-world and experimental use},
	volume = {2006},
	doi = {10.1109/ICALT.2006.1652575},
	abstract = {Authoring tools for Intelligent Tutoring Systems are especially valuable if they not only provide a rich set of options for the efficient authoring of tutoring systems but also support controlled experiments in which the added educational value of new tutor features is evaluated. The Cognitive Tutor Authoring Tools (CTAT) provide both. Using CTAT, real-world "Example- Tracing Tutors" can be created without programming. CTAT also provides various kinds of support for controlled experiments, such as administration of different experimental treatments, logging, and data analysis. We present two case studies in which Example-Tracing Tutors created with CTAT were used in classroom experiments. The case studies illustrate a number of new features in CTAT: Use of Macromedia Flash MX 2004 for creating tutor interfaces, extensions to the Example-Tracing Engine that allow for more flexible tutors, a Mass Production facility for more efficient template-based authoring, and support for controlled experiments. © 2006 IEEE.},
	journal = {Proceedings - Sixth International Conference on Advanced Learning Technologies, ICALT 2006},
	author = {Aleven, Vincent and Sewall, Jonathan and McLaren, Bruce M. and Koedinger, Kenneth R.},
	year = {2006},
	pages = {847--851},
}

@article{zheng_graph_2017,
	title = {Graph {Drawing} by {Stochastic} {Gradient} {Descent}},
	volume = {25},
	issn = {19410506},
	url = {https://arxiv.org/abs/1710.04626v3},
	doi = {10.1109/TVCG.2018.2859997},
	abstract = {A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.},
	number = {9},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zheng, Jonathan X. and Pawar, Samraat and Goodman, Dan F.M.},
	year = {2017},
	keywords = {Graph drawing, constraints, multidimensional scaling, relaxation, stochastic gradient descent},
	pages = {2738--2748},
}

@article{nathan_combinators_2007,
	title = {Combinators for bidirectional tree transformations},
	volume = {29},
	url = {https://dl.acm.org/doi/abs/10.1145/1232420.1232424},
	doi = {10.1145/1232420.1232424},
	abstract = {We propose a novel approach to the view-update problem for tree-structured data: a domain-specific programming language in which all expressions denote bidirectional transformations on trees. In on...},
	number = {3},
	journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
	author = {Nathan, FosterJ. and B., GreenwaldMichael and T., MooreJonathan and C., PierceBenjamin and SchmittAlan},
	year = {2007},
	keywords = {Bidirectional programming, Harmony, XML, lenses, view update problem},
}

@misc{noauthor_desmos_2019,
	title = {Desmos},
	year = {2019},
	note = {Type of Work: misc},
}

@article{razzaq_assistment_2009,
	title = {The {ASSISTment} builder: {Supporting} the life cycle of tutoring system content creation},
	volume = {2},
	issn = {19391382},
	doi = {10.1109/TLT.2009.23},
	abstract = {Content creation is a large component of the cost of creating educational software. Estimates are that approximately 200 hours of development time are required for every hour of instruction. We present an authoring tool designed to reduce this cost as it helps to refine and maintain content. The ASSISTment Builder is a tool designed to effectively create, edit, test, and deploy tutor content. The Web-based interface simplifies the process of tutor construction to allow users with little or no programming experience to develop content. We show the effectiveness of our Builder at reducing the cost of content creation to 40 hours for every hour of instruction. We describe new features that work toward supporting the life cycle of ITS content creation through maintaining and improving content as it is being used by students. The Variabilization feature allows the user to reuse tutoring content across similar problems. The Student Comments feature provides a way to maintain and improve content based on feedback from users. The Most Common Wrong Answer feature provides a way to refine remediation based on the users' answers. This paper describes our attempt to support the life cycle of content creation. © 2009 IEEE.},
	number = {2},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Razzaq, Leena and Patvarczki, Jozsef and Almeida, Shane F. and Vartak, Manasi and Feng, Mingyu and Heffernan, Neil T. and Koedinger, Kenneth R.},
	year = {2009},
	keywords = {Adaptive and intelligent educational systems, Authoring tools, Computer uses in education, E-learning tools},
	pages = {157--166},
}

@article{johnson_feedback_2014,
	title = {The {Feedback} {Principle} in {Multimedia} {Learning}},
	url = {https://www.cambridge.org/core/books/cambridge-handbook-of-multimedia-learning/feedback-principle-in-multimedia-learning/F52480F8ED64AE42AA8D999E9460C08F},
	doi = {10.1017/CBO9781139547369.023},
	abstract = {Multimedia learning environments require learners to integrate information across different sources and modalities, which can pose a challenge for some learners. Providing feedback on student responses can be an effective method of guiding learners to achieve a deep understanding of the material. The feedback principle states that novice students learn better wiThexplanatory feedback than with corrective feedback alone. Explanatory feedback provides the learner with a principle-based explanation of why his or her answer was correct or incorrect, whereas corrective feedback merely informs the learner that his or her response was correct or incorrect. The theoretical rationale is that explanatory feedback guides the learner in selecting the appropriate information and consequently reduces the amount of extraneous processing relative to providing only corrective feedback. This chapter reviews evidence for the feedback principle and explores some of the boundary conditions.},
	journal = {The Cambridge Handbook of Multimedia Learning, Second Edition},
	author = {Johnson, Cheryl I. and Priest, Heather A.},
	year = {2014},
	pages = {449--463},
}

@inproceedings{will_crichton_new_2020,
	address = {Virtual},
	title = {A {New} {Medium} for {Communicating} {Research} on {Programming} {Languages}},
	url = {https://willcrichton.net/nota/},
	abstract = {Papers about programming languages involve complex notations, systems, and proofs. Static PDFs offer little support in understanding such concepts. I describe Nota, a framework for academic papers that uses the browser's interactive capabilities to support comprehension in context. Nota uses hover effects, tooltips, expandable sections, toggleable explanations, and other interactions to help readers understand a language's syntax and semantics. I demonstrate the use of Nota by rewriting a PL paper using its primitives, and also by writing this paper in Nota.},
	booktitle = {11th {Workshop} on {Evaluation} and {Usability} of {Programming} {Languages} and {Tools} ({PLATEAU} 2020)},
	author = {Will Crichton},
	year = {2020},
}

@article{allen-zhu_backward_2020,
	title = {Backward {Feature} {Correction}: {How} {Deep} {Learning} {Performs} {Deep} {Learning}},
	url = {https://arxiv.org/abs/2001.04413v5},
	doi = {10.48550/arxiv.2001.04413},
	abstract = {How does a 110-layer ResNet learn a high-complexity classifier using
relatively few training examples and short training time? We present a theory
towards explaining this in terms of Hierarchical Learning. We refer
hierarchical learning as the learner learns to represent a complicated target
function by decomposing it into a sequence of simpler functions to reduce
sample and time complexity. We formally analyze how multi-layer neural networks
can perform such hierarchical learning efficiently and automatically by
applying SGD. On the conceptual side, we present, to the best of our knowledge, the FIRST
theory result indicating how deep neural networks can still be sample and time
efficient using SGD on certain hierarchical learning tasks, when NO KNOWN
existing algorithm is efficient. We establish a new principle called "backward
feature correction", where training higher-level layers in the network can
improve the features of lower-level ones. We believe this is the key to
understand the deep learning process in multi-layer neural networks. On the technical side, we show for regression and even binary classification,
for every input dimension \$d{\textgreater}0\$, there is a concept class of degree \${\textbackslash}omega(1)\$
polynomials so that, using \${\textbackslash}omega(1)\$-layer neural networks as learners, SGD
can learn any function from this class in \${\textbackslash}mathsf\{poly\}(d)\$ time and sample
complexity to any \${\textbackslash}frac\{1\}\{{\textbackslash}mathsf\{poly\}(d)\}\$ error, through learning to
represent it as a composition of \${\textbackslash}omega(1)\$ layers of quadratic functions. In
contrast, we do not know any other simple algorithm (including layer-wise
training or applying kernel method sequentially) that can learn this concept
class in \${\textbackslash}mathsf\{poly\}(d)\$ time even to any \$d{\textasciicircum}\{-0.01\}\$ error. As a side
result, we prove \$d{\textasciicircum}\{{\textbackslash}omega(1)\}\$ lower bounds for several non-hierarchical
learners, including any kernel methods, neural tangent or neural compositional
kernels.},
	author = {Allen-Zhu, Zeyuan and Research, Microsoft and Li, Redmond Yuanzhi},
	year = {2020},
}

@book{clark_e-learning_2023,
	title = {E-learning and the science of instruction: {Proven} guidelines for consumers and designers of multimedia learning},
	publisher = {john Wiley \& sons},
	author = {Clark, Ruth C and Mayer, Richard E},
	year = {2023},
}

@inproceedings{chen_crossdata_2022,
	title = {{CrossData}: {Leveraging} {Text}-{Data} {Connections} for {Authoring} {Data} {Documents}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517485},
	doi = {10.1145/3491102.3517485},
	abstract = {Data documents play a central role in recording, presenting, and disseminating data. Despite the proliferation of applications and systems designed to support the analysis, visualization, and communication of data, writing data documents remains a laborious process, requiring a constant back-and-forth between data processing and writing tools. Interviews with eight professionals revealed that their workflows contained numerous tedious, repetitive, and error-prone operations. The key issue that we identified is the lack of persistent connection between text and data. Thus, we developed CrossData, a prototype that treats text-data connections as persistent, interactive, first-class objects. By automatically identifying, establishing, and leveraging text-data connections, CrossData enables rich interactions to assist in the authoring of data documents. An expert evaluation with eight users demonstrated the usefulness of CrossData, showing that it not only reduced the manual effort in writing data documents but also opened new possibilities to bridge the gap between data exploration and writing.},
	booktitle = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Zhutian and Xia, Haijun},
	year = {2022},
	keywords = {Data Document, Interactive Article, Language-oriented Authoring, Natural Language Processing, Text-based Editing},
}

@article{satyanarayan_vega-lite_2017,
	title = {Vega-{Lite}: {A} {Grammar} of {Interactive} {Graphics}},
	volume = {23},
	issn = {10772626},
	doi = {10.1109/TVCG.2016.2599030},
	abstract = {We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
	year = {2017},
	keywords = {Information visualization, declarative specification, interaction, systems, toolkits},
	pages = {341--350},
}

@article{bostock_protovis_2009,
	title = {Protovis: {A} graphical toolkit for visualization},
	volume = {15},
	issn = {10772626},
	doi = {10.1109/TVCG.2009.174},
	abstract = {Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency-the effort required to specify a visualization-and accessibility-the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools. © 2009 IEEE.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bostock, Michael and Heer, Jeffrey},
	year = {2009},
	keywords = {2D graphics, Information visualization, toolkits, user interfaces},
	pages = {1121--1128},
}

@article{deslauriers_measuring_2019,
	title = {Measuring actual learning versus feeling of learning in response to being actively engaged in the classroom},
	volume = {116},
	issn = {10916490},
	url = {www.pnas.org/cgi/doi/10.1073/pnas.1821936116},
	doi = {10.1073/pnas.1821936116},
	abstract = {We compared students' self-reported perception of learning with their actual learning under controlled conditions in largeenrollment introductory college physics courses taught using 1) active instruction (following best practices in the discipline) and 2) passive instruction (lectures by experienced and highly rated instructors). Both groups received identical class content and handouts, students were randomly assigned, and the instructor made no effort to persuade students of the benefit of either method. Students in active classrooms learned more (as would be expected based on prior research), but their perception of learning, while positive, was lower than that of their peers in passive environments. This suggests that attempts to evaluate instruction based on students' perceptions of learning could inadvertently promote inferior (passive) pedagogical methods. For instance, a superstar lecturer could create such a positive feeling of learning that students would choose those lectures over active learning. Most importantly, these results suggest that when students experience the increased cognitive effort associated with active learning, they initially take that effort to signify poorer learning. That disconnect may have a detrimental effect on students' motivation, engagement, and ability to self-regulate their own learning. Although students can, on their own, discover the increased value of being actively engaged during a semester-long course, their learning may be impaired during the initial part of the course. We discuss strategies that instructors can use, early in the semester, to improve students' response to being actively engaged in the classroom.},
	number = {39},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Deslauriers, Louis and McCarty, Logan S. and Miller, Kelly and Callaghan, Kristina and Kestin, Greg},
	year = {2019},
	keywords = {Constructivism, Evidence-based teaching, Scientific teaching, Undergraduate education},
	pages = {19251--19257},
}

@article{fuhrman_developing_2018,
	title = {Developing {Good} {Multiple}-{Choice} {Tests} and {Test} {Questions}},
	volume = {44},
	issn = {10899995},
	url = {https://www.tandfonline.com/doi/abs/10.5408/1089-9995-44.4.379},
	doi = {10.5408/1089-9995-44.4.379},
	abstract = {Multiple-choice tests, although often criticized, still form the backbone of most standardized and classroom tests for a variety of reasons. The advantages of multiple-choice assessments over most ...},
	number = {4},
	journal = {https://doi.org/10.5408/1089-9995-44.4.379},
	author = {Fuhrman, Miriam},
	year = {2018},
	keywords = {Education – testing and evaluation, education – geoscience},
	pages = {379--384},
}

@inproceedings{lau_data_2020,
	title = {Data {Theater}: {A} {Live} {Programming} {Environment} for {Prototyping} {Data}-{Driven} {Explorable} {Explanations}},
	url = {https://par.nsf.gov/biblio/10210727},
	booktitle = {Workshop on {Live} {Programming} ({LIVE})},
	author = {Lau, Sam and Guo, Philip J},
	year = {2020},
}

@inproceedings{myers_separating_1991,
	address = {New York, New York, USA},
	title = {Separating application code from toolkits: {Eliminating} the {Spaghetti} of call-backs},
	doi = {10.1145/120782},
	abstract = {Conventional toolkits today require the programmer to attach call-back procedures to most buttons, scroll bars, menu items, and other widgets in the interface. These procedures are called by the system when the user operates the widget in order to notify the application of the user's actions. Unfortunately, real interfaces contain hundreds or thousands of widgets, and therefore many call-back procedures, most of which perform trivial tasks, resulting in a maintenance nightmare. This paper describes a system that allows the majority of these procedures to be eliminated. The user interface designer can specify by demonstration many of the desired actions and connections among the widgets, so call-backs are only needed for the most significant application actions. In addition, the callbacks that remain are completely insulated from the widgets, so that the application code is better separated from the user interface.},
	booktitle = {Proceedings of the 4th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}, {UIST} 1991},
	publisher = {ACM Press},
	author = {Myers, Brad A},
	year = {1991},
	keywords = {Call-back procedures, Dialog boxes, Interface builders, UIMSS},
	pages = {211--220},
}

@article{jayagopal_exploring_2022,
	title = {Exploring the {Learnability} of {Program} {Synthesizers} by {Novice} {Programmers}},
	url = {https://dl.acm.org/doi/10.1145/3526113.3545659},
	doi = {10.1145/3526113.3545659},
	abstract = {Modern program synthesizers are increasingly delivering on their promise of lightening the burden of programming by automatically generating code, but little research has addressed how we can make such systems learnable to all. In this work, we ask: What aspects of program synthesizers contribute to and detract from their learnability by novice programmers? We conducted a thematic analysis of 22 observations of novice programmers, during which novices worked with existing program synthesizers, then participated in semi-structured interviews. Our findings shed light on how their specific points in the synthesizer design space affect these tools' learnability by novice programmers, including the type of specification the synthesizer requires, the method of invoking synthesis and receiving feedback, and the size of the specification. We also describe common misconceptions about what constitutes meaningful progress and useful specifications for the synthesizers, as well as participants' common behaviors and strategies for using these tools. From this analysis, we offer a set of design opportunities to inform the design of future program synthesizers that strive to be learnable by novice programmers. This work serves as a first step toward understanding how we can make program synthesizers more learnable by novices, which opens up the possibility of using program synthesizers in educational settings as well as developer tooling oriented toward novice programmers.},
	journal = {UIST 2022 - Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
	author = {Jayagopal, Dhanya and Lubin, Justin and Chasins, Sarah E.},
	year = {2022},
	keywords = {learnability, novice programmers, program synthesis, qualitative, thematic analysis},
}

@article{gulwani_synthesizing_2011,
	title = {Synthesizing geometry constructions},
	volume = {46},
	issn = {0362-1340},
	url = {https://dl.acm.org/doi/abs/10.1145/1993316.1993505},
	doi = {10.1145/1993316.1993505},
	abstract = {In this paper, we study the problem of automatically solving ruler/compass based geometry construction problems. We first introduce a logic and a programming language for describing such constructions and then phrase the automation problem as a program synthesis problem. We then describe a new program synthesis technique based on three key insights: (i) reduction of symbolic reasoning to concrete reasoning (based on a deep theoretical result that reduces verification to random testing), (ii) extending the instruction set of the programming language with higher level primitives (representing basic constructions found in textbook chapters, inspired by how humans use their experience and knowledge gained from chapters to perform complicated constructions), and (iii) pruning the forward exhaustive search using a goal-directed heuristic (simulating backward reasoning performed by humans). Our tool can successfully synthesize constructions for various geometry problems picked up from high-school textbooks and examination papers in a reasonable amount of time. This opens up an amazing set of possibilities in the context of making classroom teaching interactive.},
	number = {6},
	journal = {ACM SIGPLAN Notices},
	author = {Gulwani, Sumit and Korthikanti, Vijay Anand and Tiwari, Ashish},
	year = {2011},
	keywords = {abstraction, forward and backward analysis, program synthesis, ruler-compass geometry constructions},
	pages = {50--61},
}

@article{mulero_two-dimensional_2007,
	title = {Two-dimensional {Minkowski} sum optimization of ganged stamping blank layouts for use on pre-cut sheet metal for convex and concave parts},
	volume = {26},
	issn = {02786125},
	doi = {10.1016/j.jmsy.2007.10.001},
	abstract = {With the increasing number of parts that manufacturers need to place on a piece of material such as sheet metal, the need increases for more sophisticated algorithms for part orientation and spacing. With greater part shape complexity, the ability of a skilled worker is challenged to minimize waste. Building on the previous work of Nye, this paper presents a Minkowski sum method for maximizing the number of parts within gangs on a rectangular sheet of material. The example provided uses a simply shaped part to illustrate the presented method, yielding a packing efficiency of 62\% that is identical to the efficiency that a skilled worker would produce without the algorithm. The paper also provides results for laying out a more complex part in ganged sections, demonstrating a result that would be difficult for a human to reproduce. This work extends that of Nye by adding practical constraints such as the number of parts that can be blanked at once as well as the amount of horizontal and vertical spacing between ganged blanking sets. Additionally, the paper adds an algorithm for laying out polygons with concave geometries by separating the part into a set of convex polygons. Two examples for optimization, one of a chevron-shaped part and one of a complex shape previously used by Nye [Nye TJ. Stamping strip layout for optimal raw material utilization. Journal of Manufacturing Systems 2000;19(4):239-46] and Choi et al. [Choi JC, Kim BM, Cho HY, Kim C. A compact and practical CAD system for blanking or piercing of irregular-shaped sheet metal products and stator and rotor parts. International Journal of Machine Tools \& Manufacture 1998;38:931-63], are provided, demonstrating the existence of a local maximum number of parts that may be stamped within a single ganged blank. The algorithm is extendable to a program that may provide stamping manufacturers with a tool that can maximize the total number of parts stamped on stock sheet metal, or for other tiling problems. © 2008 The Society of Manufacturing Engineers.},
	number = {1},
	journal = {Journal of Manufacturing Systems},
	author = {Mulero, Rafael and Layton, Bradley},
	year = {2007},
	pages = {44--52},
}

@article{bostock_d3_2011,
	title = {D3 data-driven documents},
	volume = {17},
	issn = {10772626},
	doi = {10.1109/TVCG.2011.185},
	abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations. © 2011 IEEE.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
	year = {2011},
	keywords = {2D graphics., Information visualization, toolkits, user interfaces},
	pages = {2301--2309},
}

@article{koedinger_cognitive_2019,
	title = {A {Cognitive} {Task} {Analysis} of {Using} {Pictures} {To} {Support} {Pre}-{Algebraic} {Reasoning}},
	doi = {10.4324/9781315782379-129},
	abstract = {We present an analysis of hypothesized advantages of pictorial representations for improving learning and understanding of pre-algebraic quantitative reasoning. We discuss a “Picture Algebra” strategy that has been used successfully by 6th grade students as part of a new middle school mathematics curriculum. This strategy supports students in sense making both as they construct pictorial representations and as they use them to cue appropriate computations. Although we demonstrate that 6th grade students can use this strategy to successfully solve algebra-level problems, our detailed production rule analysis revealed limitations in our instructional approach and targeted areas for improvement.},
	journal = {Proceedings of the Twenty-Fourth Annual Conference of the Cognitive Science Society},
	author = {Koedinger, Kenneth R. and Terao, Atsushi},
	year = {2019},
	pages = {542--547},
}

@article{heer_interactive_2012,
	title = {Interactive {Dynamics} for {Visual} {Analysis}},
	volume = {10},
	issn = {15427749},
	url = {https://dl.acm.org/doi/abs/10.1145/2133416.2146416},
	doi = {10.1145/2133416.2146416},
	abstract = {The increasing scale and availability of digital data provides an extraordinary resource for informing public policy, scientific discovery, business strategy, and even our personal lives. To get th...},
	number = {2},
	journal = {Queue},
	author = {Heer, Jeffrey and Shneiderman, Ben},
	year = {2012},
	pages = {30--55},
}

@article{boy_suggested_2016,
	title = {Suggested {Interactivity}: {Seeking} {Perceived} {Affordances} for {Information} {Visualization}},
	volume = {22},
	issn = {10772626},
	doi = {10.1109/TVCG.2015.2467201},
	abstract = {In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances - SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Boy, Jeremy and Eveillard, Louis and Detienne, Françoise and Fekete, Jean Daniel},
	year = {2016},
	keywords = {Brushes, Electronic publishing, Encyclopedias, Internet, Silicon, Visualization},
	pages = {639--648},
}

@article{dwyer_scalable_2009,
	title = {Scalable, {Versatile} and {Simple} {Constrained} {Graph} {Layout}},
	volume = {28},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8659.2009.01449.xhttps://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01449.xhttps://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01449.x},
	doi = {10.1111/J.1467-8659.2009.01449.X},
	abstract = {We describe a new technique for graph layout subject to constraints. Compared to previous techniques the proposed method is much faster and scalable to much larger graphs. For a graph with n nodes, m edges and c constraints it computes incremental layout in time O(n log n + m + c) per iteration. Also, it supports a much more powerful class of constraint: inequalities or equalities over the Euclidean distance between nodes. We demonstrate the power of this technique by application to a number of diagramming conventions which previous constrained graph layout methods could not support. Further, the constraint-satisfaction method - inspired by recent work in position-based dynamics - is far simpler to implement than previous methods. © 2009 The Eurographics Association and Blackwell Publishing Ltd.},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Dwyer, Tim},
	year = {2009},
	keywords = {Computer Graphics [I.3.3]: Display algorithms, Display algorithms-Optimization [G16], Optimization [G.1.6]: Constrained optimization},
	pages = {991--998},
}

@article{satyanarayan_declarative_2014,
	title = {Declarative interaction design for data visualization},
	url = {https://dl.acm.org/doi/10.1145/2642918.2647360},
	doi = {10.1145/2642918.2647360},
	abstract = {Declarative visualization grammars can accelerate development, facilitate retargeting across platforms, and allow language-level optimizations. However, existing declarative visualization languages are primarily concerned with visual encoding, and rely on imperative event handlers for interactive behaviors. In response, we introduce a model of declarative interaction design for data visualizations. Adopting methods from reactive programming, we model low-level events as composable data streams from which we form higher-level semantic signals. Signals feed predicates and scale inversions, which allow us to generalize interactive selections at the level of item geometry (pixels) into interactive queries over the data domain. Production rules then use these queries to manipulate the visualization's appearance. To facilitate reuse and sharing, these constructs can be encapsulated as named interactors: standalone, purely declarative specifications of interaction techniques. We assess our model's feasibility and expressivity by instantiating it with extensions to the Vega visualization grammar. Through a diverse range of examples, we demonstrate coverage over an established taxonomy of visualization interaction techniques.},
	journal = {UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
	author = {Satyanarayan, Arvind and Wongsuphasawat, Kanit and Heer, Jeffrey},
	year = {2014},
	keywords = {Declarative design, Interaction design, Toolkits, Visualization, toolkits},
	pages = {669--678},
}

@book{hadamard_mathematicians_1997,
	title = {The {Mathematician}'s {Mind}},
	abstract = {Fifty years ago when Jacques Hadamard set out to explore how mathematicians invent new ideas, he considered the creative experiences of some of the greatest thinkers of his generation, such as George Polya, Claude Lévi-Strauss, and Albert Einstein. It appeared that inspiration could strike anytime, particularly after an individual had worked hard on a problem for days and then turned attention to another activity. In exploring this phenomenon, Hadamard produced one of the most famous and cogent cases for the existence of unconscious mental processes in mathematical invention and other forms of creativity. Written before the explosion of research in computers and cognitive science, his book, originally titled The Psychology of Invention in the Mathematical Field, remains an important tool for exploring the increasingly complex problem of mental life. The roots of creativity for Hadamard lie not in consciousness, but in the long unconscious work of incubation, and in the unconscious aesthetic selection of ideas that thereby pass into consciousness. His discussion of this process comprises a wide range of topics, including the use of mental images or symbols, visualized or auditory words, "meaningless" words, logic, and intuition. Among the important documents collected is a letter from Albert Einstein analyzing his own mechanism of thought.},
	publisher = {Princeton University Press},
	author = {Hadamard, Jacques},
	year = {1997},
	doi = {10.1515/9780691212906/HTML},
}

@article{batra_accelerating_2015,
	title = {Accelerating vector graphics rendering using the graphics hardware pipeline},
	volume = {34},
	issn = {15577368},
	url = {https://dl.acm.org/doi/10.1145/2766968},
	doi = {10.1145/2766968},
	abstract = {We describe our successful initiative to accelerate Adobe Illustrator with the graphics hardware pipeline of modern GPUs. Relying on OpenGL 4.4 plus recent OpenGL extensions for advanced blend mode...},
	number = {4},
	journal = {ACM Transactions on Graphics (TOG)},
	author = {Batra, Vineet and Kilgard, Mark J. and Kumar, Harish and Lorach, Tristan},
	year = {2015},
	keywords = {OpenGL, illustrator, path rendering, vector graphics},
	pages = {146},
}

@article{head_augmenting_2021,
	title = {Augmenting scientific papers with just-in-time, position-sensitive definitions of terms and symbols},
	url = {https://doi.org/10.1145/3411764.3445648},
	doi = {10.1145/3411764.3445648},
	abstract = {Despite the central importance of research papers to scientifc progress, they can be difcult to read. Comprehension is often stymied when the information needed to understand a passage resides somewhere else-in another section, or in another paper. In this work, we envision how interfaces can bring defnitions of technical terms and symbols to readers when and where they need them most. We introduce ScholarPhi, an augmented reading interface with four novel features: (1) tooltips that surface position-sensitive defnitions from elsewhere in a paper, (2) a flter over the paper that declutters it to reveal how the term or symbol is used across the paper, (3) automatic equation diagrams that expose multiple defnitions in parallel, and (4) an automatically generated glossary of important terms and symbols. A usability study showed that the tool helps researchers of all experience levels read papers. Furthermore, researchers were eager to have ScholarPhi's defnitions available to support their everyday reading.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Head, Andrew and Lo, Kyle and Kang, Dongyeop and Fok, Raymond and Skjonsberg, Sam and Weld, Daniel S and Hearst, Marti A},
	year = {2021},
	keywords = {Defnitions, Interactive documents, Nonce words, Reading interfaces, Scientifc papers},
}

@article{thurston_proof_1994,
	title = {On proof and progress in mathematics},
	volume = {30},
	issn = {02730979},
	url = {https://arxiv.org/abs/math/9404236v1},
	doi = {10.1090/S0273-0979-1994-00502-6},
	abstract = {In response to Jaffe and Quinn [math.HO/9307227], the author discusses forms of progress in mathematics that are not captured by formal proofs of theorems, especially in his own work in the theory of foliations and geometrization of 3-manifolds and dynamical systems.},
	number = {2},
	journal = {Bulletin of the American Mathematical Society},
	author = {Thurston, William P.},
	year = {1994},
	pages = {161--177},
}

@article{bille_survey_2005,
	title = {A survey on tree edit distance and related problems},
	volume = {337},
	issn = {03043975},
	doi = {10.1016/j.tcs.2004.12.030},
	abstract = {We survey the problem of comparing labeled trees based on simple local operations of deleting, inserting, and relabeling nodes. These operations lead to the tree edit distance, alignment distance, and inclusion problem. For each problem we review the results available and present, in detail, one or more of the central algorithms for solving the problem. © 2005 Elsevier B.V. All rights reserved.},
	number = {1-3},
	journal = {Theoretical Computer Science},
	author = {Bille, Philip},
	year = {2005},
	keywords = {Tree alignment, Tree edit distance, Tree inclusion, Tree matching},
	pages = {217--239},
}

@article{lynch_science_1991,
	title = {Science in the age of mechanical reproduction: moral and epistemic relations between diagrams and photographs},
	volume = {6},
	issn = {1572-8404},
	url = {https://link.springer.com/article/10.1007/BF02426838},
	doi = {10.1007/BF02426838},
	abstract = {Sociologists, philosophers and historians of science are gradually recognizing the importance of visual representation. This is part of a more general movement away from a theory-centric view of science and towards an interest in practical aspects of observation and experimentation. Rather than treating science as a matter of demonstrating the logical connection between theoretical and empirical statements, an increasing number of investigations are examining how scientists compose and use diagrams, graphs, photographs, micrographs, maps, charts, and related visual displays. This paper focuses on diagrams in biology, and tries to demonstrate how diagrams are an integral part of the production of scientific knowledge. In order to disclose some of the distinctive practical and analytical uses of diagrams, the paper contrasts the way diagrams and photographs are used in biological texts. Both diagrams and photographs are shown to be “constructions” that separately and together mediate the investigation of scientific phenoman.},
	number = {2},
	journal = {Biology and Philosophy 1991 6:2},
	author = {Lynch, Michael},
	year = {1991},
	keywords = {Evolutionary Biology, Philosophy of Biology},
	pages = {205--226},
}

@article{cordy_txl_2006,
	title = {The {TXL} source transformation language},
	volume = {61},
	issn = {0167-6423},
	doi = {10.1016/J.SCICO.2006.04.002},
	abstract = {TXL is a special-purpose programming language designed for creating, manipulating and rapidly prototyping language descriptions, tools and applications. TXL is designed to allow explicit programmer control over the interpretation, application, order and backtracking of both parsing and rewriting rules. Using first order functional programming at the higher level and term rewriting at the lower level, TXL provides for flexible programming of traversals, guards, scope of application and parameterized context. This flexibility has allowed TXL users to express and experiment with both new ideas in parsing, such as robust, island and agile parsing, and new paradigms in rewriting, such as XML mark-up, rewriting strategies and contextualized rules, without any change to TXL itself. This paper outlines the history, evolution and concepts of TXL with emphasis on its distinctive style and philosophy, and gives examples of its use in expressing and applying recent new paradigms in language processing. © 2006 Elsevier B.V. All rights reserved.},
	number = {3},
	journal = {Science of Computer Programming},
	author = {Cordy, James R.},
	year = {2006},
	keywords = {Functional programming, Grammars, Source transformation, Term rewriting},
	pages = {190--210},
}

@article{gibson_survey_2013,
	title = {A survey of two-dimensional graph layout techniques for information visualisation},
	volume = {12},
	issn = {14738716},
	url = {https://journals.sagepub.com/doi/full/10.1177/1473871612455749?casa_token=WoeybsA_rOsAAAAA%3AsyIoUVr6NizrS9wzs9jEEMCeEBRrqanoOiph4lD1ZpgOgggSTGXlFXXKRJP-jep--sisiTiduVFo},
	doi = {10.1177/1473871612455749/ASSET/IMAGES/LARGE/10.1177_1473871612455749-FIG19.JPEG},
	abstract = {Many algorithms for graph layout have been devised over the last 30 years spanning both the graph drawing and information visualisation communities. This article first reviews the advances made in the field of graph drawing that have then often been applied by the information visualisation community. There then follows a discussion of a range of techniques developed specifically for graph visualisations. Graph drawing algorithms are categorised into the following approaches: force-directed layouts, the use of dimension reduction in graph layout and computational improvements including multi-level techniques. Methods developed specifically for graph visualisation often make use of node-attributes and are categorised based on whether the attributes are used to introduce constraints to the layout, provide a clustered view or define an explicit representation in two-dimensional space. The similarities and distinctions between these techniques are examined and the aim is to provide a detailed assessment of currently available graph layout techniques, specifically how they can be used by visualisation practitioners, and to motivate further research in the area. © The Author(s) 2012.},
	number = {3-4},
	journal = {Information Visualization},
	author = {Gibson, Helen and Faith, Joe and Vickers, Paul},
	year = {2013},
	keywords = {2D, Force-directed layout, Graph and network visualisation, Graph layout, Multi-attribute visualisation, Network layout visualisation},
	pages = {324--357},
}

@article{bekos_external_2019,
	title = {External labeling techniques: {A} taxonomy and survey},
	volume = {38},
	issn = {14678659},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.13729https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13729https://onlinelibrary.wiley.com/doi/10.1111/cgf.13729},
	doi = {10.1111/cgf.13729},
	abstract = {External labeling is frequently used for annotating features in graphical displays and visualizations, such as technical illustrations, anatomical drawings, or maps, with textual information. Such a labeling connects features within an illustration by thin leader lines with their labels, which are placed in the empty space surrounding the image. Over the last twenty years, a large body of literature in diverse areas of computer science has been published that investigates many different aspects, models, and algorithms for automatically placing external labels for a given set of features. This state-of-the-art report introduces a first unified taxonomy for categorizing the different results in the literature and then presents a comprehensive survey of the state of the art, a sketch of the most relevant algorithmic techniques for external labeling algorithms, as well as a list of open research challenges in this multidisciplinary research field.},
	number = {3},
	journal = {Computer Graphics Forum},
	author = {Bekos, Michael A. and Niedermann, Benjamin and Nöllenburg, Martin},
	year = {2019},
	keywords = {Computational geometry, Human-centered computing, Information visualization, Theory of computation, Visualization techniques},
	pages = {833--860},
}

@inproceedings{ferdowsifard_small-step_2020,
	title = {Small-step live programming by example},
	url = {http://dx.doi.org/10.1145/3379337.3415869},
	doi = {10.1145/3379337.3415869},
	abstract = {Live programming is a paradigm in which the programming environment continually displays runtime values. Program synthesis is a technique that can generate programs or program snippets from examples. {\textbackslash}deltextThis paper presents a new programming paradigm called Synthesis-Aided Live Programming that combines these two prior ideas in a synergistic way. When using Synthesis-Aided Live Programming, programmers can change the runtime values displayed by the live {\textbackslash}addtextPrevious works that combine the two have taken a holistic approach to the way examples describe the behavior of functions and programs. This paper presents a new programming paradigm called Small-Step Live Programming by Example that lets the user apply Programming by Example locally. When using Small-Step Live Programming by Example, programmers can change the runtime values displayed by the live visualization to generate local program snippets. \% Live programming and program \% synthesis work perfectly together because the live programming environment \% reifies values, which makes it easy for programmers to provide the examples \% needed by the synthesizer. We implemented this new paradigm in a tool called {\textbackslash}toolname, and performed a user study on \$13\$ programmers. Our study finds that Small-Step Live Programming by Example with {\textbackslash}toolname helps users solve harder problems faster, and that for certain types of queries, users prefer it to searching the web. Additionally, we identify the {\textbackslash}usersynthgap, in which users' mental models of the tool do not match its ability, and needs to be taken into account in the design of future synthesis tools.},
	booktitle = {{UIST} 2020 - {Proceedings} of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Ferdowsifard, Kasra and Ordookhanians, Allen and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
	year = {2020},
	keywords = {Live programming, Program synthesis},
	pages = {614--626},
}

@article{wilkinson_grammar_2012,
	title = {The {Grammar} of {Graphics}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-21551-3_13},
	doi = {10.1007/978-3-642-21551-3_13},
	abstract = {The Grammar of Graphics, or GOG, denotes a system with seven orthogonal components. By orthogonal, we mean there are seven graphical component sets whose elements are aspects of the general system and that every combination of aspects in the product of all these sets is meaningful. This sense of the word orthogonality, a term used by computer designers to describe a combinatoric system of components or building blocks, is in some sense similar to the orthogonal factorial analysis of variance (ANOVA), where factors have levels and all possible combinations of levels exist in the ANOVA design. If we interpret each combination of features in a GOG system as a point in a network, then the world described by GOG is represented in a seven-dimensional rectangular lattice.},
	journal = {Handbook of Computational Statistics},
	author = {Wilkinson, Leland},
	year = {2012},
	pages = {375--414},
}

@article{hurley_solving_2010,
	title = {Solving problems using matrix, network, and hierarchy diagrams: {The} consequences of violating construction conventions},
	volume = {63},
	issn = {17470218},
	url = {https://journals.sagepub.com/doi/10.1080/17470210902888908},
	doi = {10.1080/17470210902888908},
	abstract = {In order for a diagram to be useful for solving a problem, it must be constructed so that its perceptual features facilitate inferences relevant to that problem. In Experiment 1, we established the construction conventions, which relate to how information is assigned to different parts of the diagram, for three spatial representations-networks, hierarchies, and matrices. In Experiment 2, participants solved problems using diagrams that either followed or violated these conventions. As hypothesized, participants took longer to draw inferences from convention-violating matrix and network diagrams than from their convention-following counterparts, and these inferences were less accurate. Convention adherence did not affect reasoning time or accuracy for hierarchy diagrams. The authors concluded that the construction conventions are related to perceptual features that facilitate certain types of inferences for matrix and network diagrams, and they discussed why this might not have been the case for the hierarchy. © 2009 The Experimental Psychology Society.},
	number = {2},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Hurley, Sean M. and Novick, Laura R.},
	year = {2010},
	keywords = {Conventions, Diagrams, Problem solving, Representations},
	pages = {275--290},
}

@article{hempel_semi-automated_2016,
	title = {Semi-automated {SVG} programming via direct manipulation},
	doi = {10.1145/2984511.2984575},
	abstract = {Direct manipulation interfaces provide intuitive and interactive features to a broad range of users, but they often exhibit two limitations: the built-in features cannot possibly cover all use cases, and the internal representation of the content is not readily exposed. We believe that if direct manipulation interfaces were to (a) use general-purpose programs as the representation format, and (b) expose those programs to the user, then experts could customize these systems in powerful new ways and non-experts could enjoy some of the benefits of programmable systems. In recent work, we presented a prototype SVG editor called Sketch-n-Sketch that offered a step towards this vision. In that system, the user wrote a program in a general-purpose lambda-calculus to generate a graphic design and could then directly manipulate the output to indirectly change design parameters (i.e. constant literals) in the program in real-time during the manipulation. Unfortunately, the burden of programming the desired relationships rested entirely on the user. In this paper, we design and implement new features for Sketch-n-Sketch that assist in the programming process itself. Like typical direct manipulation systems, our extended Sketch-n-Sketch now provides GUI-based tools for drawing shapes, relating shapes to each other, and grouping shapes together. Unlike typical systems, however, each tool carries out the user's intention by transforming their general-purpose program. This novel, semi-automated programming workflow allows the user to rapidly create highlevel, reusable abstractions in the program while at the same time retaining direct manipulation capabilities. In future work, our approach may be extended with more graphic design features or realized for other application domains.},
	journal = {UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
	author = {Hempel, Brian and Chugh, Ravi},
	year = {2016},
	keywords = {Direct manipulation, Live programming, SVG},
	pages = {379--390},
}

@article{ruan_closed-form_2022,
	title = {Closed-form {Minkowski} sums of convex bodies with smooth positively curved boundaries},
	volume = {143},
	issn = {0010-4485},
	doi = {10.1016/J.CAD.2021.103133},
	abstract = {This article derives closed-form parametric formulas for the Minkowski sums of convex bodies in d-dimensional Euclidean space with boundaries that are smooth and have all positive sectional curvatures at every point. Under these conditions, there is a unique relationship between the position of each boundary point and the surface normal. The main results are presented as two theorems. The first theorem directly parameterizes Minkowski sum boundaries using the unit normal vector at each surface point. Although simple to express mathematically, such a parameterization is not always practical to obtain computationally. Therefore, the second theorem derives a more useful parametric closed-form expression using the gradient that is not normalized. In the special case of two ellipsoids, the proposed expressions are identical to those derived previously using geometric interpretations. In order to examine the results, numerical validations and comparisons of the Minkowski sums between two superquadric bodies are conducted. Applications to generate configuration space obstacles in motion planning problems and to improve optimization-based collision detection algorithms are introduced and demonstrated.},
	journal = {Computer-Aided Design},
	author = {Ruan, Sipu and Chirikjian, Gregory S.},
	year = {2022},
	keywords = {Computational geometry, Computer-aided design, Minkowski sums},
	pages = {103133},
}

@book{rosen_discrete_1999,
	edition = {7th},
	title = {Discrete mathematics \& applications},
	isbn = {978-0-07-338309-5},
	publisher = {McGraw-Hill},
	author = {Rosen, Kenneth H},
	year = {1999},
}

@article{boming_thinglab--constraint-oriented_1979,
	title = {Thinglab--{A} {Constraint}-{Oriented} {Simulation} {Laboratory}},
	journal = {Stanford Univ. report STANCS-79-746},
	author = {Boming, Alan},
	year = {1979},
}

@incollection{ericsson_influence_2006,
	address = {New York, NY, US},
	title = {The {Influence} of {Experience} and {Deliberate} {Practice} on the {Development} of {Superior} {Expert} {Performance}.},
	isbn = {0-521-60081-2 (Paperback); 0-521-84097-X (Hardcover); 978-0-521-60081-1 (Paperback); 978-0-521-84097-2 (Hardcover)},
	abstract = {In this chapter the author will review evidence on the effects of experience and deliberate practice on individual differences in the acquisition of skilled and expert performance. The author will first describe the traditional account of individual differences in performance based on experience and innate talent. Then the author will review evidence on the effects of various types of experience on performance, especially the effects of deliberate practice. In the last half of the chapter, the author will discuss how deliberate practice can account for the changes in the structure of the mechanisms that mediate the superior performance of experts. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	booktitle = {The {Cambridge} handbook of expertise and expert performance.},
	publisher = {Cambridge University Press},
	author = {Ericsson, K Anders},
	year = {2006},
	doi = {10.1017/CBO9780511816796.038},
	keywords = {*Experience Level, *Individual Differences, *Knowledge Level, *Performance, Skill Learning},
	pages = {683--703},
}

@article{koedinger_trade-offs_2008,
	title = {Trade-{Offs} {Between} {Grounded} and {Abstract} {Representations}: {Evidence} {From} {Algebra} {Problem} {Solving}},
	volume = {32},
	issn = {1551-6709},
	doi = {10.1080/03640210701863933},
	abstract = {This article explores the complementary strengths and weaknesses of grounded and abstract representations in the domain of early algebra. Abstract representations, such as algebraic symbols, are concise and easy to manipulate but are distanced from any physical referents. Grounded representations, such as verbal descriptions of situations, are more concrete and familiar, and they are more similar to physical objects and everyday experience. The complementary computational characteristics of grounded and abstract representations lead to trade-offs in problem-solving performance. In prior research with high school students solving relatively simple problems, Koedinger and Nathan (2004) demonstrated performance benefits of grounded representations over abstract representations - students were better at solving simple story problems than the analogous equations. This article extends this prior work to examine both simple and more complex problems in two samples of college students. On complex problems with two references to the unknown, a "symbolic advantage" emerged, such that students were better at solving equations than analogous story problems. Furthermore, the previously observed "verbal advantage" on simple problems was replicated. We thus provide empirical support for a trade-off between grounded, verbal representations, which show advantages on simpler problems, and abstract, symbolic representations, which show advantages on more complex problems.},
	number = {2},
	journal = {Cognitive Science},
	author = {Koedinger, Kenneth R. and Alibali, Martha W. and Nathan, Mitchell J.},
	year = {2008},
	keywords = {Abstraction, Algebra, External representation, Grounding, Problem solving},
	pages = {366--397},
}

@article{pantziara_using_2009,
	title = {Using diagrams as tools for the solution of non-routine mathematical problems},
	volume = {72},
	issn = {00131954},
	url = {https://link.springer.com/article/10.1007/s10649-009-9181-5},
	doi = {10.1007/S10649-009-9181-5/FIGURES/15},
	abstract = {The Mathematics education community has long recognized the importance of diagrams in the solution of mathematical problems. Particularly, it is stated that diagrams facilitate the solution of mathematical problems because they represent problems' structure and information (Novick \& Hurley, 2001; Diezmann, 2005). Novick and Hurley were the first to introduce three well-defined types of diagrams, that is, network, hierarchy, and matrix, which represent different problematic situations. In the present study, we investigated the effects of these types of diagrams in non-routine mathematical problem solving by contrasting students' abilities to solve problems with and without the presence of diagrams. Structural equation modeling affirmed the existence of two first-order factors indicating the differential effects of the problems' representation, i.e., text with diagrams and without diagrams, and a second-order factor representing general non-routine problem solving ability in mathematics. Implicative analysis showed the influence of the presence of diagrams in the problems' hierarchical ordering. Furthermore, results provided support for other studies (e.g. Diezman \& English, 2001) which documented some students' difficulties to use diagrams efficiently for the solution of problems. We discuss the findings and provide suggestions for the efficient use of diagrams in the problem solving situation. © Springer Science+Business Media B.V. 2009.},
	number = {1},
	journal = {Educational Studies in Mathematics},
	author = {Pantziara, Marilena and Gagatsis, Athanasios and Elia, Iliada},
	year = {2009},
	keywords = {Diagrams, Hierarchy, Implicative analysis, Matrix, Network, Non-routine problems, Structural equation modeling},
	pages = {39--60},
}

@inproceedings{barrett_measuring_2018,
	title = {Measuring abstract reasoning in neural networks},
	url = {https://proceedings.mlr.press/v80/barrett18a.html},
	abstract = {Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation ’regimes’ in which the training data and test questions differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model’s ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Barrett, David and Hill, Felix and Santoro, Adam and Morcos, Ari and Lillicrap, Timothy},
	editor = {Dy, Jennifer and Krause, Andreas},
	year = {2018},
	pages = {511--520},
}

@article{disessa_metarepresentation_2004,
	title = {Metarepresentation: {Native} competence and targets for instruction},
	volume = {22},
	issn = {07370008},
	doi = {10.1207/s1532690xci2203_2},
	abstract = {The premise of this article is that the study of representation is valuable and important for mathematics and science students. Learning about representation should go beyond learning specific, sanctioned representations emphasized in standard curricula (graphs, tables, etc.) to include principles and design strategies that apply to any scientific representation, including novel variations and even completely new representations. The article explores what it means to understand representation, what we believe students already know about the topic, and what they can profitably learn about it. The discussion includes learning difficulties - goals for instruction that appear challenging for students and may need particular attention.},
	number = {3},
	journal = {Cognition and Instruction},
	author = {DiSessa, Andrea A.},
	year = {2004},
	pages = {293--331},
}

@article{kurdi_systematic_2020,
	title = {A {Systematic} {Review} of {Automatic} {Question} {Generation} for {Educational} {Purposes}},
	volume = {30},
	issn = {15604306},
	url = {https://link.springer.com/article/10.1007/s40593-019-00186-y},
	doi = {10.1007/S40593-019-00186-Y/TABLES/17},
	abstract = {While exam-style questions are a fundamental educational tool serving a variety of purposes, manual construction of questions is a complex process that requires training, experience, and resources. This, in turn, hinders and slows down the use of educational activities (e.g. providing practice questions) and new advances (e.g. adaptive testing) that require a large pool of questions. To reduce the expenses associated with manual construction of questions and to satisfy the need for a continuous supply of new questions, automatic question generation (AQG) techniques were introduced. This review extends a previous review on AQG literature that has been published up to late 2014. It includes 93 papers that were between 2015 and early 2019 and tackle the automatic generation of questions for educational purposes. The aims of this review are to: provide an overview of the AQG community and its activities, summarise the current trends and advances in AQG, highlight the changes that the area has undergone in the recent years, and suggest areas for improvement and future opportunities for AQG. Similar to what was found previously, there is little focus in the current literature on generating questions of controlled difficulty, enriching question forms and structures, automating template construction, improving presentation, and generating feedback. Our findings also suggest the need to further improve experimental reporting, harmonise evaluation metrics, and investigate other evaluation methods that are more feasible.},
	number = {1},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Kurdi, Ghader and Leo, Jared and Parsia, Bijan and Sattler, Uli and Al-Emari, Salam},
	year = {2020},
	keywords = {Assessment, Automatic question generation, Difficulty prediction, Education, Natural language generation, Natural language processing, Semantic Web},
	pages = {121--204},
}

@article{myers_natural_2004,
	title = {Natural programming languages and environments},
	volume = {47},
	number = {9},
	journal = {Communications of the ACM},
	author = {Myers, Brad A and Pane, John F and Ko, Amy},
	year = {2004},
	pages = {47--52},
}

@article{li_whatwe_2021,
	title = {Whatwe can learn from visual artists about sofware development},
	doi = {10.1145/3411764.3445682},
	abstract = {This paper explores software's role in visual art production by examining how artists use and develop software. We conducted interviews with professional artists who were collaborating with software developers, learning software development, and building and maintaining software.We found artists were motivated to learn software development for intellectual growth and access to technical communities. Artists valued efcient workfows through skilled manual execution and personal software development, but avoided high-level forms of software automation. Artists identifed conficts between their priorities and those of professional developers and computational art communities, which infuenced how they used computational aesthetics in their work. These fndings contribute to eforts in systems engineering research to integrate end-user programming and creativity support across software and physical media, suggesting opportunities for artists as collaborators. Artists' experiences writing software can guide technical implementations of domain-specifc representations, and their experiences in interdisciplinary production can aid inclusive community building around computational tools.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Li, Jingyi and Hashim, Sonia and Jacobs, Jennifer},
	year = {2021},
	keywords = {Creativity support tools, Software development, Visual art},
}

@article{sannella_multi-way_1993,
	title = {Multi-way versus one-way constraints in user interfaces: {Experience} with the deltablue algorithm},
	volume = {23},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/spe.4380230507https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380230507https://onlinelibrary.wiley.com/doi/10.1002/spe.4380230507},
	doi = {10.1002/SPE.4380230507},
	abstract = {The efficient satisfaction of constraints is essential to the performance of constraint‐based user interfaces. In the past, most constraint‐based user interfaces have used one‐way rather than multi‐way constraints because of a widespread belief that one‐way constraints were more efficient. In this paper we argue that many user interface construction problems are handled more naturally and elegantly by multi‐way constraints than by one‐way constraints. We present pseudocode for an incremental multi‐way constraint satisfaction algorithm, DeltaBlue, and describe experience in using the algorithm in two user interface toolkits. Finally, we provide performance figures demonstrating that multi‐way constraint solvers can be entirely competitive in performance with one‐way constraint solvers. Copyright © 1993 John Wiley \& Sons, Ltd},
	number = {5},
	journal = {Software: Practice and Experience},
	author = {Sannella, Michael and Maloney, John and Freeman‐Benson, Bjorn and Borning, Alan},
	year = {1993},
	keywords = {Constraint satisfaction, Constraints, DeltaBlue, Local propagation, User interface implementation techniques},
	pages = {529--566},
}

@book{burger_holt_2007,
	title = {Holt geometry},
	publisher = {Holt, Rinehart and Winston},
	author = {Burger, Edward B and Chard, David J and Hall, Earlene J and Kennedy, Paul A and Leinwand, Steven J and Renfro, Freddie L and Seymour, Dale G and Wattis, Bert K},
	year = {2007},
}

@article{miltner_fly_2019,
	title = {On the fly synthesis of edit suggestions},
	volume = {3},
	issn = {2475-1421},
	url = {https://doi.org/10.1145/3360569},
	doi = {10.1145/3360569},
	abstract = {When working with a document, users often perform context-specific repetitive edits – changes to the document that are similar but specific to the contexts at their locations. Programming by demonstration/examples (PBD/PBE) systems automate these tasks by learning programs to perform the repetitive edits from demonstration or examples. However, PBD/PBE systems are not widely adopted, mainly because they require modal UIs – users must enter a special mode to give the demonstration/examples. This paper presents Blue-Pencil, a modeless system for synthesizing edit suggestions on the fly. Blue-Pencil observes users as they make changes to the document, silently identifies repetitive changes, and automatically suggests transformations that can apply at other locations. Blue-Pencil is parameterized – it allows the ”plug-and-play” of different PBE engines to support different document types and different kinds of transformations. We demonstrate this parameterization by instantiating Blue-Pencil to several domains – C\# and SQL code, markdown documents, and spreadsheets – using various existing PBE engines. Our evaluation on 37 code editing sessions shows that Blue-Pencil synthesized edit suggestions with a precision of 0.89 and a recall of 1.0, and took 199 ms to return suggestions on average. Finally, we report on several improvements based on feedback gleaned from a field study with professional programmers to investigate the use of Blue-Pencil during long code editing sessions. Blue-Pencil has been integrated with Visual Studio IntelliCode to power the IntelliCode refactorings feature.},
	number = {OOPSLA},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Miltner, Anders and Gulwani, Sumit and Le, Vu and Leung, Alan and Radhakrishna, Arjun and Soares, Gustavo and Tiwari, Ashish and Udupa, Abhishek},
	year = {2019},
	keywords = {Program synthesis, Program transformation, Programming by example, Refactoring},
	pages = {1--29},
}

@article{ayabe_problem-appropriate_2022,
	title = {Problem-appropriate diagram instruction for improving mathematical word problem solving},
	volume = {13},
	issn = {16641078},
	doi = {10.3389/fpsyg.2022.992625},
	abstract = {The use of diagrams can be effective in solving mathematical word problems solving. However, students worldwide do not construct diagrams unprompted or have trouble using them. In the present study, the effects of problem-appropriate diagram use instruction were investigated with an adaptation of the multiple baseline design method. The instruction for using line diagrams, tables, and graphs was provided to 67 junior high school students in a staggered manner and the effects on problem solving of three different types of problems was examined. The results showed that use of problem-appropriate diagrams increased and persisted over time. More importantly, the instruction led to increases in problem solving performance and to decreases in perceived cognitive load. These findings support the argument that effective diagram use depends on the acquisition not only of declarative knowledge, but also sufficient procedural and conditional knowledge.},
	journal = {Frontiers in Psychology},
	author = {Ayabe, Hiroaki and Manalo, Emmanuel and Vries, Erica de},
	year = {2022},
	keywords = {Japanese students, cognitive load, instructional methods, mathematical word problem solving, multiple baseline design, representational effect, self-constructed diagrams, visual representation},
	pages = {6113},
}

@article{cox_review_2021,
	title = {A {Review} of {Methods} to {Compute} {Minkowski} {Operations} for {Geometric} {Overlap} {Detection}},
	volume = {27},
	issn = {19410506},
	doi = {10.1109/TVCG.2020.2976922},
	abstract = {This article provides an extensive review of algorithms for constructing Minkowski sums and differences of polygons and polyhedra, both convex and non-convex, commonly known as no-fit polygons and configuration space obstacles. The Minkowski difference is a set operation, which when applied to shapes defines a method for efficient overlap detection, providing an important tool in packing and motion-planning problems. This is the first complete review on this specific topic, and aims to unify algorithms spread over the literature of separate disciplines.},
	number = {8},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cox, Wesley and While, Lyndon and Reynolds, Mark},
	year = {2021},
	keywords = {Collision avoidance, computational geometry, configuration space, minkowski sum, no-fit polygon, reviews},
	pages = {3377--3396},
}

@book{burger_holt_2007-1,
	title = {Holt geometry},
	publisher = {Holt, Rinehart and Winston},
	author = {Burger, Edward B and Chard, David J and Hall, Earlene J and Kennedy, Paul A and Leinwand, Steven J and Renfro, Freddie L and Seymour, Dale G and Wattis, Bert K},
	year = {2007},
}

@inproceedings{wang_automatic_2015,
	title = {Automatic generation of {Raven}'s progressive {Matrices}},
	abstract = {Raven's Progressive Matrices (RPMs) are a popular family of general intelligence tests, and provide a non-verbal measure of a test subject's reasoning abilities. Traditionally RPMs have been manually designed. To make them readily available for both practice and examination, we tackle the problem of automatically synthesizing RPMs. Our goal is to efficiently generate a large number of RPMs that are authentic (i.e. similar to manually written problems), interesting (i.e. diverse in terms of difficulty), and well-formed (i.e. unambiguous). The main technical challenges are: How to formalize RPMs to accommodate their seemingly enormous diversity, and how to define and enforce their validity? To this end, we (1) introduce an abstract representation of RPMs using first-order logic, and (2) restrict instantiations to only valid RPMs. We have realized our approach and evaluated its efficiency and effectiveness. We show that our system can generate hundreds of valid problems per second with varying levels of difficulty. More importantly, we show, via a user study with 24 participants, that the generated problems are statistically indistinguishable from actual problems. This work is an exciting instance of how logic and reasoning may aid general learning.},
	booktitle = {{IJCAI} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Wang, Ke and Su, Zhendong},
	year = {2015},
	keywords = {Reasoning, Technical Papers — Knowledge Representation, and Logic},
	pages = {903--909},
}

@article{novick_evidence_1999,
	title = {Evidence for abstract, schematic knowledge of three spatial diagram representations},
	volume = {27},
	issn = {1532-5946},
	url = {https://link.springer.com/article/10.3758/BF03211413},
	doi = {10.3758/BF03211413},
	abstract = {Spatial diagram representations such as hierarchies, matrices, and networks are important tools for thinking. Our data suggest that college students possess abstract schemas for these representations that include at least rudimentary information about their applicability conditions. In Experiment 1, subjects were better able to select the appropriate spatial diagram representation for a problem when cued to use general category information in memory about those representations than when cued to use specific example problems given during the experiment. The results of Experiment 2 showed that the superior performance in the general category condition was not based on a comparison of the test problems with examples in memory. The results of Experiment 3 showed that the superior performance was not due to learning that occurred during the experiment or to transfer appropriate processing. The General Discussion section considers the nature of students’ representation schemas and the question of why college students have only rudimentary schemas for common and widely applicable diagrammatic representations.},
	number = {2},
	journal = {Memory \& Cognition 1999 27:2},
	author = {Novick, Laura R. and Hurley, Sean M. and Francis, Melissa},
	year = {1999},
	keywords = {Cognitive Psychology},
	pages = {288--308},
}

@article{rau_framework_2017,
	title = {A {Framework} for {Educational} {Technologies} that {Support} {Representational} {Competencies}},
	volume = {10},
	issn = {19391382},
	doi = {10.1109/TLT.2016.2623303},
	abstract = {Visual representations are ubiquitous in STEM disciplines. Yet, students' difficulties in learning with visual representations are well documented. Therefore, to succeed in STEM, students need representational competencies - the ability to use visual representations for problem solving and learning. Educational technologies that support students' acquisition of representational competencies can significantly enhance their success in STEM disciplines. Current design frameworks for educational technologies do not offer sufficient guidance to develop supports for representational competencies. This paper presents a new design framework that describes an iterative, step-by-step approach for the design of educational technologies that support representational competencies (SUREC) in a way that aligns with the demands specific to the target discipline. The paper illustrates how this framework was used to inform the design of an intelligent tutoring system for undergraduate chemistry. An evaluation study suggests that the SUREC framework yielded an effective educational technology that enhances students' learning of content knowledge.},
	number = {3},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Rau, Martina Angela},
	year = {2017},
	keywords = {Educational technologies, discipline-based research, multiple representations, representational competencies},
	pages = {290--305},
}

@inproceedings{lerner_projection_2020,
	title = {Projection {Boxes}: {On}-the-fly {Reconfigurable} {Visualization} for {Live} {Programming}},
	url = {https://doi.org/10.1145/3313831.3376494},
	doi = {10.1145/3313831.3376494},
	abstract = {Live programming is a regime in which the programming environment provides continual feedback, most often in the form of runtime values. In this paper, we present Projection Boxes, a novel visualization technique for displaying runtime values of programs. The key idea behind projection boxes is to start with a full semantics of the program, and then use projections to pick a subset of the semantics to display. By varying the projection used, projection boxes can encode both previously known visualization techniques, and also new ones. As such, projection boxes provide an expressive and configurable framework for displaying runtime information. Through a user study we demonstrate that (1) users find projection boxes and their configurability useful (2) users are not distracted by the always-on visualization (3) a key driving force behind the need for a configurable visualization for live programming lies with the wide variation in programmer preferences.},
	booktitle = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Lerner, Sorin},
	year = {2020},
	keywords = {debugging, live programming, program visualization, programming environment},
}

@article{vanlehn_behavior_2006,
	title = {The {Behavior} of {Tutoring} {Systems}},
	volume = {16},
	issn = {1560-4292},
	number = {3},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {VanLehn, Kurt},
	year = {2006},
	pages = {227--265},
}

@article{myers_easily_1996,
	title = {Easily adding animations to interfaces using constraints},
	doi = {10.1145/237091.237109},
	abstract = {Adding animation to interfaces is a very difficult task with today's toolkits, even though there are many situations in which it would be useful and effective. The Amulet toolkit contains a new form of animation constraint that allows animations to be added to interfaces extremely easily without changing the logic of the application or the graphical objects themselves. An animation constraint detects changes to the value of the slot to which it is attached, and causes the slot to instead take on a series of values interpolated between the original and new values. The advantage over previous approaches is that animation constraints provide significantly better modularity and reuse. The programmer has independent control over the graphics to be animated, the start and end values of the animation, the path through value space, and the timing of the animation. Animations can be attached to any object, even existing widgets from the toolkit, and any type of value can be animated: scalars, coordinates, fonts, colors, line widths, point lists (for polygons), booleans (for visibility), etc. A library of useful animation constraints is provided in the toolkit, including support for exaggerated, cartoon-style effects such as slow-in-slow-out, anticipation, and follow-through. Because animations can be added to an existing application with only a single extra line of code, we expect that this new mechanism will make it easy for researchers and developers to investigate the use of animations in a wide variety of applications.},
	journal = {UIST (User Interface Software and Technology): Proceedings of the ACM Symposium},
	author = {Myers, Brad A. and Miller, Robert C. and McDaniel, Rich and Ferrency, Alan},
	year = {1996},
	pages = {119--128},
}

@article{hornke_rule-based_1986,
	title = {Rule-{Based} {Item} {Bank} {Construction} and {Evaluation} {Within} the {Linear} {Logistic} {Framework}},
	volume = {10},
	issn = {15523497},
	url = {https://journals.sagepub.com/doi/10.1177/014662168601000405},
	doi = {10.1177/014662168601000405},
	abstract = {In cognition research, item writing rules are consid ered a necessary prerequisite of item banking. A set of 636 items was constructed using prespecified cognitive operations. An evaluation of test data from some 7,400 examinees revealed 446 homogeneous items. Some items had to be discarded because of printing flaws, and others because of operation complexion or other well-describable reasons. However, cognitive operations explained item difficulty parameters quite well; further cross-validation research may contribute to an item writing approach which attempts to bring psychological theory and psychometric models closer together. This will eventually free item construction from item writer idiosyncrasies. © 1986, Sage Publications. All rights reserved.},
	number = {4},
	journal = {Applied Psychological Measurement},
	author = {Hornke, Lutz F. and Habon, Michael W.},
	year = {1986},
	pages = {369--380},
}

@inproceedings{nathan_representational_2002,
	title = {Representational fluency in middle school: {A} classroom study},
	booktitle = {Proceedings of the twenty-fourth annual meeting of the {North} {American} chapter of the {International} {Group} for the {Psychology} of {Mathematics} {Education}},
	author = {Nathan, Mitchell J and Stephens, Ana C and Masarik, D K and Alibali, Martha W and Koedinger, Kenneth R},
	year = {2002},
	pages = {462--472},
}

@incollection{tversky_thinking_2009,
	title = {Thinking with {Sketches}},
	isbn = {978-0-19-987026-4},
	url = {https://academic.oup.com/book/7628/chapter/152650177},
	abstract = {Sketches serve to externalize ideas, render fleeting ideas permanent, confer coherence on scattered concepts, and turn internal thoughts public. They can be created and recreated, examined and re-examined, configured and reconfigured, considered and reconsidered, for clarity and for creativity. The schematic vocabulary of sketches allows both expression and discovery of ideas. Sketching is integral to design, where vagueness encourages reinterpretation and discourages fixation. Using sketches to those ends requires constructive perception, a combination of a perceptual skill of reconfiguring and a cognitive skill of finding remote associations.},
	booktitle = {Tools for {Innovation}},
	publisher = {Oxford University Press},
	author = {Tversky, Barbara and Suwa, Masaki},
	year = {2009},
	doi = {10.1093/acprof:oso/9780195381634.003.0004},
	keywords = {Creativity, Design, Diagram, Discovery, Reconfigure, Sketch},
}

@article{edwards_coherent_2009,
	title = {Coherent reaction},
	url = {https://dl.acm.org/doi/10.1145/1639950.1640058},
	doi = {10.1145/1639950.1640058},
	abstract = {Side effects are both the essence and bane of imperative programming. The programmer must carefully coordinate actions to manage their side effects upon each other. Such coordination is complex, error-prone, and fragile. Coherent reaction is a new model of change-driven computation that coordinates effects automatically. State changes trigger events called reactions that in turn change other states. A coherent execution order is one in which each reaction executes before any others that are affected by its changes. A coherent order is discovered iteratively by detecting incoherencies as they occur and backtracking their effects. Unlike alternative solutions, much of the power of imperative programming is retained, as is the common sense notion of mutable state. Automatically coordinating actions lets the programmer express what to do, not when to do it. Coherent reactions are embodied in the Coherence language, which is specialized for interactive applications like those common on the desktop and web. The fundamental building block of Coherence is the dynamically typed mutable tree. The fundamental abstraction mechanism is the virtual tree, whose value is lazily computed, and whose behavior is generated by coherent reactions. Copyright © 2009 ACM.},
	journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
	author = {Edwards, Jonathan},
	year = {2009},
	keywords = {Bidirectional functions, Functional reactive programming, Interactive systems, Reactive systems, Synchronous reactive programming, Trees},
	pages = {925--932},
}

@article{paas_variability_1994,
	title = {Variability of {Worked} {Examples} and {Transfer} of {Geometrical} {Problem}-{Solving} {Skills}: {A} {Cognitive}-{Load} {Approach}},
	volume = {86},
	issn = {00220663},
	doi = {10.1037/0022-0663.86.1.122},
	abstract = {Four computer-based training strategies for geometrical problem solving in the domain of computer numerically controlled machinery programming were studied with regard to their effects on training performance, transfer performance, and cognitive load. A low- and a high-variability conventional condition, in which conventional practice problems had to be solved (followed by worked examples), were compared with a low- and a high-variability worked condition, in which worked examples had to be studied. Results showed that students who studied worked examples gained most from high-variability examples, invested less time and mental effort in practice, and attained better and less effort-demanding transfer performance than students who first attempted to solve conventional problems and then studied work examples.},
	number = {1},
	journal = {Journal of Educational Psychology},
	author = {Paas, Fred G.W.C. and Van Merriënboer, Jeroen J.G.},
	year = {1994},
	pages = {122--133},
}

@incollection{chik_simultaneity_2004,
	title = {Simultaneity and the enacted object of learning},
	isbn = {0-8058-4009-5},
	booktitle = {Classroom {Discourse} and the {Space} of {Learning}},
	publisher = {Routledge},
	author = {Chik, Pakey P.M. and Lo, Mun Ling},
	year = {2004},
	doi = {10.4324/9781410609762},
	pages = {89--112},
}

@article{Tversky2011,
	title = {Visualizing {Thought}},
	volume = {3},
	issn = {1756-8757},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1756-8765.2010.01113.x},
	doi = {10.1111/j.1756-8765.2010.01113.x},
	abstract = {{\textless}p{\textgreater} Depictive expressions of thought predate written language by thousands of years. They have evolved in communities through a kind of informal user testing that has refined them. Analyzing common visual communications reveals consistencies that illuminate how people think as well as guide design; the process can be brought into the laboratory and accelerated. Like language, visual communications abstract and schematize; unlike language, they use properties of the page (e.g., proximity and place: center, horizontal/up–down, vertical/left–right) and the marks on it (e.g., dots, lines, arrows, boxes, blobs, likenesses, symbols) to convey meanings. The visual expressions of these meanings (e.g., individual, category, order, relation, correspondence, continuum, hierarchy) have analogs in language, gesture, and especially in the patterns that are created when people design the world around them, arranging things into piles and rows and hierarchies and arrays, spatial‐abstraction‐action interconnections termed {\textless}italic{\textgreater}spractions{\textless}/italic{\textgreater} . The designed world is a diagram. {\textless}/p{\textgreater}},
	number = {3},
	urldate = {2022-03-05},
	journal = {Topics in Cognitive Science},
	author = {Tversky, Barbara},
	month = jul,
	year = {2011},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Action, Analogy, Diagrams, Gesture, Metaphor, Spatial cognition, Visual communication},
	pages = {499--535},
}

@incollection{Tversky2009,
	title = {Thinking with {Sketches}},
	isbn = {978-0-19-987026-4},
	url = {https://academic.oup.com/book/7628/chapter/152650177},
	abstract = {Sketches serve to externalize ideas, render fleeting ideas permanent, confer coherence on scattered concepts, and turn internal thoughts public. They can be created and recreated, examined and re-examined, configured and reconfigured, considered and reconsidered, for clarity and for creativity. The schematic vocabulary of sketches allows both expression and discovery of ideas. Sketching is integral to design, where vagueness encourages reinterpretation and discourages fixation. Using sketches to those ends requires constructive perception, a combination of a perceptual skill of reconfiguring and a cognitive skill of finding remote associations.},
	urldate = {2024-03-18},
	booktitle = {Tools for {Innovation}},
	publisher = {Oxford University Press},
	author = {Tversky, Barbara and Suwa, Masaki},
	month = sep,
	year = {2009},
	doi = {10.1093/acprof:oso/9780195381634.003.0004},
	keywords = {Creativity, Design, Diagram, Discovery, Reconfigure, Sketch},
}

@inproceedings{Cohen2019,
	title = {Designing declarative language tutorials: {A} guided and individualized approach},
	volume = {76},
	isbn = {978-3-95977-135-1},
	doi = {10.4230/OASIcs.PLATEAU.2019.4},
	abstract = {The ability to declare what a program should include rather than how these features should be implemented makes declarative languages very useful in many visual output programs. The wide-ranging uses of these programs, in domains ranging from architecture to web programming to data visualization, encourages us to find an effective method to teach them. Traditional tutorial systems are usually non-interactive and have a gap between the learning and application. This can leave the user frustrated without a way to move forward in the learning process. A general lack of guidance can lead the student down an incorrect path. To prevent these difficulties, we propose a guided tour followed by novel question types that both direct the student’s learning and creates a focused environment to practice individual skills. Lastly, we propose a study to test the hypothesis that this tutorial is quicker to complete and results in a greater understanding of the declarative language.},
	booktitle = {10th {Workshop} on {Evaluation} and {Usability} of {Programming} {Languages} and {Tools} ({PLATEAU} 2019)},
	author = {Cohen, A.K. and Ni, W. and Sunshine, J.},
	year = {2019},
	note = {ISSN: 21906807},
	keywords = {Declarative programming, Programming language tutorial, Visualizations},
}

@book{Carter2009,
	title = {Visual {Group} {Theory}},
	volume = {32},
	isbn = {978-0-88385-757-1},
	url = {https://www.ams.org/clrm/032},
	abstract = {This book is ideal for a student beginning a first course in group theory. It can be used in place of a traditional textbook, or as a supplement to one, but its aim is quite different than that of a traditional text. Most textbooks present the theory of groups using theorems, proofs, and examples. Their exercises teach you how to make conjectures about groups and prove or refute them. This book, however, teaches you to know groups. You will see them, experiment with them, and understand their significance. The mental library of images and intuitions you gain from reading this book will enable you to appreciate far better the facts and proofs in a traditional text.},
	urldate = {2023-02-10},
	publisher = {American Mathematical Society},
	author = {Carter, Nathan},
	year = {2009},
	doi = {10.1090/clrm/032},
	note = {Publication Title: Visual Group Theory},
}

@article{Rittle-Johnson2001a,
	title = {Developing conceptual understanding and procedural skill in mathematics: {An} iterative process},
	volume = {93},
	issn = {00220663},
	doi = {10.1037/0022-0663.93.2.346},
	abstract = {The authors propose that conceptual and procedural knowledge develop in an iterative fashion and that improved problem representation is 1 mechanism underlying the relations between them. Two experiments were conducted with 5th- and 6th-grade students learning about decimal fractions. In Experiment 1, children's initial conceptual knowledge predicted gains in procedural knowledge, and gains in procedural knowledge predicted improvements in conceptual knowledge. Correct problem representations mediated the relation between initial conceptual knowledge and improved procedural knowledge. In Experiment 2, amount of support for correct problem representation was experimentally manipulated, and the manipulations led to gains in procedural knowledge. Thus, conceptual and procedural knowledge develop iteratively, and improved problem representation is 1 mechanism in this process.},
	number = {2},
	journal = {Journal of Educational Psychology},
	author = {Rittle-Johnson, Bethany and Siegler, Robert S. and Alibali, Martha Wagner},
	year = {2001},
	pages = {346--362},
}

@article{tversky_representing_2012,
	title = {Representing category and continuum: {Visualizing} thought},
	volume = {7352 LNAI},
	issn = {03029743},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-31223-6_8},
	doi = {10.1007/978-3-642-31223-6_8/COVER},
	abstract = {Abstract thought has roots in the spatial world. Abstractions are expressed in the ways things are arranged in the world as well as the ways people talk and gesture. Mappings to the page should be better when they are congruent, that is, when the abstract concept matches the spatial one. Congruent mappings can be revealed in people's performance and preferences. Congruence is supported here for visual representations of continuum and category. Congruently mapping a continuous concept, frequency, to a continuous visual variable and mapping a categorical concept, class inclusion, to a categorical visual variable were preferred and led to better performance than the reverse mappings. © 2012 Springer-Verlag.},
	urldate = {2024-03-18},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Tversky, Barbara and Corter, James E. and Yu, Lixiu and Mason, David L. and Nickerson, Jeffrey V.},
	year = {2012},
	note = {Publisher: Springer, Berlin, Heidelberg},
	keywords = {design, diagrams, information systems, networks, reasoning, spatial metaphors},
	pages = {23--34},
}

@article{Imhof1975,
	title = {Positioning names on maps},
	volume = {2},
	issn = {00941689},
	url = {https://www.tandfonline.com/doi/abs/10.1559/152304075784313304},
	doi = {10.1559/152304075784313304},
	abstract = {Prof. Dr. Eduard Imhof, dean of European cartographers, has been an astute student of the esthetic-scientific characteristics of the cartographic method. In this paper published 13 years ago, he draws upon his long experience in map design and production to formulate a series of precepts about positioning or locating the lettering on maps in relation to the various functional aspects of the map and the individual named features. Noting that legibility and clarity of the map depend on good name positioning—each name having only one optimum position on the map—he encourages the use of a graphic draft of lettering to determine this position. © 1975 Taylor \& Francis Group, LLC.},
	number = {2},
	urldate = {2024-01-23},
	journal = {American Cartographer},
	author = {Imhof, Eduard},
	month = jan,
	year = {1975},
	note = {Publisher: Taylor \& Francis Group},
	pages = {128--144},
}

@article{allen1999mixedinitiative,
	title = {Mixed-initiative interaction},
	volume = {14},
	issn = {10947167},
	doi = {10.1109/5254.796083},
	abstract = {Research in mixed-initiative interaction is still in its infancy, and the research problems we will face are significant. The potential impact of such systems, however, cannot be overestimated. If we are ever to build computer systems that can seamlessly interact with humans as they perform complex tasks, these systems will need to support effective mixed-initiative interaction.},
	number = {5},
	urldate = {2024-02-14},
	journal = {IEEE Intelligent Systems and Their Applications},
	author = {Allen, James E {and} Guinn, Curry I {and} Horvtz, Eric},
	year = {1999},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	pages = {14--16},
}

@misc{belouadi2024automatikz,
	title = {{AutomaTikZ}: {Text}-{Guided} {Synthesis} of {Scientific} {Vector} {Graphics} with {TikZ}},
	author = {Belouadi, Jonas and Lauscher, Anne and Eger, Steffen},
	year = {2024},
	note = {arXiv: cs.CL/2310.00367},
}

@inproceedings{He2022,
	title = {Parameterized {Interior} {Floor} {Plan} {Design} {Based} on {Differentiable} {Renderer}},
	volume = {951 LNEE},
	isbn = {978-981-19622-5-7},
	url = {https://link.springer.com/chapter/10.1007/978-981-19-6226-4_14},
	doi = {10.1007/978-981-19-6226-4_14},
	abstract = {Creating floor plans for indoor scenes is a fundamental task of architecture and interior design. Since a high-quality floor plan requires proper space division and location distribution for rooms inside the scene, such a task always require professional designers to spend huge efforts and workloads. In this paper, we intend to leverage the artificial intelligence method to relieve the manual work of interior floor plan design. Specifically, we employ the differentiable renderer, which is an optimizer that adjusts the parameters of certainly given mesh primitives. The optimization process is under the constraints of the input outer boundary, overlap, and weights, to ensure the design is parameterized, and suitable for interior floor plans with plausible space division. We also provide post-processing to refine the optimized mesh primitives and convert them to an interior floor plan. We conduct both ablation and controlled experiments to verify the effectiveness of our method in floor plan design.},
	urldate = {2024-01-23},
	booktitle = {Lecture {Notes} in {Electrical} {Engineering}},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	author = {He, Shuhan and Fu, Qiang and Li, Xueming},
	year = {2022},
	note = {ISSN: 18761119},
	keywords = {Computer-aided design, Differentiable renderer, Floor plan synthesis},
	pages = {132--141},
}

@article{koedinger_learning_2015,
	title = {Learning is not a spectator sport: {Doing} is better than watching for learning from a {MOOC}},
	url = {https://dl.acm.org/doi/10.1145/2724660.2724681},
	doi = {10.1145/2724660.2724681},
	abstract = {The printing press long ago and the computer today have made widespread access to information possible. Learning theorists have suggested, however, that mere information is a poor way to learn. Instead, more effective learning comes through doing. While the most popularized element of today's MOOCs are the video lectures, many MOOCs also include interactive activities that can afford learning by doing. This paper explores the learning benefits of the use of informational assets (e.g., videos and text) in MOOCs, versus the learning by doing opportunities that interactive activities provide. We find that students doing more activities learn more than students watching more videos or reading more pages. We estimate the learning benefit from extra doing (1 SD increase) to be more than six times that of extra watching or reading. Our data, from a psychology MOOC, is correlational in character, however we employ causal inference mechanisms to lend support for the claim that the associations we find are causal.},
	urldate = {2024-02-10},
	journal = {L@S 2015 - 2nd ACM Conference on Learning at Scale},
	author = {Koedinger, Kenneth R. and McLaughlin, Elizabeth A. and Kim, Jihee and Jia, Julianna Zhuxin and Bier, Norman L.},
	month = mar,
	year = {2015},
	note = {Publisher: Association for Computing Machinery
ISBN: 9781450334112},
	keywords = {Course effectiveness, Learning by doing, Learning prediction, MOOCs, OER, Open education},
	pages = {111--120},
}

@article{Fogel2009,
	title = {On the exact maximum complexity of {Minkowski} sums of polytopes},
	volume = {42},
	issn = {01795376},
	url = {https://link.springer.com/article/10.1007/s00454-009-9159-1},
	doi = {10.1007/s00454-009-9159-1},
	abstract = {We present a tight bound On the exact maximum complexity of Minkowski sums of polytopes in ℝ3. In particular, we prove that the maximum number of facets of the Minkowski sum of k polytopes with m1,m2,...,mk facets, respectively, is bounded from above by. Given k positive integers m1,m2,...,mk, we describe how to construct k polytopes with corresponding number of facets, such that the number of facets of their Minkowski sum is exactly. When k=2, for example, the expression above reduces to 4m1m2-9m1-9m2+26. © Springer Science+Business Media, LLC 2009.},
	number = {4},
	urldate = {2024-01-23},
	journal = {Discrete and Computational Geometry},
	author = {Fogel, Efi and Halperin, Dan and Weibel, Christophe},
	month = oct,
	year = {2009},
	note = {Publisher: Springer},
	keywords = {Complexity, Gaussian maps, Minkowski sum, Polyhedra},
	pages = {654--669},
}

@article{Mulero2007,
	title = {Two-dimensional {Minkowski} sum optimization of ganged stamping blank layouts for use on pre-cut sheet metal for convex and concave parts},
	volume = {26},
	issn = {02786125},
	doi = {10.1016/j.jmsy.2007.10.001},
	abstract = {With the increasing number of parts that manufacturers need to place on a piece of material such as sheet metal, the need increases for more sophisticated algorithms for part orientation and spacing. With greater part shape complexity, the ability of a skilled worker is challenged to minimize waste. Building on the previous work of Nye, this paper presents a Minkowski sum method for maximizing the number of parts within gangs on a rectangular sheet of material. The example provided uses a simply shaped part to illustrate the presented method, yielding a packing efficiency of 62\% that is identical to the efficiency that a skilled worker would produce without the algorithm. The paper also provides results for laying out a more complex part in ganged sections, demonstrating a result that would be difficult for a human to reproduce. This work extends that of Nye by adding practical constraints such as the number of parts that can be blanked at once as well as the amount of horizontal and vertical spacing between ganged blanking sets. Additionally, the paper adds an algorithm for laying out polygons with concave geometries by separating the part into a set of convex polygons. Two examples for optimization, one of a chevron-shaped part and one of a complex shape previously used by Nye [Nye TJ. Stamping strip layout for optimal raw material utilization. Journal of Manufacturing Systems 2000;19(4):239-46] and Choi et al. [Choi JC, Kim BM, Cho HY, Kim C. A compact and practical CAD system for blanking or piercing of irregular-shaped sheet metal products and stator and rotor parts. International Journal of Machine Tools \& Manufacture 1998;38:931-63], are provided, demonstrating the existence of a local maximum number of parts that may be stamped within a single ganged blank. The algorithm is extendable to a program that may provide stamping manufacturers with a tool that can maximize the total number of parts stamped on stock sheet metal, or for other tiling problems. © 2008 The Society of Manufacturing Engineers.},
	number = {1},
	urldate = {2024-01-23},
	journal = {Journal of Manufacturing Systems},
	author = {Mulero, Rafael and Layton, Bradley},
	month = jan,
	year = {2007},
	note = {Publisher: Elsevier},
	pages = {44--52},
}

@article{ruan_closed-form_2022-1,
	title = {Closed-form {Minkowski} sums of convex bodies with smooth positively curved boundaries},
	volume = {143},
	issn = {0010-4485},
	doi = {10.1016/J.CAD.2021.103133},
	abstract = {This article derives closed-form parametric formulas for the Minkowski sums of convex bodies in d-dimensional Euclidean space with boundaries that are smooth and have all positive sectional curvatures at every point. Under these conditions, there is a unique relationship between the position of each boundary point and the surface normal. The main results are presented as two theorems. The first theorem directly parameterizes Minkowski sum boundaries using the unit normal vector at each surface point. Although simple to express mathematically, such a parameterization is not always practical to obtain computationally. Therefore, the second theorem derives a more useful parametric closed-form expression using the gradient that is not normalized. In the special case of two ellipsoids, the proposed expressions are identical to those derived previously using geometric interpretations. In order to examine the results, numerical validations and comparisons of the Minkowski sums between two superquadric bodies are conducted. Applications to generate configuration space obstacles in motion planning problems and to improve optimization-based collision detection algorithms are introduced and demonstrated.},
	urldate = {2024-01-23},
	journal = {Computer-Aided Design},
	author = {Ruan, Sipu and Chirikjian, Gregory S.},
	month = feb,
	year = {2022},
	note = {arXiv: 2012.15461
Publisher: Elsevier},
	keywords = {Computational geometry, Computer-aided design, Minkowski sums},
	pages = {103133},
}

@article{Kern2008,
	title = {Automation and the map label placement problem: {A} comparison of two {GIS} implementations of label placement},
	issn = {10489053},
	url = {https://www.researchgate.net/publication/270591240_Automation_and_the_Map_Label_Placement_Problem},
	doi = {10.14714/CP60.230},
	abstract = {The placement of feature name labels on maps has challenged mapmakers throughout history. Before the development of mapping software, placing labels in manual map production could consume up to half or more of overall map production time. This paper explores the extent to which current GIS software can place labels legibly, without overlap, and with good visual association between features and labels. This evaluation takes place in the context of a densely featured municipal sewer utility map book. The primary research objective is to evaluate the ability of current GIS software to automate label placement; the research also identifies factors that make manual refinement of automated label placement necessary in order to complete the labeling process. The research compares map-labeling tools from ESRI™'s ArcMap™ 9.2: the Standard Labeling Engine and the MapleX™ labeling extension. Label placement success is assessed by both quantity and quality metrics, using a methodology developed and tailored specifically for evaluation of sewer map label placement. The research found that Maplex placed almost seven percent more labels overall than the Standard Labeling Engine. For the labels they did place, both products provided equally good quality label placement: About 93 percent of labels were placed with no overlap, and virtually 100 percent of labels were placed in their preferred position. After conversion to annotation, manual label position refinement eliminated all overlaps but at the cost of a nine percent decline in the preferred position metric.},
	number = {60},
	urldate = {2024-01-23},
	journal = {Cartographic Perspectives},
	author = {Kern, Jill Phelps and Brewer, Cynthia A.},
	year = {2008},
	note = {Publisher: NACIS (North American Cartographic Information Society)},
	keywords = {Automated label placement, GIS mapping, Map design, Map label placement, Utility map labeling},
	pages = {22--45},
}

@article{article,
	title = {Using {Meta}-{Heuristics} for {Constraint}-{Based} {3D} {Objects} {Layout}},
	journal = {Intelligenza Artificiale - IA},
	author = {Larive, Mathieu and Roux, Olivier and Gaildrat, Véronique},
	year = {2004},
}

@article{VanKreveld2005,
	title = {{AUTOMATED} {LABEL} {PLACEMENT} {FOR} {GROUPS} {OF} {ISLANDS}},
	abstract = {In his article "Positioning Names on Maps", Eduard Imhof describes label placement guidelines for three types of objects; point, line, and area objects. We describe how a label can be placed for a fourth type, namely groups of area objects. In particular we consider groups of islands. A suitable place for the label may be the position that minimizes the maximum distance from the label to each island of the group. We develop an efficient algorithm that computes this position for a given horizontal, two-dimensional label, and a set P of polygons representing the islands. The solution is based on geometric concepts like furthest site Voronoi diagrams and Minkowski sums. Furthermore, we give an implementation that determines good island label positions for fixed horizontal labels that may or may not overlap with the islands, and for horizontal labels with different letter spacing. Tests with various settings of the implementation show the quality of the results on several groups of islands.},
	urldate = {2024-01-23},
	author = {Van Kreveld, Marc and Schlechter, Tim},
	year = {2005},
}

@article{Bekos2019,
	title = {External labeling techniques: {A} taxonomy and survey},
	volume = {38},
	issn = {14678659},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.13729},
	doi = {10.1111/cgf.13729},
	abstract = {External labeling is frequently used for annotating features in graphical displays and visualizations, such as technical illustrations, anatomical drawings, or maps, with textual information. Such a labeling connects features within an illustration by thin leader lines with their labels, which are placed in the empty space surrounding the image. Over the last twenty years, a large body of literature in diverse areas of computer science has been published that investigates many different aspects, models, and algorithms for automatically placing external labels for a given set of features. This state-of-the-art report introduces a first unified taxonomy for categorizing the different results in the literature and then presents a comprehensive survey of the state of the art, a sketch of the most relevant algorithmic techniques for external labeling algorithms, as well as a list of open research challenges in this multidisciplinary research field.},
	number = {3},
	urldate = {2024-01-23},
	journal = {Computer Graphics Forum},
	author = {Bekos, Michael A. and Niedermann, Benjamin and Nöllenburg, Martin},
	month = jun,
	year = {2019},
	note = {arXiv: 1902.01454
Publisher: John Wiley \& Sons, Ltd},
	keywords = {Computational geometry, Human-centered computing, Information visualization, Theory of computation, Visualization techniques},
	pages = {833--860},
}

@article{kern_automation_2008,
	title = {Automation and the {Map} {Label} {Placement} {Problem}: {A} {Comparison} of {Two} {GIS} {Implementations} of {Label} {Placement}},
	issn = {1048-9053},
	url = {https://cartographicperspectives.org/index.php/journal/article/view/cp60-kern-brewer},
	doi = {10.14714/CP60.230},
	abstract = {The placement of feature name labels on maps has challenged mapmakers throughout history. Before the development of mapping software, placing labels in manual map production could consume up to half or more of overall map production time. This paper explores the extent to which current GIS software can place labels legibly, without overlap, and with good visual association between features and labels. This evaluation takes place in the context of a densely featured municipal sewer utility map book. The primary research objective is to evaluate the ability of current GIS software to automate label placement; the research also identifies factors that make manual refinement of automated label placement necessary in order to complete the labeling process. The research compares map-labeling tools from ESRI TM ’s ArcMap TM 9.2: the Standard Labeling Engine and the Maplex TM labeling extension. Label placement success is assessed by both quantity and quality metrics, using a methodology developed and tailored specifically for evaluation of sewer map label placement. The research found that Maplex placed almost seven percent more labels overall than the Standard Labeling Engine. For the labels they did place, both products provided equally good quality label placement: About 93 percent of labels were placed with no overlap, and virtually 100 percent of labels were placed in their preferred position. After conversion to annotation, manual label position refinement eliminated all overlaps but at the cost of a nine percent decline in the preferred position metric.},
	number = {60},
	urldate = {2024-01-23},
	journal = {Cartographic Perspectives},
	author = {Kern, Jill Phelps and Brewer, Cynthia A.},
	month = jun,
	year = {2008},
	note = {Publisher: NACIS (North American Cartographic Information Society)},
	keywords = {GIS mapping, automated label placement, map design, utility map  labeling},
	pages = {22--45},
}

@inproceedings{Dwyer2010,
	title = {Layout with circular and other non-linear constraints using {Procrustes} projection},
	volume = {5849 LNCS},
	isbn = {3-642-11804-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-11805-0_37},
	doi = {10.1007/978-3-642-11805-0_37},
	abstract = {Recent work on constrained graph layout has involved projection of simple two-variable linear equality and inequality constraints in the context of majorization or gradient-projection based optimization. While useful classes of containment, alignment and rectangular non-overlap constraints could be built using this framework, a severe limitation was that the layout used an axis-separation approach such that all constraints had to be axis aligned. In this paper we use techniques from Procrustes Analysis to extend the gradient-projection approach to useful types of non-linear constraints. The constraints require subgraphs to be locally fixed into various geometries - such as circular cycles or local layout obtained by a combinatorial algorithm (e.g. orthogonal or layered-directed) - but then allow these sub-graph geometries to be integrated into a larger layout through translation, rotation and scaling. © 2010 Springer-Verlag.},
	urldate = {2024-01-23},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Dwyer, Tim and Robertson, George},
	year = {2010},
	note = {ISSN: 03029743},
	pages = {393--404},
}

@article{Sun2023,
	title = {Application of {Mathematical} {Optimization} in {Data} {Visualization} and {Visual} {Analytics}: {A} {Survey}},
	volume = {9},
	issn = {23327790},
	doi = {10.1109/TBDATA.2023.3262151},
	abstract = {Mathematical optimization is the process of determining the set of globally or locally optimal parameters in a finite or infinite search space. It has been extensively employed in the research areas of computer science, engineering, operations research, and economics. The application of mathematical optimization has also been extended to data visualization, where it can enhance data processing, structure visualization, and facilitate exploration. However, the current state of summarization in the application of mathematical optimization in data visualization remains inadequate. In this article, we review and classify the existing techniques for advanced mathematical optimization in the fields of data visualization and visual analytics. The classification is conducted based on a classical visualization pipeline, including data enhancement and transformation, representation and rendering, as well as interactive exploration and analysis. We also discuss various mathematical optimization models and their solution methods to help readers gain a better understanding of the relationship among models, visualization, and application scenarios. We additionally provide an online exploration demo, which could enable users to interactively find relevant articles. Based on the limitations and potential trends revealed in the existing literature, we define future challenges in the cross-disciplinary of mathematical optimization and data visualization.},
	number = {4},
	urldate = {2024-01-23},
	journal = {IEEE Transactions on Big Data},
	author = {Sun, Guodao and Zhu, Zihao and Zhang, Gefei and Xu, Chaoqing and Wang, Yunchao and Zhu, Sujia and Chang, Baofeng and Liang, Ronghua},
	month = aug,
	year = {2023},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.},
	keywords = {Data visualization, mathematical optimization, scientific visualization, visual analytics},
	pages = {1018--1037},
}

@article{Gibson2013,
	title = {A survey of two-dimensional graph layout techniques for information visualisation},
	volume = {12},
	issn = {14738716},
	url = {https://journals.sagepub.com/doi/full/10.1177/1473871612455749?casa_token=WoeybsA_rOsAAAAA%3AsyIoUVr6NizrS9wzs9jEEMCeEBRrqanoOiph4lD1ZpgOgggSTGXlFXXKRJP-jep--sisiTiduVFo},
	doi = {10.1177/1473871612455749/ASSET/IMAGES/LARGE/10.1177_1473871612455749-FIG19.JPEG},
	abstract = {Many algorithms for graph layout have been devised over the last 30 years spanning both the graph drawing and information visualisation communities. This article first reviews the advances made in the field of graph drawing that have then often been applied by the information visualisation community. There then follows a discussion of a range of techniques developed specifically for graph visualisations. Graph drawing algorithms are categorised into the following approaches: force-directed layouts, the use of dimension reduction in graph layout and computational improvements including multi-level techniques. Methods developed specifically for graph visualisation often make use of node-attributes and are categorised based on whether the attributes are used to introduce constraints to the layout, provide a clustered view or define an explicit representation in two-dimensional space. The similarities and distinctions between these techniques are examined and the aim is to provide a detailed assessment of currently available graph layout techniques, specifically how they can be used by visualisation practitioners, and to motivate further research in the area. © The Author(s) 2012.},
	number = {3-4},
	urldate = {2024-01-23},
	journal = {Information Visualization},
	author = {Gibson, Helen and Faith, Joe and Vickers, Paul},
	month = jul,
	year = {2013},
	note = {Publisher: SAGE PublicationsSage UK: London, England},
	keywords = {2D, Force-directed layout, Graph and network visualisation, Graph layout, Multi-attribute visualisation, Network layout visualisation},
	pages = {324--357},
}

@article{cox_review_2021-1,
	title = {A {Review} of {Methods} to {Compute} {Minkowski} {Operations} for {Geometric} {Overlap} {Detection}},
	volume = {27},
	issn = {19410506},
	doi = {10.1109/TVCG.2020.2976922},
	abstract = {This article provides an extensive review of algorithms for constructing Minkowski sums and differences of polygons and polyhedra, both convex and non-convex, commonly known as no-fit polygons and configuration space obstacles. The Minkowski difference is a set operation, which when applied to shapes defines a method for efficient overlap detection, providing an important tool in packing and motion-planning problems. This is the first complete review on this specific topic, and aims to unify algorithms spread over the literature of separate disciplines.},
	number = {8},
	urldate = {2024-01-23},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cox, Wesley and While, Lyndon and Reynolds, Mark},
	month = aug,
	year = {2021},
	pmid = {32142441},
	note = {Publisher: IEEE Computer Society},
	keywords = {Collision avoidance, computational geometry, configuration space, minkowski sum, no-fit polygon, reviews},
	pages = {3377--3396},
}

@article{Zheng2017,
	title = {Graph {Drawing} by {Stochastic} {Gradient} {Descent}},
	volume = {25},
	issn = {19410506},
	url = {https://arxiv.org/abs/1710.04626v3},
	doi = {10.1109/TVCG.2018.2859997},
	abstract = {A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.},
	number = {9},
	urldate = {2024-01-23},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zheng, Jonathan X. and Pawar, Samraat and Goodman, Dan F.M.},
	month = oct,
	year = {2017},
	pmid = {30047888},
	note = {arXiv: 1710.04626
Publisher: IEEE Computer Society},
	keywords = {Graph drawing, constraints, multidimensional scaling, relaxation, stochastic gradient descent},
	pages = {2738--2748},
}

@article{Dwyer2009,
	title = {Scalable, {Versatile} and {Simple} {Constrained} {Graph} {Layout}},
	volume = {28},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8659.2009.01449.x},
	doi = {10.1111/J.1467-8659.2009.01449.X},
	abstract = {We describe a new technique for graph layout subject to constraints. Compared to previous techniques the proposed method is much faster and scalable to much larger graphs. For a graph with n nodes, m edges and c constraints it computes incremental layout in time O(n log n + m + c) per iteration. Also, it supports a much more powerful class of constraint: inequalities or equalities over the Euclidean distance between nodes. We demonstrate the power of this technique by application to a number of diagramming conventions which previous constrained graph layout methods could not support. Further, the constraint-satisfaction method - inspired by recent work in position-based dynamics - is far simpler to implement than previous methods. © 2009 The Eurographics Association and Blackwell Publishing Ltd.},
	number = {3},
	urldate = {2024-01-23},
	journal = {Computer Graphics Forum},
	author = {Dwyer, Tim},
	month = jun,
	year = {2009},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Computer Graphics [I.3.3]: Display algorithms, Display algorithms-Optimization [G16], Optimization [G.1.6]: Constrained optimization},
	pages = {991--998},
}

@article{Cascaval2022,
	title = {Differentiable {3D} {CAD} {Programs} for {Bidirectional} {Editing}},
	volume = {41},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14476},
	doi = {10.1111/CGF.14476},
	abstract = {Modern CAD tools represent 3D designs not only as geometry, but also as a program composed of geometric operations, each of which depends on a set of parameters. Program representations enable meaningful and controlled shape variations via parameter changes. However, achieving desired modifications solely through parameter editing is challenging when CAD models have not been explicitly authored to expose select degrees of freedom in advance. We introduce a novel bidirectional editing system for 3D CAD programs. In addition to editing the CAD program, users can directly manipulate 3D geometry and our system infers parameter updates to keep both representations in sync. We formulate inverse edits as a set of constrained optimization objectives, returning plausible updates to program parameters that both match user intent and maintain program validity. Our approach implements an automatically differentiable domain-specific language for CAD programs, providing derivatives for this optimization to be performed quickly on any expressed program. Our system enables rapid, interactive exploration of a constrained 3D design space by allowing users to manipulate the program and geometry interchangeably during design iteration. While our approach is not designed to optimize across changes in geometric topology, we show it is expressive and performant enough for users to produce a diverse set of design variants, even when the CAD program contains a relatively large number of parameters.},
	number = {2},
	urldate = {2024-01-22},
	journal = {Computer Graphics Forum},
	author = {Cascaval, D. and Shalah, M. and Quinn, P. and Bodik, R. and Agrawala, M. and Schulz, A.},
	month = may,
	year = {2022},
	note = {arXiv: 2110.01182
Publisher: John Wiley \& Sons, Ltd},
	keywords = {CCS Concepts, Graphics systems and interfaces, • Computing methodologies → Shape modeling},
	pages = {309--323},
}

@article{Hottelier2014,
	title = {Programming by {Manipulation} for layout},
	url = {http://dx.doi.org/10.1145/2642918.2647378},
	doi = {10.1145/2642918.2647378},
	abstract = {We present Programming by Manipulation, a new programming methodology for specifying the layout of data visualizations, targeted at non-programmers. We address the two central sources of bugs that arise when programming with constraints: ambiguities and conflicts (inconsistencies). We rule out conflicts by design and exploit ambiguity to explore possible layout designs. Our users design layouts by highlighting undesirable aspects of a current design, effectively breaking spurious constraints and introducing ambiguity by giving some elements freedom to move or resize. Subsequently, the tool indicates how the ambiguity can be removed, by computing how the free elements can be fixed with available constraints. To support this workflow, our tool computes the ambiguity and summarizes it visually. We evaluate our work with two user-studies demonstrating that both non-programmers and programmers can effectively use our prototype. Our results suggest that our tool is 5-times more productive than direct programming with constraints.},
	urldate = {2021-10-06},
	journal = {UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
	author = {Hottelier, Thibaud and Bodik, Ras and Ryokai, Kimiko},
	month = oct,
	year = {2014},
	note = {Publisher: Association for Computing Machinery, Inc},
	keywords = {Constraint-based layout, Layout editing, Programming by demonstration},
	pages = {231--242},
}

@article{thurston_proof_1994-1,
	title = {On proof and progress in mathematics},
	volume = {30},
	issn = {02730979},
	url = {https://arxiv.org/abs/math/9404236v1},
	doi = {10.1090/S0273-0979-1994-00502-6},
	abstract = {In response to Jaffe and Quinn [math.HO/9307227], the author discusses forms of progress in mathematics that are not captured by formal proofs of theorems, especially in his own work in the theory of foliations and geometrization of 3-manifolds and dynamical systems.},
	number = {2},
	urldate = {2023-12-11},
	journal = {Bulletin of the American Mathematical Society},
	author = {Thurston, William P.},
	month = apr,
	year = {1994},
	note = {arXiv: math/9404236},
	pages = {161--177},
}

@book{clark2023learning,
	title = {E-learning and the science of instruction: {Proven} guidelines for consumers and designers of multimedia learning},
	publisher = {john Wiley \& sons},
	author = {Clark, Ruth C and Mayer, Richard E},
	year = {2023},
}

@misc{desmos,
	title = {Desmos},
	year = {2019},
	note = {Medium: {\textbackslash}url\{https://www.desmos.com/\}},
}

@article{fogh_explorable_2018,
	title = {Explorable {Explanations}: {What} are they? {What} do they explain? {How} do we work with them? {Let}\&apos;s find out},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:mau:diva-23326},
	abstract = {In this paper, the author examines the concept of explorable explanations. It has emerged as a genre of educational software within the last 7 years, yet descriptions of it are vague at best. The a ...},
	urldate = {2023-10-11},
	author = {Fogh, Jesper Hyldahl},
	year = {2018},
	note = {Publisher: Malmö universitet/Kultur och samhälle},
	keywords = {Engineering and Technology, Teknik och teknologier, educational software, interaction design, neural networks},
}

@article{myers_garnet_1990,
	title = {Garnet: {Comprehensive} {Support} for {Graphical}, {Highly} {Interactive} {User} {Interfaces}},
	volume = {23},
	issn = {00189162},
	doi = {10.1109/2.60882},
	number = {11},
	urldate = {2023-05-03},
	journal = {Computer},
	author = {Myers, Brad A. and Giuse, Dario A. and Dannenberg, Roger B. and Vander Zanden, Brad and Kosbie, David S. and Pervin, Edward and Mickish, Andrew and Marchal, Philippe},
	year = {1990},
	pages = {71--85},
}

@article{batra_accelerating_2015-1,
	title = {Accelerating vector graphics rendering using the graphics hardware pipeline},
	volume = {34},
	issn = {15577368},
	url = {https://dl.acm.org/doi/10.1145/2766968},
	doi = {10.1145/2766968},
	abstract = {We describe our successful initiative to accelerate Adobe Illustrator with the graphics hardware pipeline of modern GPUs. Relying on OpenGL 4.4 plus recent OpenGL extensions for advanced blend mode...},
	number = {4},
	urldate = {2023-05-18},
	journal = {ACM Transactions on Graphics (TOG)},
	author = {Batra, Vineet and Kilgard, Mark J. and Kumar, Harish and Lorach, Tristan},
	month = jul,
	year = {2015},
	note = {Publisher: 
		ACM
		PUB27
		New York, NY, USA
	
ISBN: 9781450333313},
	keywords = {OpenGL, illustrator, path rendering, vector graphics},
	pages = {146},
}

@inproceedings{vega,
	address = {New York, NY, USA},
	title = {Declarative interaction design for data visualization},
	isbn = {978-1-4503-3069-5},
	url = {http://dx.doi.org/10.1145/2642918.2647360},
	doi = {10.1145/2642918.2647360},
	abstract = {Declarative visualization grammars can accelerate development, facilitate retargeting across platforms, and allow language-level optimizations. However, existing declarative visualization languages are primarily concerned with visual encoding, and rely on imperative event handlers for interactive behaviors. In response, we introduce a model of declarative interaction design for data visualizations. Adopting methods from reactive programming, we model low-level events as composable data streams from which we form higher-level semantic signals. Signals feed predicates and scale inversions, which allow us to generalize interactive selections at the level of item geometry (pixels) into interactive queries over the data domain. Production rules then use these queries to manipulate the visualization's appearance. To facilitate reuse and sharing, these constructs can be encapsulated as named interactors: standalone, purely declarative specifications of interaction techniques. We assess our model's feasibility and expressivity by instantiating it with extensions to the Vega visualization grammar. Through a diverse range of examples, we demonstrate coverage over an established taxonomy of visualization interaction techniques.},
	urldate = {2022-03-16},
	booktitle = {{UIST} 2014 - {Proceedings} of the 27th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Satyanarayan, Arvind and Wongsuphasawat, Kanit and Heer, Jeffrey},
	year = {2014},
	keywords = {Declarative design, Interaction design, Toolkits, Visualization},
	pages = {669--678},
}

@article{horvath_conceptual_2023,
	title = {Conceptual diagrams in {Quantum} {Mechanics}},
	issn = {1521-3994},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/asna.20230046},
	doi = {10.1002/ASNA.20230046},
	abstract = {Quantum Mechanics (QM) stands alone as a (very) successful physical theory, but the meaning of its variables and the status of many quantities in the mathematical formalism is obscure. This unique situation prompted the need for attribution of a physical meaning to the latter, a procedure known as interpretation. On the other hand, the study of QM is usually presented, even to future scientists, within the only framework developed by Bohr and the Copenhagen researchers, known as the Copenhagen interpretation. As a contribution to the understanding and teaching of Quantum Mechanics, aimed to a broader and deeper appreciation of its fundamentals, including contemplating alternatives and updated interpretations for physicists and philosophers interested in the study of exact sciences (through Ontology, Epistemology, Logic or the Theory of Knowledge), we present a set of Conceptual Diagrams elaborated and designed to expose and facilitate the visualization of elements intervening in any interpretation of Quantum Mechanics and apply them to several well-developed cases of the latter.},
	urldate = {2023-04-25},
	journal = {Astronomische Nachrichten},
	author = {Horvath, Jorge E and Fernandes, Rodrigo Rosas and Paulo, São and Correspondence, Brazil},
	month = mar,
	year = {2023},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Quantum Mechanics, diagrams, philosophy},
	pages = {e20230046},
}

@article{pan_human-computer_2023,
	title = {A {Human}-{Computer} {Collaborative} {Editing} {Tool} for {Conceptual} {Diagrams}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580676},
	doi = {10.1145/3544548.3580676},
	urldate = {2023-04-25},
	journal = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
	author = {Pan, Lihang and Yu, Chun and He, Zhe and Shi, Yuanchun},
	month = apr,
	year = {2023},
	note = {Publisher: ACM
Place: New York, NY, USA
ISBN: 9781450394215},
	pages = {1--29},
}

@article{protovis09,
	title = {Protovis: {A} graphical toolkit for visualization},
	volume = {15},
	issn = {10772626},
	doi = {10.1109/TVCG.2009.174},
	abstract = {Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency-the effort required to specify a visualization-and accessibility-the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools. © 2009 IEEE.},
	number = {6},
	urldate = {2023-04-17},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bostock, Michael and Heer, Jeffrey},
	month = nov,
	year = {2009},
	keywords = {2D graphics, Information visualization, toolkits, user interfaces},
	pages = {1121--1128},
}

@article{edwards_coherent_2009-1,
	title = {Coherent reaction},
	url = {https://dl.acm.org/doi/10.1145/1639950.1640058},
	doi = {10.1145/1639950.1640058},
	abstract = {Side effects are both the essence and bane of imperative programming. The programmer must carefully coordinate actions to manage their side effects upon each other. Such coordination is complex, error-prone, and fragile. Coherent reaction is a new model of change-driven computation that coordinates effects automatically. State changes trigger events called reactions that in turn change other states. A coherent execution order is one in which each reaction executes before any others that are affected by its changes. A coherent order is discovered iteratively by detecting incoherencies as they occur and backtracking their effects. Unlike alternative solutions, much of the power of imperative programming is retained, as is the common sense notion of mutable state. Automatically coordinating actions lets the programmer express what to do, not when to do it. Coherent reactions are embodied in the Coherence language, which is specialized for interactive applications like those common on the desktop and web. The fundamental building block of Coherence is the dynamically typed mutable tree. The fundamental abstraction mechanism is the virtual tree, whose value is lazily computed, and whose behavior is generated by coherent reactions. Copyright © 2009 ACM.},
	urldate = {2023-04-17},
	journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
	author = {Edwards, Jonathan},
	year = {2009},
	note = {ISBN: 9781605587660},
	keywords = {Bidirectional functions, Functional reactive programming, Interactive systems, Reactive systems, Synchronous reactive programming, Trees},
	pages = {925--932},
}

@article{hutchins_direct_2009,
	title = {Direct {Manipulation} {Interfaces}},
	volume = {1},
	issn = {15327051},
	url = {https://www.tandfonline.com/doi/abs/10.1207/s15327051hci0104_2},
	doi = {10.1207/S15327051HCI0104_2},
	abstract = {Direct manipulation has been lauded as a good form of interface design, and some interfaces that have this property have been well received by users. In this article we seek a cognitive account of ...},
	number = {4},
	urldate = {2023-04-19},
	journal = {https://doi.org/10.1207/s15327051hci0104\_2},
	author = {Hutchins, Edwin L. and Hollan, James D. and Norman, Donald A.},
	year = {2009},
	note = {Publisher:  Lawrence Erlbaum Associates, Inc.},
	pages = {311--338},
}

@article{satyanarayan_declarative_2014-1,
	title = {Declarative interaction design for data visualization},
	url = {https://dl.acm.org/doi/10.1145/2642918.2647360},
	doi = {10.1145/2642918.2647360},
	abstract = {Declarative visualization grammars can accelerate development, facilitate retargeting across platforms, and allow language-level optimizations. However, existing declarative visualization languages are primarily concerned with visual encoding, and rely on imperative event handlers for interactive behaviors. In response, we introduce a model of declarative interaction design for data visualizations. Adopting methods from reactive programming, we model low-level events as composable data streams from which we form higher-level semantic signals. Signals feed predicates and scale inversions, which allow us to generalize interactive selections at the level of item geometry (pixels) into interactive queries over the data domain. Production rules then use these queries to manipulate the visualization's appearance. To facilitate reuse and sharing, these constructs can be encapsulated as named interactors: standalone, purely declarative specifications of interaction techniques. We assess our model's feasibility and expressivity by instantiating it with extensions to the Vega visualization grammar. Through a diverse range of examples, we demonstrate coverage over an established taxonomy of visualization interaction techniques.},
	urldate = {2023-04-17},
	journal = {UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
	author = {Satyanarayan, Arvind and Wongsuphasawat, Kanit and Heer, Jeffrey},
	month = oct,
	year = {2014},
	note = {Publisher: Association for Computing Machinery
ISBN: 9781450330695},
	keywords = {Declarative design, Interaction design, Toolkits, Visualization, toolkits},
	pages = {669--678},
}

@article{gierl_role_2012,
	title = {The {Role} of {Item} {Models} in {Automatic} {Item} {Generation}},
	volume = {12},
	issn = {15305058},
	url = {https://www.tandfonline.com/doi/abs/10.1080/15305058.2011.635830},
	doi = {10.1080/15305058.2011.635830},
	abstract = {Automatic item generation represents a relatively new but rapidly evolving research area where cognitive and psychometric theories are used to produce tests that include items generated using computer technology. Automatic item generation requires two steps. First, test development specialists create item models, which are comparable to templates or prototypes, that highlight the features or elements in the assessment task that must be manipulated. Second, these item model elements are manipulated to generate new items with the aid of computer-based algorithms. With this two-step process, hundreds or even thousands of new items can be created from a single item model. The purpose of our article is to describe seven different but related topics that are central to the development and use of item models for automatic item generation. We start by defining item model and highlighting some related concepts; we describe how item models are developed; we present an item model taxonomy; we illustrate how item models can be used for automatic item generation; we outline some benefits of using item models; we introduce the idea of an item model bank; and finally, we demonstrate how statistical procedures can be used to estimate the parameters of the generated items without the need for extensive field or pilot testing. © 2012 Copyright Taylor and Francis Group, LLC.},
	number = {3},
	urldate = {2023-04-04},
	journal = {International Journal of Testing},
	author = {Gierl, Mark J. and Lai, Hollis},
	month = jul,
	year = {2012},
	note = {Publisher: Taylor \& Francis Group},
	keywords = {automatic item generation, computer based testing, test development},
	pages = {273--298},
}

@article{yang_automatic_2022,
	title = {Automatic {Item} {Generation} of {Figural} {Analogy} {Problems}: {A} {Review} and {Outlook}},
	url = {https://arxiv.org/abs/2201.08450v1},
	abstract = {Figural analogy problems have long been a widely used format in human intelligence tests. In the past four decades, more and more research has investigated automatic item generation for figural analogy problems, i.e., algorithmic approaches for systematically and automatically creating such problems. In cognitive science and psychometrics, this research can deepen our understandings of human analogical ability and psychometric properties of figural analogies. With the recent development of data-driven AI models for reasoning about figural analogies, the territory of automatic item generation of figural analogies has further expanded. This expansion brings new challenges as well as opportunities, which demand reflection on previous item generation research and planning future studies. This paper reviews the important works of automatic item generation of figural analogies for both human intelligence tests and data-driven AI models. From an interdisciplinary perspective, the principles and technical details of these works are analyzed and compared, and desiderata for future research are suggested.},
	urldate = {2023-04-04},
	author = {Yang, Yuan and Sanyal, Deepayan and Michelson, Joel and Ainooson, James and Kunda, Maithilee},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.08450},
}

@article{Singh2012,
	title = {Automatically {Generating} {Algebra} {Problems}},
	volume = {26},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/8341},
	doi = {10.1609/AAAI.V26I1.8341},
	abstract = {We propose computer-assisted techniques for helping with pedagogy in Algebra. In particular, given a proof problem p (of the form “Left-hand-side-term = Right-hand-side-term”), we show how to automatically generate problems that are similar to p. We believe that such a tool can be used by teachers in making examinations where they need to test students on problems similar to what they taught in class, and by students in generating practice problems tailored to their specific needs. Our first insight is that we can generalize p syntactically to a query Q that implicitly represents a set of problems [[Q]] (which includes p). Our second insight is that we can explore the space of problems [[Q]] automatically, use classical results from polynomial identity testing to generate only those problems in [[Q]] that are correct, and then use pruning techniques to generate only unique and interesting problems. Our third insight is that with a small amount of manual tuning on the query Q, the user can interactively guide the computer to generate problems of interest to her. We present the technical details of the above mentioned steps, and also describe a tool where these steps have been implemented. We also present an empirical evaluation on a wide variety of problems from various sub-fields of algebra including polynomials, trigonometry, calculus, determinants etc. Our tool is able to generate a rich corpus of similar problems from each given problem; while some of these similar problems were already present in the textbook, several were new!},
	number = {1},
	urldate = {2023-04-04},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Singh, Rohit and Gulwani, Sumit and Rajamani, Sriram},
	year = {2012},
	note = {ISBN: 9781577355687},
	keywords = {Aided Education, Computer, HCI, Synthesis},
	pages = {1620--1628},
}

@article{hornke_rule-based_1986-1,
	title = {Rule-{Based} {Item} {Bank} {Construction} and {Evaluation} {Within} the {Linear} {Logistic} {Framework}},
	volume = {10},
	issn = {15523497},
	url = {https://journals.sagepub.com/doi/10.1177/014662168601000405},
	doi = {10.1177/014662168601000405},
	abstract = {In cognition research, item writing rules are consid ered a necessary prerequisite of item banking. A set of 636 items was constructed using prespecified cognitive operations. An evaluation of test data from some 7,400 examinees revealed 446 homogeneous items. Some items had to be discarded because of printing flaws, and others because of operation complexion or other well-describable reasons. However, cognitive operations explained item difficulty parameters quite well; further cross-validation research may contribute to an item writing approach which attempts to bring psychological theory and psychometric models closer together. This will eventually free item construction from item writer idiosyncrasies. © 1986, Sage Publications. All rights reserved.},
	number = {4},
	urldate = {2023-04-05},
	journal = {Applied Psychological Measurement},
	author = {Hornke, Lutz F. and Habon, Michael W.},
	month = dec,
	year = {1986},
	note = {Publisher: Sage PublicationsSage CA: Thousand Oaks, CA},
	pages = {369--380},
}

@article{carpenter_what_1990,
	title = {What one intelligence test measures: {A} theoretical account of the processing in the {Raven} progressive matrices test},
	volume = {97},
	issn = {0033295X},
	doi = {10.1037/0033-295X.97.3.404},
	abstract = {The cognitive processes in a widely used, nonverbal test of analytic intelligence, the Raven Progressive Matrices Test (Raven, 1962), are analyzed in terms of which processes distinguish between higher scoring and lower scoring subjects and which processes are common to all subjects and all items on the test. The analysis is based on detailed performance characteristics, such as verbal protocols, eye-fixation patterns, and errors. The theory is expressed as a pair of computer simulation models that perform like the median or best college students in the sample. The processing characteristic common to all subjects is an incremental, reiterative strategy for encoding and inducing the regularities in each problem. The processes that distinguish among individuals are primarily the ability to induce abstract relations and the ability to dynamically manage a large set of problem-solving goals in working memory.},
	number = {3},
	urldate = {2023-04-05},
	journal = {Psychological Review},
	author = {Carpenter, Patricia A. and Just, Marcel Adam and Shell, Peter},
	year = {1990},
	pmid = {2381998},
	note = {Publisher: American Psychological Association Inc.},
	pages = {404--431},
}

@inproceedings{Wang2015,
	title = {Automatic generation of {Raven}'s progressive {Matrices}},
	volume = {2015-Janua},
	isbn = {978-1-57735-738-4},
	abstract = {Raven's Progressive Matrices (RPMs) are a popular family of general intelligence tests, and provide a non-verbal measure of a test subject's reasoning abilities. Traditionally RPMs have been manually designed. To make them readily available for both practice and examination, we tackle the problem of automatically synthesizing RPMs. Our goal is to efficiently generate a large number of RPMs that are authentic (i.e. similar to manually written problems), interesting (i.e. diverse in terms of difficulty), and well-formed (i.e. unambiguous). The main technical challenges are: How to formalize RPMs to accommodate their seemingly enormous diversity, and how to define and enforce their validity? To this end, we (1) introduce an abstract representation of RPMs using first-order logic, and (2) restrict instantiations to only valid RPMs. We have realized our approach and evaluated its efficiency and effectiveness. We show that our system can generate hundreds of valid problems per second with varying levels of difficulty. More importantly, we show, via a user study with 24 participants, that the generated problems are statistically indistinguishable from actual problems. This work is an exciting instance of how logic and reasoning may aid general learning.},
	urldate = {2023-04-05},
	booktitle = {{IJCAI} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Wang, Ke and Su, Zhendong},
	year = {2015},
	note = {ISSN: 10450823},
	keywords = {Reasoning, Technical Papers — Knowledge Representation, and Logic},
	pages = {903--909},
}

@article{matzen_recreating_2010,
	title = {Recreating raven's: {Software} for systematically generating large numbers of raven-like matrix problems with normed properties},
	volume = {42},
	issn = {1554351X},
	doi = {10.3758/BRM.42.2.525},
	abstract = {Raven's Progressive Matrices is a widely used test for assessing intelligence and reasoning ability (Raven, Court, \& Raven, 1998). Since the test is nonverbal, it can be applied to many different populations and has been used all over the world (Court \& Raven, 1995). However, relatively few matrices are in the sets developed by Raven, which limits their use in experiments requiring large numbers of stimuli. For the present study, we analyzed the types of relations that appear in Raven's original Standard Progressive Matrices (SPMs) and created a software tool that can combine the same types of relations according to parameters chosen by the experimenter, to produce very large numbers of matrix problems with specific properties. We then conducted a norming study in which the matrices we generated were compared with the actual SPMs. This study showed that the generated matrices both covered and expanded on the range of problem difficulties provided by the SPMs. © 2010 The Psychonomic Society, Inc.},
	number = {2},
	urldate = {2023-04-05},
	journal = {Behavior Research Methods},
	author = {Matzen, Laura E. and Benz, Zachary O. and Dixon, Kevin R. and Posey, Jamie and Kroger, James K. and Speed, Ann E.},
	month = may,
	year = {2010},
	pmid = {20479184},
	pages = {525--541},
}

@inproceedings{pmlr-v80-barrett18a,
	title = {Measuring abstract reasoning in neural networks},
	volume = {80},
	url = {https://proceedings.mlr.press/v80/barrett18a.html},
	abstract = {Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation ’regimes’ in which the training data and test questions differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model’s ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Barrett, David and Hill, Felix and Santoro, Adam and Morcos, Ari and Lillicrap, Timothy},
	editor = {Dy, Jennifer and Krause, Andreas},
	year = {2018},
	note = {Series Title: Proceedings of Machine Learning Research},
	pages = {511--520},
}

@article{embretson_cognitive_1998,
	title = {A {Cognitive} {Design} {System} {Approach} to {Generating} {Valid} {Tests}: {Application} to {Abstract} {Reasoning}},
	volume = {3},
	issn = {1082989X},
	doi = {10.1037/1082-989X.3.3.380},
	abstract = {The actual impact of cognitive theory on testing contrasts sharply with its potential impact, which suggests some deep incompatibilities between the areas. This article describes and illustrates a cognitive design system approach that centralizes cognitive theory in developing valid tests. To resolve incompatibilities between cognitive and testing, the cognitive design system approach includes both conceptual and procedural frameworks. To illustrate the cognitive design approach, an item bank for measuring abstract reasoning was generated from cognitive theory (i.e., P. A. Carpenter, M. A. Just, \& P. Shell's, 1990, processing theory). The construct validity of the generating item bank was strongly supported by several studies from the cognitive design system approach.},
	number = {3},
	urldate = {2023-04-05},
	journal = {Psychological Methods},
	author = {Embretson, Susan E.},
	year = {1998},
	note = {Publisher: American Psychological Association Inc.},
	pages = {380--396},
}

@article{andersen_trace-based_2013,
	title = {A trace-based framework for analyzing and synthesizing educational progressions},
	url = {https://dl.acm.org/doi/10.1145/2470654.2470764},
	doi = {10.1145/2470654.2470764},
	abstract = {A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods. Copyright © 2013 ACM.},
	urldate = {2023-04-04},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Andersen, Erik and Gulwani, Sumit and Popović, Zoran},
	year = {2013},
	note = {ISBN: 9781450318990},
	keywords = {Education, Execution traces, Games, Problem generation},
	pages = {773--782},
}

@article{Rau2017,
	title = {A {Framework} for {Educational} {Technologies} that {Support} {Representational} {Competencies}},
	volume = {10},
	issn = {19391382},
	doi = {10.1109/TLT.2016.2623303},
	abstract = {Visual representations are ubiquitous in STEM disciplines. Yet, students' difficulties in learning with visual representations are well documented. Therefore, to succeed in STEM, students need representational competencies - the ability to use visual representations for problem solving and learning. Educational technologies that support students' acquisition of representational competencies can significantly enhance their success in STEM disciplines. Current design frameworks for educational technologies do not offer sufficient guidance to develop supports for representational competencies. This paper presents a new design framework that describes an iterative, step-by-step approach for the design of educational technologies that support representational competencies (SUREC) in a way that aligns with the demands specific to the target discipline. The paper illustrates how this framework was used to inform the design of an intelligent tutoring system for undergraduate chemistry. An evaluation study suggests that the SUREC framework yielded an effective educational technology that enhances students' learning of content knowledge.},
	number = {3},
	urldate = {2023-04-04},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Rau, Martina Angela},
	month = jul,
	year = {2017},
	note = {Publisher: Institute of Electrical and Electronics Engineers},
	keywords = {Educational technologies, discipline-based research, multiple representations, representational competencies},
	pages = {290--305},
}

@inproceedings{rho_preparing_2022,
	title = {Preparing {Future} {Learning} with {Novel} {Visuals} by {Supporting} {Representational} {Competencies}},
	volume = {13355 LNCS},
	isbn = {978-3-031-11643-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-11644-5_6},
	doi = {10.1007/978-3-031-11644-5_6},
	abstract = {Many STEM problems involve visuals. To benefit from these problems, students need representational competencies: the ability to understand and appropriately use visuals. Support for representational competencies enhances students’ learning outcomes. However, it is infeasible to design representational-competency supports for entire curricula. This raises the question of whether these supports enhance future learning from novel problems. We addressed this question with an experiment with 120 undergraduates in an engineering class. All students worked with an intelligent tutoring system (ITS) that provided problems with interactive visual representations. The experiment varied which types of representational-competency supports the problems provided. We assessed future learning from a subsequent set of novel problems that involved a novel visual representation. Results show that representational-competency support can enhance future learning from the novel problems. We discuss implications for the integration of these supports in educational technologies.},
	urldate = {2023-04-04},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	author = {Rho, Jihyun and Rau, Martina A. and Van Veen, Barry D.},
	year = {2022},
	note = {ISSN: 16113349},
	keywords = {Future learning, Representational competencies, Visualizations},
	pages = {66--77},
}

@article{synthGeometry,
	title = {Synthesizing geometry constructions},
	volume = {46},
	issn = {0362-1340},
	url = {https://dl.acm.org/doi/abs/10.1145/1993316.1993505},
	doi = {10.1145/1993316.1993505},
	abstract = {In this paper, we study the problem of automatically solving ruler/compass based geometry construction problems. We first introduce a logic and a programming language for describing such constructions and then phrase the automation problem as a program synthesis problem. We then describe a new program synthesis technique based on three key insights: (i) reduction of symbolic reasoning to concrete reasoning (based on a deep theoretical result that reduces verification to random testing), (ii) extending the instruction set of the programming language with higher level primitives (representing basic constructions found in textbook chapters, inspired by how humans use their experience and knowledge gained from chapters to perform complicated constructions), and (iii) pruning the forward exhaustive search using a goal-directed heuristic (simulating backward reasoning performed by humans). Our tool can successfully synthesize constructions for various geometry problems picked up from high-school textbooks and examination papers in a reasonable amount of time. This opens up an amazing set of possibilities in the context of making classroom teaching interactive.},
	number = {6},
	urldate = {2022-03-14},
	journal = {ACM SIGPLAN Notices},
	author = {Gulwani, Sumit and Korthikanti, Vijay Anand and Tiwari, Ashish},
	month = jun,
	year = {2011},
	note = {Publisher: ACM PUB27 New York, NY, USA
ISBN: 9781450306638},
	keywords = {abstraction, forward and backward analysis, program synthesis, ruler-compass geometry constructions},
	pages = {50--61},
}

@article{compEduCACM,
	title = {Example-based learning in computer-aided {STEM} education},
	volume = {57},
	issn = {15577317},
	doi = {10.1145/2634273},
	number = {8},
	urldate = {2022-03-14},
	journal = {Communications of the ACM},
	author = {Gulwani, Sumit},
	year = {2014},
	note = {Publisher: Association for Computing Machinery},
	pages = {70--80},
}

@article{kurdi_systematic_2020,
	title = {A {Systematic} {Review} of {Automatic} {Question} {Generation} for {Educational} {Purposes}},
	volume = {30},
	issn = {15604306},
	url = {https://link.springer.com/article/10.1007/s40593-019-00186-y},
	doi = {10.1007/S40593-019-00186-Y/TABLES/17},
	abstract = {While exam-style questions are a fundamental educational tool serving a variety of purposes, manual construction of questions is a complex process that requires training, experience, and resources. This, in turn, hinders and slows down the use of educational activities (e.g. providing practice questions) and new advances (e.g. adaptive testing) that require a large pool of questions. To reduce the expenses associated with manual construction of questions and to satisfy the need for a continuous supply of new questions, automatic question generation (AQG) techniques were introduced. This review extends a previous review on AQG literature that has been published up to late 2014. It includes 93 papers that were between 2015 and early 2019 and tackle the automatic generation of questions for educational purposes. The aims of this review are to: provide an overview of the AQG community and its activities, summarise the current trends and advances in AQG, highlight the changes that the area has undergone in the recent years, and suggest areas for improvement and future opportunities for AQG. Similar to what was found previously, there is little focus in the current literature on generating questions of controlled difficulty, enriching question forms and structures, automating template construction, improving presentation, and generating feedback. Our findings also suggest the need to further improve experimental reporting, harmonise evaluation metrics, and investigate other evaluation methods that are more feasible.},
	number = {1},
	urldate = {2023-04-04},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Kurdi, Ghader and Leo, Jared and Parsia, Bijan and Sattler, Uli and Al-Emari, Salam},
	month = mar,
	year = {2020},
	note = {Publisher: Springer},
	keywords = {Assessment, Automatic question generation, Difficulty prediction, Education, Natural language generation, Natural language processing, Semantic Web},
	pages = {121--204},
}

@article{goldstone_education_2010,
	title = {The {Education} of {Perception}},
	volume = {2},
	issn = {1756-8765},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1756-8765.2009.01055.x},
	doi = {10.1111/J.1756-8765.2009.01055.X},
	abstract = {Although the field of perceptual learning has mostly been concerned with low- to middle-level changes to perceptual systems due to experience, we consider high-level perceptual changes that accompany learning in science and mathematics. In science, we explore the transfer of a scientific principle (competitive specialization) across superficially dissimilar pedagogical simulations. We argue that transfer occurs when students develop perceptual interpretations of an initial simulation and simply continue to use the same interpretational bias when interacting with a second simulation. In arithmetic and algebraic reasoning, we find that proficiency in mathematics involves executing spatially explicit transformations to notational elements. People learn to attend mathematical operations in the order in which they should be executed, and the extent to which students employ their perceptual attention in this manner is positively correlated with their mathematical experience. For both science and mathematics, relatively sophisticated performance is achieved not by ignoring perceptual features in favor of deep conceptual features, but rather by adapting perceptual processing so as to conform with and support formally sanctioned responses. These "rigged-up perceptual systems" offer a promising approach to educational reform. © 2009 Cognitive Science Society, Inc.},
	number = {2},
	urldate = {2023-04-04},
	journal = {Topics in Cognitive Science},
	author = {Goldstone, Robert L. and Landy, David H. and Son, Ji Y.},
	month = apr,
	year = {2010},
	pmid = {25163789},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Complex systems, Education, Mathematical reasoning, Perceptual learning, Scientific reasoning},
	pages = {265--284},
}

@article{vanlehn_behavior_2006,
	title = {The {Behavior} of {Tutoring} {Systems}},
	volume = {16},
	issn = {1560-4292},
	number = {3},
	urldate = {2023-04-04},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {VanLehn, Kurt},
	month = jan,
	year = {2006},
	note = {Publisher: IOS Press},
	pages = {227--265},
}

@inproceedings{Wang2021,
	title = {Seeing beyond expert blind spots: {Online} learning design for scale and qality},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445045},
	doi = {10.1145/3411764.3445045},
	abstract = {Maximizing system scalability and quality are sometimes at odds. This work provides an example showing scalability and quality can be achieved at the same time in instructional design, contrary to what instructors may believe or expect. We situate our study in the education of HCI methods, and provide suggestions to improve active learning within the HCI education community. While designing learning and assessment activities, many instructors face the choice of using open-ended or close-ended activities. Close-ended activities such as multiple-choice questions (MCQs) enable automated feedback to students. However, a survey with 22 HCI professors revealed a belief that MCQs are less valuable than open-ended questions, and thus, using them entails making a quality sacrifce in order to achieve scalability. A study with 178 students produced no evidence to support the teacher belief. This paper indicates more promise than concern in using MCQs for scalable instruction and assessment in at least some HCI domains.},
	urldate = {2023-04-04},
	booktitle = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xu and Rose, Carolyn and Koedinger, Kenneth R.},
	month = may,
	year = {2021},
	keywords = {Hci education, Instructor belief, Learning experience design, Learning@scale, Matched assessment comparison, Multiple-choice questions},
}

@article{mccracken_text_2001,
	title = {Text to diagram to symbol: {Representational} transformations in problem-solving},
	volume = {2},
	issn = {01905848},
	doi = {10.1109/FIE.2001.963721},
	abstract = {Central to engineering problem solving is what we call representational transformation. Such transformations are built upon community-sanctioned practices often referred to as "back of the envelope" calculations. First a problem statement (text) is translated into a sketch (diagram) which visually articulates the essential problem parts. Mechanical models and free-body diagrams are instances of this first transformation. The qualitative model is then transformed into a set of mathematical formulae (symbols), which drive the problem solution. Thus, the problem is solved using three types of representational systems: textual, diagrammatic and symbolic. At each step the engineer translates information from one representational system to another, enacting an abstract cultural algorithm. The knowledge necessary to undertake these transformation is described in this paper in the context of multi-literacies. We propose that a large part of learning engineering problem solving is in fact learning the relationships between the multiple languages of problem solving.},
	urldate = {2023-04-04},
	journal = {Proceedings - Frontiers in Education Conference},
	author = {McCracken, W. M. and Newstetter, W. C.},
	year = {2001},
	keywords = {Education, Learning, Literacy, Problem-solving},
}

@inproceedings{expertBlindspot,
	title = {Expert blind spot: {When} content knowledge eclipses pedagogical content knowledge},
	volume = {644648},
	booktitle = {Proceedings of the third international conference on cognitive science},
	author = {Nathan, Mitchell J and Koedinger, Kenneth R and Alibali, Martha W and {others}},
	year = {2001},
}

@article{metarepresentation,
	title = {Metarepresentation: {Native} competence and targets for instruction},
	volume = {22},
	issn = {07370008},
	doi = {10.1207/s1532690xci2203_2},
	abstract = {The premise of this article is that the study of representation is valuable and important for mathematics and science students. Learning about representation should go beyond learning specific, sanctioned representations emphasized in standard curricula (graphs, tables, etc.) to include principles and design strategies that apply to any scientific representation, including novel variations and even completely new representations. The article explores what it means to understand representation, what we believe students already know about the topic, and what they can profitably learn about it. The discussion includes learning difficulties - goals for instruction that appear challenging for students and may need particular attention.},
	number = {3},
	urldate = {2022-03-16},
	journal = {Cognition and Instruction},
	author = {DiSessa, Andrea A.},
	year = {2004},
	note = {Publisher: Lawrence Erlbaum Associates, Inc.},
	pages = {293--331},
}

@inproceedings{representationalFluency,
	title = {Representational fluency in middle school: {A} classroom study},
	volume = {1},
	booktitle = {Proceedings of the twenty-fourth annual meeting of the {North} {American} chapter of the {International} {Group} for the {Psychology} of {Mathematics} {Education}},
	publisher = {ERIC Clearinghouse for Science, Mathematics and Environmental Education{\textasciitilde}…},
	author = {Nathan, Mitchell J and Stephens, Ana C and Masarik, D K and Alibali, Martha W and Koedinger, Kenneth R},
	year = {2002},
	pages = {462--472},
}

@article{pantziara_using_2009,
	title = {Using diagrams as tools for the solution of non-routine mathematical problems},
	volume = {72},
	issn = {00131954},
	url = {https://link.springer.com/article/10.1007/s10649-009-9181-5},
	doi = {10.1007/S10649-009-9181-5/FIGURES/15},
	abstract = {The Mathematics education community has long recognized the importance of diagrams in the solution of mathematical problems. Particularly, it is stated that diagrams facilitate the solution of mathematical problems because they represent problems' structure and information (Novick \& Hurley, 2001; Diezmann, 2005). Novick and Hurley were the first to introduce three well-defined types of diagrams, that is, network, hierarchy, and matrix, which represent different problematic situations. In the present study, we investigated the effects of these types of diagrams in non-routine mathematical problem solving by contrasting students' abilities to solve problems with and without the presence of diagrams. Structural equation modeling affirmed the existence of two first-order factors indicating the differential effects of the problems' representation, i.e., text with diagrams and without diagrams, and a second-order factor representing general non-routine problem solving ability in mathematics. Implicative analysis showed the influence of the presence of diagrams in the problems' hierarchical ordering. Furthermore, results provided support for other studies (e.g. Diezman \& English, 2001) which documented some students' difficulties to use diagrams efficiently for the solution of problems. We discuss the findings and provide suggestions for the efficient use of diagrams in the problem solving situation. © Springer Science+Business Media B.V. 2009.},
	number = {1},
	urldate = {2023-04-01},
	journal = {Educational Studies in Mathematics},
	author = {Pantziara, Marilena and Gagatsis, Athanasios and Elia, Iliada},
	month = feb,
	year = {2009},
	note = {Publisher: Springer},
	keywords = {Diagrams, Hierarchy, Implicative analysis, Matrix, Network, Non-routine problems, Structural equation modeling},
	pages = {39--60},
}

@inproceedings{gumtree,
	title = {Fine-grained and accurate source code differencing},
	isbn = {978-1-4503-3013-8},
	url = {https://dl.acm.org/doi/10.1145/2642937.2642982},
	doi = {10.1145/2642937.2642982},
	abstract = {At the heart of software evolution is a sequence of edit actions, called an edit script, made to a source code file. Since software systems are stored version by version, the edit script has to be computed from these versions, which is known as a complex task. Existing approaches usually compute edit scripts at the text granularity with only add line and delete line actions. However, inferring syntactic changes from such an edit script is hard. Since moving code is a frequent action performed when editing code, it should also be taken into account. In this paper, we tackle these issues by introducing an algorithm computing edit scripts at the abstract syntax tree granularity including move actions. Our objective is to compute edit scripts that are short and close to the original developer intent. Our algorithm is implemented in a freely-available and extensible tool that has been intensively validated.},
	urldate = {2023-04-01},
	booktitle = {{ASE} 2014 - {Proceedings} of the 29th {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Falleri, Jean Rémy and Morandat, Floréal and Blanc, Xavier and Martinez, Matias and Monperrus, Martin},
	year = {2014},
	keywords = {AST, Program comprehension, Software evolution, Tree differencing},
	pages = {313--323},
}

@inproceedings{Chen2022,
	title = {{CrossData}: {Leveraging} {Text}-{Data} {Connections} for {Authoring} {Data} {Documents}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517485},
	doi = {10.1145/3491102.3517485},
	abstract = {Data documents play a central role in recording, presenting, and disseminating data. Despite the proliferation of applications and systems designed to support the analysis, visualization, and communication of data, writing data documents remains a laborious process, requiring a constant back-and-forth between data processing and writing tools. Interviews with eight professionals revealed that their workflows contained numerous tedious, repetitive, and error-prone operations. The key issue that we identified is the lack of persistent connection between text and data. Thus, we developed CrossData, a prototype that treats text-data connections as persistent, interactive, first-class objects. By automatically identifying, establishing, and leveraging text-data connections, CrossData enables rich interactions to assist in the authoring of data documents. An expert evaluation with eight users demonstrated the usefulness of CrossData, showing that it not only reduced the manual effort in writing data documents but also opened new possibilities to bridge the gap between data exploration and writing.},
	urldate = {2023-03-23},
	booktitle = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Zhutian and Xia, Haijun},
	month = apr,
	year = {2022},
	keywords = {Data Document, Interactive Article, Language-oriented Authoring, Natural Language Processing, Text-based Editing},
}

@inproceedings{onishi_waddlewalls_2022,
	title = {{WaddleWalls}: {Room}-scale {Interactive} {Partitioning} {System} using a {Swarm} of {Robotic} {Partitions}},
	isbn = {978-1-4503-9320-1},
	url = {https://dl.acm.org/doi/10.1145/3526113.3545615},
	doi = {10.1145/3526113.3545615},
	abstract = {We propose WaddleWalls, a room-scale interactive partitioning system using a swarm of robotic partitions that allows occupants to interactively reconfigure workspace partitions to satisfy their privacy and interaction needs. The system can automatically arrange the partitions' layout designed by the user on demand. The user specifies the target partition's position, orientation, and height using the controller's 3D manipulations. In this work, we discuss the design considerations of the interactive partition system and implement WaddleWalls' proof-of-concept prototype assembled with off-the-shelf materials. We demonstrate the functionalities of WaddleWalls through several application scenarios in an open-planned office environment. We also conduct an initial user evaluation that compares WaddleWalls with conventional wheeled partitions, finding that WaddleWalls allows effective workspace partitioning and mitigates the physical and temporal efforts needed to fulfill ad hoc social and privacy requirements. Finally, we clarify the feasibility, potential, and future challenges of WaddleWalls through an interview with experts.},
	urldate = {2023-03-23},
	booktitle = {{UIST} 2022 - {Proceedings} of the 35th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Onishi, Yuki and Takashima, Kazuki and Higashiyama, Shoi and Fujita, Kazuyuki and Kitamura, Yoshifumi},
	month = oct,
	year = {2022},
	keywords = {Robotic Furniture, Shape-Changing Device, Spatial Input},
}

@article{perceptualLearning,
	title = {Perceptual learning modules in mathematics: {Enhancing} students' pattern recognition, structure extraction, and fluency},
	volume = {2},
	issn = {17568757},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1756-8765.2009.01053.x},
	doi = {10.1111/j.1756-8765.2009.01053.x},
	abstract = {Learning in educational settings emphasizes declarative and procedural knowledge. Studies of expertise, however, point to other crucial components of learning, especially improvements produced by experience in the extraction of information: perceptual learning (PL). We suggest that such improvements characterize both simple sensory and complex cognitive, even symbolic, tasks through common processes of discovery and selection. We apply these ideas in the form of perceptual learning modules (PLMs) to mathematics learning. We tested three PLMs, each emphasizing different aspects of complex task performance, in middle and high school mathematics. In the MultiRep PLM, practice in matching function information across multiple representations improved students' abilities to generate correct graphs and equations from word problems. In the Algebraic Transformations PLM, practice in seeing equation structure across transformations (but not solving equations) led to dramatic improvements in the speed of equation solving. In the Linear Measurement PLM, interactive trials involving extraction of information about units and lengths produced successful transfer to novel measurement problems and fraction problem solving. Taken together, these results suggest (a) that PL techniques have the potential to address crucial, neglected dimensions of learning, including discovery and fluent processing of relations; (b) PL effects apply even to complex tasks that involve symbolic processing; and (c) appropriately designed PL technology can produce rapid and enduring advances in learning. © 2009 Cognitive Science Society, Inc.},
	number = {2},
	urldate = {2022-03-06},
	journal = {Topics in Cognitive Science},
	author = {Kellman, Philip J. and Massey, Christine M. and Son, Ji Y.},
	month = apr,
	year = {2010},
	pmid = {25163790},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Algebra, Expertise, Fluency, Learning technology, Mathematics instruction, Mathematics learning, Pattern recognition, Perceptual learning, perceptual learning},
	pages = {285--305},
}

@book{rosen1999discrete,
	title = {Discrete mathematics \& applications},
	isbn = {978-0-07-338309-5},
	publisher = {McGraw-Hill},
	author = {Rosen, Kenneth H},
	year = {1999},
}

@book{burger2007holt,
	title = {Holt geometry},
	publisher = {Holt, Rinehart and Winston},
	author = {Burger, Edward B and Chard, David J and Hall, Earlene J and Kennedy, Paul A and Leinwand, Steven J and Renfro, Freddie L and Seymour, Dale G and Wattis, Bert K},
	year = {2007},
}

@inproceedings{CTAT,
	address = {Jhongli, Taiwan},
	title = {The cognitive tutor authoring tools ({CTAT}): {Preliminary} evaluation of efficiency gains},
	volume = {4053 LNCS},
	isbn = {3-540-35159-0},
	url = {https://link.springer.com/chapter/10.1007/11774303_7},
	doi = {10.1007/11774303_7},
	abstract = {Intelligent Tutoring Systems have been shown to be effective in a number of domains, but they remain hard to build, with estimates of 200-300 hours of development per hour of instruction. Two goals of the Cognitive Tutor Authoring Tools (CTAT) project are to (a) make tutor development more efficient for both programmers and non-programmers and (b) produce scientific evidence indicating which tool features lead to improved efficiency. CTAT supports development of two types of tutors, Cognitive Tutors and Example-Tracing Tutors, which represent different trade-offs in terms of ease of authoring and generality. In preliminary small-scale controlled experiments involving basic Cognitive Tutor development tasks, we found efficiency gains due to CTAT of 1.4 to 2 times faster. We expect that continued development of CTAT, informed by repeated evaluations involving increasingly complex authoring tasks, will lead to further efficiency gains. © Springer-Verlag Berlin Heidelberg 2006.},
	urldate = {2022-03-14},
	booktitle = {International {Conference} on {Intelligent} {Tutoring} {Systems}},
	publisher = {Springer},
	author = {Aleven, Vincent and McLaren, Bruce M. and Sewall, Jonathan and Koedinger, Kenneth R.},
	year = {2006},
	note = {ISSN: 16113349},
	pages = {61--70},
}

@article{nimoThesisProposal,
	title = {Developing conceptual understanding through interactive diagramming},
	abstract = {“Mental pictures” and “visual intuition” capture how people make sense of ab- stract concepts and see solutions to hard problems in a visual way. Learning research suggests that visual representations of knowledge are powerful tools for thought. Visual representations like diagrams enable more robust learning and flexible problem solving. Existing diagramming tools often require hours of low-level tweaking of geometric primitives and do not capture the core task of diagramming: representing ideas visually. PENROSE is a diagramming platform that explicitly encodes visual representations in domain-specific languages. In this thesis proposal, I argue that this explicit encoding can be leveraged to (1) reduce the programming effort of pro- ducing diagrammatic problems at scale and (2) simplify the workflow of authoring interactive diagrams. The resulting diagrams also carry rich semantics, and I’ll dis- cuss how to use them to (3) provide useful, automated feedback to students.},
	author = {Ni, Wode},
	year = {2022},
	note = {Publisher: Carnegie Mellon University},
	pages = {24},
}

@article{wilson_harnessing_2003,
	title = {Harnessing curiosity to increase correctness in end-user programming},
	url = {https://dl.acm.org/doi/10.1145/642611.642665},
	doi = {10.1145/642611.642665},
	abstract = {Despite their ability to help with program correctness, assertions have been notoriously unpopular-even with professional programmers. End-user programmers seem even less likely to appreciate the value of assertions; yet end-user programs suffer from serious correctness problems that assertions could help detect. This leads to the following question: can end users be enticed to enter assertions? To investigate this question, we have devised a curiosity-centered approach to eliciting assertions from end users, built on a surprise-explain-reward strategy. Our follow-up work with end-user participants shows that the approach is effective in encouraging end users to enter assertions that help them find errors. Copyright 2003 ACM.},
	urldate = {2023-02-24},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Wilson, Aaron and Burnett, Margaret and Beckwith, Laura and Granatir, Orion and Casburn, Ledah and Cook, Curtis and Durham, Mike and Rothermel, Gregg},
	year = {2003},
	note = {ISBN: 1581136307},
	keywords = {Assertions, Curiosity, End-user software engineering},
	pages = {305--312},
}

@article{fuhrman_developing_2018,
	title = {Developing {Good} {Multiple}-{Choice} {Tests} and {Test} {Questions}},
	volume = {44},
	issn = {10899995},
	url = {https://www.tandfonline.com/doi/abs/10.5408/1089-9995-44.4.379},
	doi = {10.5408/1089-9995-44.4.379},
	abstract = {Multiple-choice tests, although often criticized, still form the backbone of most standardized and classroom tests for a variety of reasons. The advantages of multiple-choice assessments over most ...},
	number = {4},
	urldate = {2023-02-24},
	journal = {https://doi.org/10.5408/1089-9995-44.4.379},
	author = {Fuhrman, Miriam},
	year = {2018},
	pmid = {i0022-1368-44-4-379},
	note = {Publisher: National Association of Geology Teachers},
	keywords = {Education – testing and evaluation, education – geoscience},
	pages = {379--384},
}

@article{mccoubrie_improving_2009,
	title = {Improving the fairness of multiple-choice questions: a literature review},
	volume = {26},
	issn = {0142159X},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01421590400013495},
	doi = {10.1080/01421590400013495},
	abstract = {The ubiquity of multiple-choice questions (MCQs) results from their efficiency and hence reliability. Cognitive knowledge assessed by MCQ predicts and correlates well with overall competence and pe...},
	number = {8},
	urldate = {2023-02-24},
	journal = {http://dx.doi.org/10.1080/01421590400013495},
	author = {McCoubrie, Paul},
	month = dec,
	year = {2009},
	pmid = {15763874},
	note = {Publisher: Taylor \& Francis},
	pages = {709--712},
}

@article{Dreyfus2006,
	title = {Exemplification in mathematics education},
	abstract = {There is evidence from earliest historical records that examples play a central role in both the development of mathematics as a discipline and in the teaching of mathematics. It is not surprising therefore that examples have found a place in many theories of learning mathematics. Many would argue that the use of examples is an integral part of the discipline of mathematics and not just an aid for teaching and learning. The forum takes as its background both the variety of ways in which examples are construed within different theories of learning and the contribution that attention to examples can make to the learning and teaching processes. Consequently the forum can be seen as addressing issues at the very heart of mathematics education, both drawing upon and informing many other research topics. We argue that paying attention to examples offers both a practically useful and an important theoretical perspective on the design of teaching activities, on the appreciation of learners’ experiences and on the professional development of mathematics teachers. The importance of these ideas does not actually depend on the framework used for analysing teachers’ intentions, nor on any terms used to describe forms of teaching, such as: ‘analytic-inductive’ or ‘synthetic-deductive’, ‘traditional’ or ‘reform’, ‘rote- learning’ or ‘teaching for understanding’, ‘authentic’ or ‘investigative’. Issues in exemplification are relevant to all kinds of engagement with mathematics. This paper positions exemplification on the research agenda for the community by giving a historical overview of the way examples have been seen in mathematics education; an account of associated literature; an exploration of how exemplification ‘fits’ with various perspectives on learning mathematics; accounts of issues relating to teachers’ and learners’ use of examples; and directions for future research.},
	number = {Leinhardt 2001},
	urldate = {2023-02-23},
	journal = {30th Conference of the International Group for the Psychology of Mathematics Education},
	author = {Dreyfus, Tommy and Mason, John and Tsamir, Pessia and Watson, Anne and Zaslavsky, Orit},
	year = {2006},
	note = {Publisher: PME
ISBN: 0771-100x},
	keywords = {Aviv, Open, Oxford, Technion-Israel), Tel-Aviv},
	pages = {126--154},
}

@article{Sevimli2022,
	title = {Exemplification process in online education: a longitudinal study of mathematics teachers},
	issn = {15731855},
	url = {https://link.springer.com/article/10.1007/s10984-022-09440-y},
	doi = {10.1007/s10984-022-09440-y},
	abstract = {The examples used in the teaching–learning process of mathematics have a crucial role in fostering conceptual understanding, and some variables can affect instructors' qualified example usage. This longterm study focused on mathematics teachers’ exemplification process in face-to-face and online learning environments. In this regard, the change in examples used by mathematics teachers were evaluated in terms of content preparation and presentation during the shift from face-to-face lectures to online classes. A longitudinal design was used in the study and the teaching processes of 14 middle-school mathematics teachers were observed over two semesters. Observation notes, course documents, and semi-structured interview data were analyzed, and content analysis findings were presented through descriptive statistics in order to compare content preferences in two different learning environments. The use of worked examples decreased, while the use of conceptual examples increased with the shift from face-to-face lectures to online classes. Also the length of time devoted to examples in online classes decreased, and examples were more teacher-centered. The interview revealed that mathematics teachers need support in terms of example preparation and presentation aspects in online learning environments. The other technological-pedagogical competencies that teachers might need to choose qualified examples in different teaching–learning environments are discussed in the light of relevant literature.},
	urldate = {2023-02-23},
	journal = {Learning Environments Research},
	author = {Sevimli, Eyüp},
	month = nov,
	year = {2022},
	note = {Publisher: Springer Science and Business Media B.V.},
	keywords = {Exemplification, Mathematics teachers, Online education, Teaching practices},
	pages = {1--24},
}

@article{hurley_solving_2010,
	title = {Solving problems using matrix, network, and hierarchy diagrams: {The} consequences of violating construction conventions},
	volume = {63},
	issn = {17470218},
	url = {https://journals.sagepub.com/doi/10.1080/17470210902888908},
	doi = {10.1080/17470210902888908},
	abstract = {In order for a diagram to be useful for solving a problem, it must be constructed so that its perceptual features facilitate inferences relevant to that problem. In Experiment 1, we established the construction conventions, which relate to how information is assigned to different parts of the diagram, for three spatial representations-networks, hierarchies, and matrices. In Experiment 2, participants solved problems using diagrams that either followed or violated these conventions. As hypothesized, participants took longer to draw inferences from convention-violating matrix and network diagrams than from their convention-following counterparts, and these inferences were less accurate. Convention adherence did not affect reasoning time or accuracy for hierarchy diagrams. The authors concluded that the construction conventions are related to perceptual features that facilitate certain types of inferences for matrix and network diagrams, and they discussed why this might not have been the case for the hierarchy. © 2009 The Experimental Psychology Society.},
	number = {2},
	urldate = {2023-02-23},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Hurley, Sean M. and Novick, Laura R.},
	month = feb,
	year = {2010},
	pmid = {19440931},
	note = {Publisher: SAGE PublicationsSage UK: London, England},
	keywords = {Conventions, Diagrams, Problem solving, Representations},
	pages = {275--290},
}

@article{ayabe_problem-appropriate_2022,
	title = {Problem-appropriate diagram instruction for improving mathematical word problem solving},
	volume = {13},
	issn = {16641078},
	doi = {10.3389/fpsyg.2022.992625},
	abstract = {The use of diagrams can be effective in solving mathematical word problems solving. However, students worldwide do not construct diagrams unprompted or have trouble using them. In the present study, the effects of problem-appropriate diagram use instruction were investigated with an adaptation of the multiple baseline design method. The instruction for using line diagrams, tables, and graphs was provided to 67 junior high school students in a staggered manner and the effects on problem solving of three different types of problems was examined. The results showed that use of problem-appropriate diagrams increased and persisted over time. More importantly, the instruction led to increases in problem solving performance and to decreases in perceived cognitive load. These findings support the argument that effective diagram use depends on the acquisition not only of declarative knowledge, but also sufficient procedural and conditional knowledge.},
	urldate = {2023-02-23},
	journal = {Frontiers in Psychology},
	author = {Ayabe, Hiroaki and Manalo, Emmanuel and Vries, Erica de},
	month = oct,
	year = {2022},
	note = {Publisher: Frontiers Media S.A.},
	keywords = {Japanese students, cognitive load, instructional methods, mathematical word problem solving, multiple baseline design, representational effect, self-constructed diagrams, visual representation},
	pages = {6113},
}

@incollection{Barwise2019,
	title = {Visual information and valid reasoning},
	isbn = {978-0-429-30162-9},
	url = {https://academic.oup.com/book/40816/chapter/348782106},
	urldate = {2023-02-09},
	booktitle = {Philosophy {And} {The} {Computer}},
	author = {Barwise, Jon and Etchemendy, John},
	year = {2019},
	doi = {10.1093/oso/9780195104271.003.0005},
	pages = {160--182},
}

@article{jayagopal_exploring_2022,
	title = {Exploring the {Learnability} of {Program} {Synthesizers} by {Novice} {Programmers}},
	url = {https://dl.acm.org/doi/10.1145/3526113.3545659},
	doi = {10.1145/3526113.3545659},
	abstract = {Modern program synthesizers are increasingly delivering on their promise of lightening the burden of programming by automatically generating code, but little research has addressed how we can make such systems learnable to all. In this work, we ask: What aspects of program synthesizers contribute to and detract from their learnability by novice programmers? We conducted a thematic analysis of 22 observations of novice programmers, during which novices worked with existing program synthesizers, then participated in semi-structured interviews. Our findings shed light on how their specific points in the synthesizer design space affect these tools' learnability by novice programmers, including the type of specification the synthesizer requires, the method of invoking synthesis and receiving feedback, and the size of the specification. We also describe common misconceptions about what constitutes meaningful progress and useful specifications for the synthesizers, as well as participants' common behaviors and strategies for using these tools. From this analysis, we offer a set of design opportunities to inform the design of future program synthesizers that strive to be learnable by novice programmers. This work serves as a first step toward understanding how we can make program synthesizers more learnable by novices, which opens up the possibility of using program synthesizers in educational settings as well as developer tooling oriented toward novice programmers.},
	urldate = {2023-02-13},
	journal = {UIST 2022 - Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
	author = {Jayagopal, Dhanya and Lubin, Justin and Chasins, Sarah E.},
	month = oct,
	year = {2022},
	note = {Publisher: Association for Computing Machinery, Inc
ISBN: 9781450393201},
	keywords = {learnability, novice programmers, program synthesis, qualitative, thematic analysis},
}

@book{Moktefi2013,
	title = {Visual reasoning with diagrams},
	isbn = {978-3-0348-0600-8},
	abstract = {Logic, the discipline that explores valid reasoning, does not need to be limited to a specific form of representation but should include any form as long as it allows us to draw sound conclusions from given information. The use of diagrams has a long but unequal history in logic: The golden age of diagrammatic logic of the 19th century thanks to Euler and Venn diagrams was followed by the early 20th century's symbolization of modern logic by Frege and Russell. Recently, we have been witnessing a revival of interest in diagrams from various disciplines - mathematics, logic, philosophy, cognitive science, and computer science. This book aims to provide a space for this newly debated topic - the logical status of diagrams - in order to advance the goal of universal logic by exploring common and/or unique features of visual reasoning.},
	urldate = {2023-02-09},
	publisher = {Springer Basel},
	author = {Moktefi, Amirouche and Shin, Sun Joo},
	month = jan,
	year = {2013},
	doi = {10.1007/978-3-0348-0600-8},
	note = {Publication Title: Visual Reasoning with Diagrams},
}

@article{Dyer22,
	title = {Applying cognitive principles to model-finding output: {The} positive value of negative information},
	volume = {6},
	issn = {24751421},
	url = {https://dl.acm.org/doi/10.1145/3527323},
	doi = {10.1145/3527323},
	abstract = {Model-finders, such as SAT/SMT-solvers and Alloy, are used widely both directly and embedded in domain-specific tools. They support both conventional verification and, unlike other verification tools, property-free exploration. To do this effectively, they must produce output that helps users with these tasks. Unfortunately, the output of model-finders has seen relatively little rigorous human-factors study. Conventionally, these tools tend to show one satisfying instance at a time. Drawing inspiration from the cognitive science literature, we investigate two aspects of model-finder output: how many instances to show at once, and whether all instances must actually satisfy the input constraints. Using both controlled studies and open-ended talk-alouds, we show that there is benefit to showing negative instances in certain settings; the impact of multiple instances is less clear. Our work is a first step in a theoretically grounded approach to understanding how users engage cognitively with model-finder output, and how those tools might better support users in doing so.},
	number = {OOPSLA1},
	urldate = {2023-01-20},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Dyer, Tristan and Nelson, Tim and Fisler, Kathi and Krishnamurthi, Shriram},
	month = apr,
	year = {2022},
	note = {Publisher: ACM PUB27 New York, NY, USA},
	keywords = {Alloy, cognitive science, model finding, user studies},
}

@article{dyer_applying_2022,
	title = {Applying cognitive principles to model-finding output: the positive value of negative information},
	volume = {6},
	issn = {24751421},
	url = {https://dl.acm.org/doi/10.1145/3527323},
	doi = {10.1145/3527323},
	abstract = {Model-finders, such as SAT/SMT-solvers and Alloy, are used widely both directly and embedded in domain-specific tools. They support both conventional verification and, unlike other verification too...},
	number = {OOPSLA1},
	urldate = {2023-01-20},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Dyer, Tristan and Nelson, Tim and Fisler, Kathi and Krishnamurthi, Shriram},
	month = apr,
	year = {2022},
	note = {Publisher: 
		ACM
		PUB27
		New York, NY, USA},
	keywords = {Alloy, cognitive science, model finding, user studies},
}

@article{Koedinger1990a,
	title = {Abstract planning and perceptual chunks: {Elements} of expertise in geometry},
	volume = {14},
	issn = {03640213},
	url = {http://doi.wiley.com/10.1016/0364-0213(90)90008-K},
	doi = {10.1016/0364-0213(90)90008-K},
	abstract = {We present a new model of skilled performance in geometry proof problem solving called the Diagram Configuration model (DC). While previous models plan proofs in a step-by-step fashion, we observed that experts plan at a more abstract level: They focus on the key steps and skip the less important ones. DC models this abstract planning behavior by parsing geometry problem diagrams into perceptual chunks, called diagram configurations, which cue relevant schematic knowledge. We provide verbal protocol evidence that DC's schemas correspond with the step-skipping inferences experts make in their initial planning. We compare DC with other models of geometry expertise and then, in the final section, we discuss more general implications of our research. DC's reasoning has important similarities with Larkin's (1988) display-based reasoning approach and Johnson-Laird's (1983) mental model approach. DC's perceptually based schemas are a step towards a unified explanation of (1) experts' superior problem-solving effectiveness, (2) experts' superior problem-state memory, and (3) experts' ability, in certain domains, to solve relatively simple problems by pure forward inferencing. We also argue that the particular and efficient knowledge organization of DC challenges current theories of skill acquisition as it presents an end-state of learning that is difficult to explain within such theories. Finally, we discuss the implications of DC for geometry instruction. © 1990.},
	number = {4},
	urldate = {2022-02-17},
	journal = {Cognitive Science},
	author = {Koedinger, K},
	month = dec,
	year = {1990},
	note = {Publisher: No longer published by Elsevier},
	pages = {511--550},
}

@article{cordy_txl_2006,
	title = {The {TXL} source transformation language},
	volume = {61},
	issn = {0167-6423},
	doi = {10.1016/J.SCICO.2006.04.002},
	abstract = {TXL is a special-purpose programming language designed for creating, manipulating and rapidly prototyping language descriptions, tools and applications. TXL is designed to allow explicit programmer control over the interpretation, application, order and backtracking of both parsing and rewriting rules. Using first order functional programming at the higher level and term rewriting at the lower level, TXL provides for flexible programming of traversals, guards, scope of application and parameterized context. This flexibility has allowed TXL users to express and experiment with both new ideas in parsing, such as robust, island and agile parsing, and new paradigms in rewriting, such as XML mark-up, rewriting strategies and contextualized rules, without any change to TXL itself. This paper outlines the history, evolution and concepts of TXL with emphasis on its distinctive style and philosophy, and gives examples of its use in expressing and applying recent new paradigms in language processing. © 2006 Elsevier B.V. All rights reserved.},
	number = {3},
	urldate = {2022-11-22},
	journal = {Science of Computer Programming},
	author = {Cordy, James R.},
	month = aug,
	year = {2006},
	note = {Publisher: Elsevier},
	keywords = {Functional programming, Grammars, Source transformation, Term rewriting},
	pages = {190--210},
}

@article{johnson_feedback_2014,
	title = {The {Feedback} {Principle} in {Multimedia} {Learning}},
	url = {https://www.cambridge.org/core/books/cambridge-handbook-of-multimedia-learning/feedback-principle-in-multimedia-learning/F52480F8ED64AE42AA8D999E9460C08F},
	doi = {10.1017/CBO9781139547369.023},
	abstract = {Multimedia learning environments require learners to integrate information across different sources and modalities, which can pose a challenge for some learners. Providing feedback on student responses can be an effective method of guiding learners to achieve a deep understanding of the material. The feedback principle states that novice students learn better wiThexplanatory feedback than with corrective feedback alone. Explanatory feedback provides the learner with a principle-based explanation of why his or her answer was correct or incorrect, whereas corrective feedback merely informs the learner that his or her response was correct or incorrect. The theoretical rationale is that explanatory feedback guides the learner in selecting the appropriate information and consequently reduces the amount of extraneous processing relative to providing only corrective feedback. This chapter reviews evidence for the feedback principle and explores some of the boundary conditions.},
	urldate = {2022-04-05},
	journal = {The Cambridge Handbook of Multimedia Learning, Second Edition},
	author = {Johnson, Cheryl I. and Priest, Heather A.},
	month = jan,
	year = {2014},
	note = {Publisher: Cambridge University Press
ISBN: 9781139547369},
	pages = {449--463},
}

@article{moreno_decreasing_2004,
	title = {Decreasing {Cognitive} {Load} for {Novice} {Students}: {Effects} of {Explanatory} versus {Corrective} {Feedback} in {Discovery}-{Based} {Multimedia}},
	volume = {32},
	issn = {1573-1952},
	url = {https://link.springer.com/article/10.1023/B:TRUC.0000021811.66966.1d},
	doi = {10.1023/B:TRUC.0000021811.66966.1D},
	abstract = {This paper examines one of the potentialroles that software agents may have inhelping students reduce working memoryload while learning from discovery-basedmultimedia environments: providingexplanatory feedback. Two studiesexamined the guided feedbackhypothesis according to which, discoverylearning environments that use explanatoryfeedback (EF) to guide novice students inthe process of meaning making promotedeeper learning than those that presentidentical materials using correctivefeedback (CF) alone. In both experiments,the EF group produced higher transferscores, rated the computer game as morehelpful, and gave comparable interest andmotivation ratings than the CF group. Mental load rating scales providedevidence in both experiments that EF waseffective due to reductions in cognitiveload. Results support the use of agentguidance in the form of EF for novicestudents who learn with discovery-basedmultimedia games.},
	number = {1},
	urldate = {2022-04-05},
	journal = {Instructional Science 2004 32:1},
	author = {Moreno, Roxana},
	year = {2004},
	note = {Publisher: Springer},
	keywords = {Educational Psychology, Learning and Instruction, Pedagogic Psychology},
	pages = {99--113},
}

@inproceedings{callbackSpaghetti,
	address = {New York, New York, USA},
	title = {Separating application code from toolkits: {Eliminating} the {Spaghetti} of call-backs},
	isbn = {0-89791-451-1},
	doi = {10.1145/120782},
	abstract = {Conventional toolkits today require the programmer to attach call-back procedures to most buttons, scroll bars, menu items, and other widgets in the interface. These procedures are called by the system when the user operates the widget in order to notify the application of the user's actions. Unfortunately, real interfaces contain hundreds or thousands of widgets, and therefore many call-back procedures, most of which perform trivial tasks, resulting in a maintenance nightmare. This paper describes a system that allows the majority of these procedures to be eliminated. The user interface designer can specify by demonstration many of the desired actions and connections among the widgets, so call-backs are only needed for the most significant application actions. In addition, the callbacks that remain are completely insulated from the widgets, so that the application code is better separated from the user interface.},
	urldate = {2022-03-16},
	booktitle = {Proceedings of the 4th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}, {UIST} 1991},
	publisher = {ACM Press},
	author = {Myers, Brad A},
	year = {1991},
	keywords = {Call-back procedures, Dialog boxes, Interface builders, UIMSS},
	pages = {211--220},
}

@article{infovizInteractionFramework,
	title = {Toward a deeper understanding of the role of interaction in information visualization},
	volume = {13},
	issn = {10772626},
	doi = {10.1109/TVCG.2007.70515},
	abstract = {Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction. © 2007 IEEE.},
	number = {6},
	urldate = {2022-03-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yi, Ji Soo and Kang, Youn Ah and Stasko, John T. and Jacko, Julie A.},
	month = nov,
	year = {2007},
	keywords = {Information visualization, Interaction, Interaction techniques, Taxonomy, Visual analytics},
	pages = {1224--1231},
}

@article{scholarPhi,
	title = {Augmenting scientific papers with just-in-time, position-sensitive definitions of terms and symbols},
	url = {https://doi.org/10.1145/3411764.3445648},
	doi = {10.1145/3411764.3445648},
	abstract = {Despite the central importance of research papers to scientifc progress, they can be difcult to read. Comprehension is often stymied when the information needed to understand a passage resides somewhere else-in another section, or in another paper. In this work, we envision how interfaces can bring defnitions of technical terms and symbols to readers when and where they need them most. We introduce ScholarPhi, an augmented reading interface with four novel features: (1) tooltips that surface position-sensitive defnitions from elsewhere in a paper, (2) a flter over the paper that declutters it to reveal how the term or symbol is used across the paper, (3) automatic equation diagrams that expose multiple defnitions in parallel, and (4) an automatically generated glossary of important terms and symbols. A usability study showed that the tool helps researchers of all experience levels read papers. Furthermore, researchers were eager to have ScholarPhi's defnitions available to support their everyday reading.},
	urldate = {2022-03-17},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Head, Andrew and Lo, Kyle and Kang, Dongyeop and Fok, Raymond and Skjonsberg, Sam and Weld, Daniel S and Hearst, Marti A},
	month = may,
	year = {2021},
	note = {arXiv: 2009.14237
Publisher: Association for Computing Machinery
ISBN: 9781450380966},
	keywords = {Defnitions, Interactive documents, Nonce words, Reading interfaces, Scientifc papers},
}

@inproceedings{nota,
	address = {Virtual},
	title = {A {New} {Medium} for {Communicating} {Research} on {Programming} {Languages}},
	url = {https://willcrichton.net/nota/},
	abstract = {Papers about programming languages involve complex notations, systems, and proofs. Static PDFs offer little support in understanding such concepts. I describe Nota, a framework for academic papers that uses the browser's interactive capabilities to support comprehension in context. Nota uses hover effects, tooltips, expandable sections, toggleable explanations, and other interactions to help readers understand a language's syntax and semantics. I demonstrate the use of Nota by rewriting a PL paper using its primitives, and also by writing this paper in Nota.},
	booktitle = {11th {Workshop} on {Evaluation} and {Usability} of {Programming} {Languages} and {Tools} ({PLATEAU} 2020)},
	author = {{Will Crichton}},
	year = {2020},
}

@article{learningWithRepresentations,
	title = {What recent research on diagrams suggests about learning with rather than learning from visual representations in science},
	volume = {38},
	issn = {14645289},
	url = {https://www.tandfonline.com/doi/abs/10.1080/09500693.2016.1158435},
	doi = {10.1080/09500693.2016.1158435},
	abstract = {The move from learning science from representations to learning science with representations has many potential and undocumented complexities. This thematic analysis partially explores the trends of representational uses in science instruction, examining 80 research studies on diagram use in science. These studies, published during 2000-2014, were located through searches of journal databases and books. Open coding of the studies identified 13 themes, 6 of which were identified in at least 10\% of the studies: eliciting mental models, classroom-based research, multimedia principles, teaching and learning strategies, representational competence, and student agency. A shift in emphasis on learning with rather than learning from representations was evident across the three 5-year intervals considered, mirroring a pedagogical shift from science instruction as transmission of information to constructivist approaches in which learners actively negotiate understanding and construct knowledge. The themes and topics in recent research highlight areas of active interest and reveal gaps that may prove fruitful for further research, including classroom-based studies, the role of prior knowledge, and the use of eye-tracking. The results of the research included in this thematic review of the 2000-2014 literature suggest that both interpreting and constructing representations can lead to better understanding of science concepts.},
	number = {5},
	urldate = {2022-03-17},
	journal = {International Journal of Science Education},
	author = {Tippett, Christine D.},
	month = apr,
	year = {2016},
	note = {Publisher: Routledge},
	keywords = {Diagram, Language, Metasynthesis, Science literacy, Visual representation},
	pages = {725--746},
}

@book{bloomRevised,
	title = {A taxonomy for learning, teaching, and assessing: {A} revision of {Bloom}'s taxonomy of educational objectives},
	publisher = {Longman},
	author = {Krathwohl, David R and Anderson, Lorin W},
	year = {2009},
}

@inproceedings{idyll,
	title = {{IdylL}: {A} markup language for authoring and publishing interactive articles on the web},
	isbn = {978-1-4503-5948-1},
	doi = {10.1145/3242587.3242600},
	abstract = {The web has matured as a publishing platform: news outlets regularly publish rich, interactive stories while technical writers use animation and interaction to communicate complex ideas. This style of interactive media has the potential to engage a large audience and more clearly explain concepts, but is expensive and time consuming to produce. Drawing on industry experience and interviews with domain experts, we contribute design tools to make it easier to author and publish interactive articles. We introduce Idyll, a novel “compile-to-the-web” language for web-based interactive narratives. Idyll implements a flexible article model, allowing authors control over document style and layout, reader-driven events (such as button clicks and scroll triggers), and a structured interface to JavaScript components. Through both examples and first-use results from undergraduate computer science students, we show how Idyll reduces the amount of effort and custom code required to create interactive articles.},
	urldate = {2022-03-17},
	booktitle = {{UIST} 2018 - {Proceedings} of the 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Conlen, Matthew and Heer, Jeffrey},
	month = oct,
	year = {2018},
	keywords = {Artifact or System, Interaction Design, Programming Languages, Programming/Development Support, Prototyping/Implementation, Storytelling, Visualization},
	pages = {977--989},
}

@inproceedings{dataTheater,
	title = {Data {Theater}: {A} {Live} {Programming} {Environment} for {Prototyping} {Data}-{Driven} {Explorable} {Explanations}},
	url = {https://par.nsf.gov/biblio/10210727},
	booktitle = {Workshop on {Live} {Programming} ({LIVE})},
	author = {Lau, Sam and Guo, Philip J},
	year = {2020},
}

@article{lim_ply_2018,
	title = {Ply: {A} visual web inspector for learning from professional webpages},
	doi = {10.1145/3242587.3242660},
	abstract = {While many online resources teach basic web development, few are designed to help novices learn the CSS concepts and design patterns experts use to implement complex visual features. Professional webpages embed these design patterns and could serve as rich learning materials, but their stylesheets are complex and difficult for novices to understand. This paper presents Ply, a CSS inspection tool that helps novices use their visual intuition to make sense of professional webpages. We introduce a new visual relevance testing technique to identify properties that have visual effects on the page, which Ply uses to hide visually irrelevant code and surface unintuitive relationships between properties. In user studies, Ply helped novice developers replicate complex web features 50\% faster than those using Chrome Developer Tools, and allowed novices to recognize and explain unfamiliar concepts. These results show that visual inspection tools can support learning from complex professional webpages, even for novice developers.},
	urldate = {2022-03-17},
	journal = {UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
	author = {Lim, Sarah and Hibschman, Joshua and Zhang, Haoqi and O'Rourke, Eleanor},
	month = oct,
	year = {2018},
	note = {Publisher: Association for Computing Machinery, Inc
ISBN: 9781450359481},
	keywords = {Authentic learning, CSS, Developer tools, Web inspection},
	pages = {991--1002},
}

@article{ASSISTment,
	title = {The {ASSISTment} builder: {Supporting} the life cycle of tutoring system content creation},
	volume = {2},
	issn = {19391382},
	doi = {10.1109/TLT.2009.23},
	abstract = {Content creation is a large component of the cost of creating educational software. Estimates are that approximately 200 hours of development time are required for every hour of instruction. We present an authoring tool designed to reduce this cost as it helps to refine and maintain content. The ASSISTment Builder is a tool designed to effectively create, edit, test, and deploy tutor content. The Web-based interface simplifies the process of tutor construction to allow users with little or no programming experience to develop content. We show the effectiveness of our Builder at reducing the cost of content creation to 40 hours for every hour of instruction. We describe new features that work toward supporting the life cycle of ITS content creation through maintaining and improving content as it is being used by students. The Variabilization feature allows the user to reuse tutoring content across similar problems. The Student Comments feature provides a way to maintain and improve content based on feedback from users. The Most Common Wrong Answer feature provides a way to refine remediation based on the users' answers. This paper describes our attempt to support the life cycle of content creation. © 2009 IEEE.},
	number = {2},
	urldate = {2022-03-14},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Razzaq, Leena and Patvarczki, Jozsef and Almeida, Shane F. and Vartak, Manasi and Feng, Mingyu and Heffernan, Neil T. and Koedinger, Kenneth R.},
	year = {2009},
	keywords = {Adaptive and intelligent educational systems, Authoring tools, Computer uses in education, E-learning tools},
	pages = {157--166},
}

@article{massProduction,
	title = {Rapid authoring of {Intelligent} {Tutors} for real-world and experimental use},
	volume = {2006},
	doi = {10.1109/ICALT.2006.1652575},
	abstract = {Authoring tools for Intelligent Tutoring Systems are especially valuable if they not only provide a rich set of options for the efficient authoring of tutoring systems but also support controlled experiments in which the added educational value of new tutor features is evaluated. The Cognitive Tutor Authoring Tools (CTAT) provide both. Using CTAT, real-world "Example- Tracing Tutors" can be created without programming. CTAT also provides various kinds of support for controlled experiments, such as administration of different experimental treatments, logging, and data analysis. We present two case studies in which Example-Tracing Tutors created with CTAT were used in classroom experiments. The case studies illustrate a number of new features in CTAT: Use of Macromedia Flash MX 2004 for creating tutor interfaces, extensions to the Example-Tracing Engine that allow for more flexible tutors, a Mass Production facility for more efficient template-based authoring, and support for controlled experiments. © 2006 IEEE.},
	urldate = {2022-03-14},
	journal = {Proceedings - Sixth International Conference on Advanced Learning Technologies, ICALT 2006},
	author = {Aleven, Vincent and Sewall, Jonathan and McLaren, Bruce M. and Koedinger, Kenneth R.},
	year = {2006},
	note = {ISBN: 0769526322},
	pages = {847--851},
}

@article{RT07,
	title = {The shuffling of mathematics problems improves learning},
	volume = {35},
	issn = {00204277},
	url = {https://link.springer.com/article/10.1007/s11251-007-9015-8},
	doi = {10.1007/s11251-007-9015-8},
	abstract = {In most mathematics textbooks, each set of practice problems is comprised almost entirely of problems corresponding to the immediately previous lesson. By contrast, in a small number of textbooks, the practice problems are systematically shuffled so that each practice set includes a variety of problems drawn from many previous lessons. The standard and shuffled formats differ in two critical ways, and each was the focus of an experiment reported here. In Experiment 1, college students learned to solve one kind of problem, and subsequent practice problems were either massed in a single session (as in the standard format) or spaced across multiple sessions (as in the shuffled format). When tested 1 week later, performance was much greater after spaced practice. In Experiment 2, students first learned to solve multiple types of problems, and practice problems were either blocked by type (as in the standard format) or randomly mixed (as in the shuffled format). When tested 1 week later, performance was vastly superior after mixed practice. Thus, the results of both experiments favored the shuffled format over the standard format. © 2007 Springer Science+Business Media, Inc.},
	number = {6},
	urldate = {2022-03-17},
	journal = {Instructional Science},
	author = {Rohrer, Doug and Taylor, Kelli},
	month = nov,
	year = {2007},
	note = {Publisher: Springer},
	keywords = {Block, Distribute, Interleave, Mass, Mathematics, Mix, Practice, Spacing},
	pages = {481--498},
}

@article{PV94,
	title = {Variability of {Worked} {Examples} and {Transfer} of {Geometrical} {Problem}-{Solving} {Skills}: {A} {Cognitive}-{Load} {Approach}},
	volume = {86},
	issn = {00220663},
	doi = {10.1037/0022-0663.86.1.122},
	abstract = {Four computer-based training strategies for geometrical problem solving in the domain of computer numerically controlled machinery programming were studied with regard to their effects on training performance, transfer performance, and cognitive load. A low- and a high-variability conventional condition, in which conventional practice problems had to be solved (followed by worked examples), were compared with a low- and a high-variability worked condition, in which worked examples had to be studied. Results showed that students who studied worked examples gained most from high-variability examples, invested less time and mental effort in practice, and attained better and less effort-demanding transfer performance than students who first attempted to solve conventional problems and then studied work examples.},
	number = {1},
	urldate = {2022-03-17},
	journal = {Journal of Educational Psychology},
	author = {Paas, Fred G.W.C. and Van Merriënboer, Jeroen J.G.},
	year = {1994},
	pages = {122--133},
}

@article{SSL98,
	title = {Learner preferences and achievement under differing amounts of learner practice},
	volume = {46},
	issn = {10421629},
	url = {https://link.springer.com/article/10.1007/BF02299786},
	doi = {10.1007/bf02299786},
	abstract = {This study examined the effects of program mode (i.e., a lean program version containing a basic amount of learner practice vs. a full mode containing expanded practice) and learner preference (matched or unmatched) for amount of practice on the achievement, time-in-program, and attitudes of university undergraduate students. Subjects completed a 10-item Likert-type prequestionnaire to indicate the amount of practice they preferred, then were randomly assigned to either the type of program they preferred or to the opposite type. Subjects who used the full version of the instructional program scored significantly higher on the posttest than those who used the lean version. Matching subjects to their preferred amount of practice did not yield a significant achievement difference over assigning subjects to their less-preferred amount. Subjects preferred the lean version of the program over the full one, even though the full version produced better test performance.},
	number = {2},
	urldate = {2022-03-17},
	journal = {Educational Technology Research and Development},
	author = {Schnackenberg, Heidi L. and Sullivan, Howard J. and Leader, Lars F. and Jones, Elizabeth E.K.},
	year = {1998},
	note = {Publisher: Springer},
	keywords = {Educational Technology, Learning and Instruction},
	pages = {5--16},
}

@article{DMM19,
	title = {Measuring actual learning versus feeling of learning in response to being actively engaged in the classroom},
	volume = {116},
	issn = {10916490},
	url = {www.pnas.org/cgi/doi/10.1073/pnas.1821936116},
	doi = {10.1073/pnas.1821936116},
	abstract = {We compared students' self-reported perception of learning with their actual learning under controlled conditions in largeenrollment introductory college physics courses taught using 1) active instruction (following best practices in the discipline) and 2) passive instruction (lectures by experienced and highly rated instructors). Both groups received identical class content and handouts, students were randomly assigned, and the instructor made no effort to persuade students of the benefit of either method. Students in active classrooms learned more (as would be expected based on prior research), but their perception of learning, while positive, was lower than that of their peers in passive environments. This suggests that attempts to evaluate instruction based on students' perceptions of learning could inadvertently promote inferior (passive) pedagogical methods. For instance, a superstar lecturer could create such a positive feeling of learning that students would choose those lectures over active learning. Most importantly, these results suggest that when students experience the increased cognitive effort associated with active learning, they initially take that effort to signify poorer learning. That disconnect may have a detrimental effect on students' motivation, engagement, and ability to self-regulate their own learning. Although students can, on their own, discover the increased value of being actively engaged during a semester-long course, their learning may be impaired during the initial part of the course. We discuss strategies that instructors can use, early in the semester, to improve students' response to being actively engaged in the classroom.},
	number = {39},
	urldate = {2022-03-17},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Deslauriers, Louis and McCarty, Logan S. and Miller, Kelly and Callaghan, Kristina and Kestin, Greg},
	month = sep,
	year = {2019},
	pmid = {31484770},
	note = {Publisher: National Academy of Sciences},
	keywords = {Constructivism, Evidence-based teaching, Scientific teaching, Undergraduate education},
	pages = {19251--19257},
}

@article{CW14,
	title = {The {ICAP} {Framework}: {Linking} {Cognitive} {Engagement} to {Active} {Learning} {Outcomes}},
	volume = {49},
	issn = {00461520},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00461520.2014.965823},
	doi = {10.1080/00461520.2014.965823},
	abstract = {This article describes the ICAP framework that defines cognitive engagement activities on the basis of students’ overt behaviors and proposes that engagement behaviors can be categorized and differentiated into one of four modes: Interactive, Constructive, Active, and Passive. The ICAP hypothesis predicts that as students become more engaged with the learning materials, from passive to active to constructive to interactive, their learning will increase. We suggest possible knowledge-change processes that support the ICAP hypothesis and address the limitations and caveats of the hypothesis. In addition, empirical validation for the hypothesis is provided by examining laboratory and classroom studies that focus on three specific engagement activities: note taking, concept mapping and self-explaining. We also consider how ICAP can be used as a tool for explaining discrepant findings, dictate the proper choice of a control condition, and evaluate students’ outputs. Finally, we briefly compare ICAP to existing theories of learning.},
	number = {4},
	urldate = {2022-03-17},
	journal = {Educational Psychologist},
	author = {Chi, Michelene T.H. and Wylie, Ruth},
	month = oct,
	year = {2014},
	note = {Publisher: Routledge},
	pages = {219--243},
}

@techreport{PBB07,
	address = {Washington, DC},
	title = {Organizing {Instruction} and {Study} to {Improve} {Student} {Learning}},
	institution = {NCER, IES,, U.S. Department of Education},
	author = {Pashler, Harold and Bain, Patrice M and Bottge, Brian A and Graesser, Arthur and Koedinger, Kenneth and McDaniel, Mark and Metcalfe, Janet},
	year = {2007},
	note = {Publication Title: National Center for Education Research},
}

@article{chunkingModels,
	title = {Chunking models of expertise: implications for education},
	volume = {19},
	issn = {1099-0720},
	doi = {10.1002/ACP.1110},
	abstract = {Chunking models offer a parsimonious explanation of how people acquire knowledge and have been validated in domains such as expert behaviour and the acquisition of language. In this paper, we review two computational theories based on chunking mechanisms (the chunking theory and the template theory) and show what insight they offer for instruction and training. The suggested implications include the importance of perception in learning, the cost of acquiring knowledge, the significance of segmenting and ordering instruction material, the role of the variability of the instructional material in acquiring schemata, and the importance of taking individual differences into account. Copyright © 2005 John Wiley \& Sons, Ltd.},
	number = {2},
	urldate = {2022-03-16},
	journal = {Applied Cognitive Psychology},
	author = {Gobet, Fernand},
	month = mar,
	year = {2005},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {183--204},
}

@incollection{fusion,
	title = {Simultaneity and the enacted object of learning},
	volume = {9781410609},
	isbn = {0-8058-4009-5},
	urldate = {2022-03-11},
	booktitle = {Classroom {Discourse} and the {Space} of {Learning}},
	publisher = {Routledge},
	author = {Chik, Pakey P.M. and Lo, Mun Ling},
	month = apr,
	year = {2004},
	doi = {10.4324/9781410609762},
	pages = {89--112},
}

@article{25learning,
	title = {Learning principles to guide pedagogy and the design of learning environments},
	journal = {Association for Psychological Science},
	author = {Halpern, D F and Graesser, A and Hakel, M},
	year = {2007},
}

@incollection{perceptualLearningExpertise,
	title = {Perceptual {Learning}, {Cognition}, and {Expertise}},
	volume = {58},
	abstract = {Recent research indicates that perceptual learning (PL)-experience-induced changes in the way perceivers extract information-plays a larger role in complex cognitive tasks, including abstract and symbolic domains, than has been understood in theory or implemented in instruction. Here, we describe the involvement of PL in complex cognitive tasks and why these connections, along with contemporary experimental and neuroscientific research in perception, challenge widely held accounts of the relationships among perception, cognition, and learning. We outline three revisions to common assumptions about these relations: 1) Perceptual mechanisms provide complex and abstract descriptions of reality; 2) Perceptual representations are often. amodal, not limited to modality-specific sensory features; and 3) Perception is selective. These three properties enable relations between perception and cognition that are both synergistic and dynamic, and they make possible PL processes that adapt information extraction to optimize task performance. While PL is pervasive in natural learning and in expertise, it has largely been neglected in formal instruction. We describe an emerging PL technology that has already produced dramatic learning gains in a variety of academic and professional learning contexts, including mathematics, science, aviation, and medical learning. © 2013 Elsevier Inc.},
	urldate = {2022-03-16},
	booktitle = {Psychology of {Learning} and {Motivation} - {Advances} in {Research} and {Theory}},
	publisher = {Academic Press},
	author = {Kellman, Philip J. and Massey, Christine M.},
	month = jan,
	year = {2013},
	doi = {10.1016/B978-0-12-407237-4.00004-9},
	note = {ISSN: 00797421},
	keywords = {Abstract ideas, Amodal perception, Cognition, Expertise, Instruction, Learning, Perception, Perceptual learning, Perceptual learning modules},
	pages = {117--165},
}

@article{exteriorPoint,
	title = {A {Primal}-{Dual} {Exterior} {Point} {Method} for {Nonlinear} {Optimization}},
	volume = {20},
	issn = {10526234},
	url = {https://epubs.siam.org/doi/abs/10.1137/060676970},
	doi = {10.1137/060676970},
	abstract = {In this paper, primal-dual methods for general nonconvex nonlinear optimization problems are considered. The proposed methods are exterior point type methods that permit primal variables to violate...},
	number = {6},
	urldate = {2022-03-16},
	journal = {http://dx.doi.org/10.1137/060676970},
	author = {Hiroshi, Yamashita and Tanabe, Takahito},
	month = nov,
	year = {2010},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {49M37, 90C30, exterior point method, parametric programming, primal-dual method, warm start},
	pages = {3335--3363},
}

@book{convexOptimization,
	title = {Convex optimization},
	publisher = {Cambridge university press},
	author = {Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
	year = {2004},
}

@article{graphviz,
	title = {Graphviz— {Open} {Source} {Graph} {Drawing} {Tools}},
	volume = {2265 LNCS},
	issn = {16113349},
	doi = {10.1007/3-540-45848-4_57},
	urldate = {2022-03-16},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Ellson, John and Gansner, Emden and Koutsofios, Lefteris and North, Stephen C. and Woodhull, Gordon},
	year = {2001},
	note = {Publisher: Springer, Berlin, Heidelberg
ISBN: 3540433090},
	pages = {483--484},
}

@article{cognitiveDimensions,
	title = {Usability analysis of visual programming environments: {A} 'cognitive dimensions' framework},
	volume = {7},
	issn = {1045926X},
	doi = {10.1006/jvlc.1996.0009},
	abstract = {The cognitive dimensions framework is a broad-brush evaluation technique for interactive devices and for non-interactive notations. It sets out a small vocabulary of terms designed to capture the cognitively-relevant aspects of structure, and shows how they can be traded off against each other. The purpose of this paper is to propose the framework as an evaluation technique for visual programming environments. We apply it to two commercially-available dataflow languages (with further examples from other systems) and conclude that it is effective and insightful; other HCI-based evaluation techniques focus on different aspects and would make good complements. Insofar as the examples we used are representative, current VPLs are successful in achieving a good 'closeness of match', but designers need to consider the 'viscosity' (resistance to local change) and the 'secondary notation' (possibility of conveying extra meaning by choice of layout, colour, etc.). © 1996 Academic Press Limited.},
	number = {2},
	urldate = {2022-03-16},
	journal = {Journal of Visual Languages and Computing},
	author = {Green, T. R.G. and Petre, M.},
	month = jun,
	year = {1996},
	note = {Publisher: Academic Press},
	pages = {131--174},
}

@article{machineTeaching,
	title = {An {Interaction} {Design} for {Machine} {Teaching} to {Develop} {AI} {Tutors}},
	url = {http://dx.doi.org/10.1145/3313831.3376226},
	doi = {10.1145/3313831.3376226},
	abstract = {Intelligent tutoring systems (ITSs) have consistently been shown to improve the educational outcomes of students when used alone or combined with traditional instruction. However, building an ITS is a time-consuming process which requires specialized knowledge of existing tools. Extant authoring methods, including the Cognitive Tutor Authoring Tools' (CTAT) example-tracing method and SimStudent's Authoring by Tutoring, use programming-by-demonstration to allow authors to build ITSs more quickly than they could by hand programming with model-tracing. Yet these methods still suffer from long authoring times or difficulty creating complete models. In this study, we demonstrate that Simulated Learners built with the Apprentice Learner (AL) Framework can be combined with a novel interaction design that emphasizes model transparency, input flexibility, and problem solving control to enable authors to achieve greater model completeness in less time than existing authoring methods.},
	urldate = {2022-03-14},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Weitekamp, Daniel and Harpstead, Erik and Koedinger, Ken R.},
	month = apr,
	year = {2020},
	note = {Publisher: Association for Computing Machinery
ISBN: 9781450367080},
}

@article{naturalProgramming,
	title = {Natural programming languages and environments},
	volume = {47},
	number = {9},
	journal = {Communications of the ACM},
	author = {Myers, Brad A and Pane, John F and Ko, Amy},
	year = {2004},
	note = {Publisher: ACM},
	pages = {47--52},
}

@article{naturalDiagramming,
	title = {How {Domain} {Experts} {Create} {Conceptual} {Diagrams} and {Implications} for {Tool} {Design}},
	volume = {20},
	doi = {10.1145/3313831.3376253},
	abstract = {Conceptual diagrams are used extensively to understand abstract relationships, explain complex ideas, and solve difficult problems. To illustrate concepts effectively, experts find appropriate visual representations and translate concepts into concrete shapes. This translation step is not supported explicitly by current diagramming tools. This paper investigates how domain experts create conceptual diagrams via semi-structured interviews with 18 participants from diverse backgrounds. Our participants create, adapt, and reuse visual representations using both sketches and digital tools. However, they had trouble using current diagramming tools to transition from sketches and reuse components from earlier diagrams. Our participants also expressed frustration with the slow feedback cycles and barriers to automation of their tools. Based on these results, we suggest four opportunities of diagramming tools A- exploration support, representation salience, live engagement, and vocabulary correspondence A- that together enable a natural diagramming experience. Finally, we discuss possibilities to leverage recent research advances to develop natural diagramming tools.},
	urldate = {2022-03-16},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Ma'ayan, Dor and Ni, Wode and Ye, Katherine and Kulkarni, Chinmay and Sunshine, Joshua},
	month = apr,
	year = {2020},
	note = {Publisher: Association for Computing Machinery
ISBN: 9781450367080},
	keywords = {conceptual diagramming, diagram authoring, information visualization},
}

@article{dualCoding,
	title = {Dual coding theory and education},
	volume = {3},
	issn = {1573-336X},
	doi = {10.1007/BF01320076},
	abstract = {Dual coding theory (DCT) explains human behavior and experience in terms of dynamic associative processes that operate on a rich network of modality-specific verbal and nonverbal (or imagery) representations. We first describe the underlying premises of the theory and then show how the basic DCT mechanisms can be used to model diverse educational phenomena. The research demonstrates that concreteness, imagery, and verbal associative processes play major roles in various educational domains: the representation and comprehension of knowledge, learning and memory of school material, effective instruction, individual differences, achievement motivation and test anxiety, and the learning of motor skills. DCT also has important implications for the science and practice of educational psychology — specifically, for educational research and teacher education. We show not only that DCT provides a unified explanation for diverse topics in education, but also that its mechanistic framework accommodates theories cast in terms of strategies and other high-level psychological processes. Although much additional research needs to be done, the concrete models that DCT offers for the behavior and experience of students, teachers, and educational psychologists further our understanding of educational phenomena and strengthen related pedagogical practices.},
	number = {3},
	urldate = {2022-03-16},
	journal = {Educational Psychology Review 1991 3:3},
	author = {Clark, James M. and Paivio, Allan},
	month = sep,
	year = {1991},
	note = {Publisher: Springer},
	keywords = {Child and School Psychology, Educational Psychology, Learning and Instruction},
	pages = {149--210},
}

@article{groundedAndAbstractReps,
	title = {Trade-{Offs} {Between} {Grounded} and {Abstract} {Representations}: {Evidence} {From} {Algebra} {Problem} {Solving}},
	volume = {32},
	issn = {1551-6709},
	doi = {10.1080/03640210701863933},
	abstract = {This article explores the complementary strengths and weaknesses of grounded and abstract representations in the domain of early algebra. Abstract representations, such as algebraic symbols, are concise and easy to manipulate but are distanced from any physical referents. Grounded representations, such as verbal descriptions of situations, are more concrete and familiar, and they are more similar to physical objects and everyday experience. The complementary computational characteristics of grounded and abstract representations lead to trade-offs in problem-solving performance. In prior research with high school students solving relatively simple problems, Koedinger and Nathan (2004) demonstrated performance benefits of grounded representations over abstract representations - students were better at solving simple story problems than the analogous equations. This article extends this prior work to examine both simple and more complex problems in two samples of college students. On complex problems with two references to the unknown, a "symbolic advantage" emerged, such that students were better at solving equations than analogous story problems. Furthermore, the previously observed "verbal advantage" on simple problems was replicated. We thus provide empirical support for a trade-off between grounded, verbal representations, which show advantages on simpler problems, and abstract, symbolic representations, which show advantages on more complex problems.},
	number = {2},
	urldate = {2022-03-16},
	journal = {Cognitive Science},
	author = {Koedinger, Kenneth R. and Alibali, Martha W. and Nathan, Mitchell J.},
	month = mar,
	year = {2008},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Abstraction, Algebra, External representation, Grounding, Problem solving},
	pages = {366--397},
}

@incollection{deliberatePractice,
	address = {New York, NY, US},
	title = {The {Influence} of {Experience} and {Deliberate} {Practice} on the {Development} of {Superior} {Expert} {Performance}.},
	isbn = {0-521-60081-2 (Paperback); 0-521-84097-X (Hardcover); 978-0-521-60081-1 (Paperback); 978-0-521-84097-2 (Hardcover)},
	abstract = {In this chapter the author will review evidence on the effects of experience and deliberate practice on individual differences in the acquisition of skilled and expert performance. The author will first describe the traditional account of individual differences in performance based on experience and innate talent. Then the author will review evidence on the effects of various types of experience on performance, especially the effects of deliberate practice. In the last half of the chapter, the author will discuss how deliberate practice can account for the changes in the structure of the mechanisms that mediate the superior performance of experts. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	booktitle = {The {Cambridge} handbook of expertise and expert performance.},
	publisher = {Cambridge University Press},
	author = {Ericsson, K Anders},
	year = {2006},
	doi = {10.1017/CBO9780511816796.038},
	keywords = {*Experience Level, *Individual Differences, *Knowledge Level, *Performance, Skill Learning},
	pages = {683--703},
}

@book{multimediaLearning,
	title = {Multimedia {Learning}},
	isbn = {978-1-316-94135-5},
	abstract = {Advances in computer graphic technologies have inspired new efforts to understand the potential of multimedia instruction as a means of promoting human learning. In Multimedia Learning, Third Edition, Richard E. Mayer takes an evidence-based approach to improving education using well-designed multimedia instruction. He reviews 15 principles of multimedia instructional design that are based on more than 200 experimental research studies and grounded in a cognitive theory of how people learn from words and graphics. The result is the latest instalment of what Mayer calls the Cognitive Theory of Multimedia Learning, a theory introduced in previous editions of Multimedia Learning and in The Cambridge Handbook of Multimedia Learning, Second Edition. This edition provides an up-to-date and systematic summary of research studies on multimedia learning, supplemented with complementary evidence from around the globe. It is well-suited to graduate and undergraduate courses in psychology, education, computer science, communication, instructional design, and game design.},
	urldate = {2022-03-16},
	publisher = {Cambridge University Press},
	author = {Mayer, Richard},
	month = jul,
	year = {2020},
	doi = {10.1017/9781316941355},
}

@article{pictureAlgebra,
	title = {A {Cognitive} {Task} {Analysis} of {Using} {Pictures} {To} {Support} {Pre}-{Algebraic} {Reasoning}},
	doi = {10.4324/9781315782379-129},
	abstract = {We present an analysis of hypothesized advantages of pictorial representations for improving learning and understanding of pre-algebraic quantitative reasoning. We discuss a “Picture Algebra” strategy that has been used successfully by 6th grade students as part of a new middle school mathematics curriculum. This strategy supports students in sense making both as they construct pictorial representations and as they use them to cue appropriate computations. Although we demonstrate that 6th grade students can use this strategy to successfully solve algebra-level problems, our detailed production rule analysis revealed limitations in our instructional approach and targeted areas for improvement.},
	urldate = {2022-03-16},
	journal = {Proceedings of the Twenty-Fourth Annual Conference of the Cognitive Science Society},
	author = {Koedinger, Kenneth R. and Terao, Atsushi},
	month = apr,
	year = {2019},
	note = {Publisher: Routledge
ISBN: 9781315782379},
	pages = {542--547},
}

@article{DiagramsThousandWords,
	title = {Why a {Diagram} is ({Sometimes}) {Worth} {Ten} {Thousand} {Words}},
	volume = {11},
	issn = {0364-0213},
	doi = {10.1016/S0364-0213(87)80026-5},
	abstract = {We distinguish diagrammatic from sentential paper-and-pencil representations of information by developing alternative models of information-processing systems that are informationally equivalent and that can be characterized as sentential or diagrammatic. Sentential representations are sequential, like the propositions in a text. Diagrammatic representations are indexed by location in a plane. Diagrammatic representations also typically display information that is only implicit in sentential representations and that therefore has to be computed, sometimes at great cost, to make it explicit for use. We then contrast the computational efficiency of these representations for solving several illustrative problems in mathematics and physics. When two representations are informationally equivalent, their computational efficiency depends on the information-processing operators that act on them. Two sets of operators may differ in their capabilities for recognizing patterns, in the inferences they can carry out directly, and in their control strategies (in particular, the control of search). Diagrammatic and sentential representations support operators that differ in all of these respects. Operators working on one representation may recognize features readily or make inferences directly that are difficult to realize in the other representation. Most important, however, are differences in the efficiency of search for information and in the explicitness of information. In the representations we call diagrammatic, information is organized by location, and often much of the information needed to make an inference is present and explicit at a single location. In addition, cues to the next logical step in the problem may be present at an adjacent location. Therefore problem solving can proceed through a smooth traversal of the diagram, and may require very little search or computation of elements that had been implicit. © 1987.},
	number = {1},
	urldate = {2022-03-16},
	journal = {Cognitive Science},
	author = {Larkin, Jill H. and Simon, Herbert A.},
	month = jan,
	year = {1987},
	note = {Publisher: No longer published by Elsevier},
	pages = {65--100},
}

@article{cotraining,
	title = {Combining labeled and unlabeled data with co-training},
	doi = {10.1145/279943.279962},
	abstract = {The problem of using a large unlabeled sample is considered to boost the performance of a learning algorithm when only a small set of labeled examples is available. In particular, a problem setting is considered to classify web pages, in which the description of each example can be partitioned into two distinct views. A PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data are presented. Also, empirical results on real web-page is giving, indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice.},
	urldate = {2022-03-16},
	journal = {Proceedings of the Annual ACM Conference on Computational Learning Theory},
	author = {Blum, Avrim and Mitchell, Tom},
	year = {1998},
	note = {Publisher: ACM},
	pages = {92--100},
}

@article{thinglab,
	title = {Thinglab--{A} {Constraint}-{Oriented} {Simulation} {Laboratory}},
	journal = {Stanford Univ. report STANCS-79-746},
	author = {Boming, Alan},
	year = {1979},
}

@article{animationConstraints,
	title = {Easily adding animations to interfaces using constraints},
	doi = {10.1145/237091.237109},
	abstract = {Adding animation to interfaces is a very difficult task with today's toolkits, even though there are many situations in which it would be useful and effective. The Amulet toolkit contains a new form of animation constraint that allows animations to be added to interfaces extremely easily without changing the logic of the application or the graphical objects themselves. An animation constraint detects changes to the value of the slot to which it is attached, and causes the slot to instead take on a series of values interpolated between the original and new values. The advantage over previous approaches is that animation constraints provide significantly better modularity and reuse. The programmer has independent control over the graphics to be animated, the start and end values of the animation, the path through value space, and the timing of the animation. Animations can be attached to any object, even existing widgets from the toolkit, and any type of value can be animated: scalars, coordinates, fonts, colors, line widths, point lists (for polygons), booleans (for visibility), etc. A library of useful animation constraints is provided in the toolkit, including support for exaggerated, cartoon-style effects such as slow-in-slow-out, anticipation, and follow-through. Because animations can be added to an existing application with only a single extra line of code, we expect that this new mechanism will make it easy for researchers and developers to investigate the use of animations in a wide variety of applications.},
	urldate = {2022-03-16},
	journal = {UIST (User Interface Software and Technology): Proceedings of the ACM Symposium},
	author = {Myers, Brad A. and Miller, Robert C. and McDaniel, Rich and Ferrency, Alan},
	year = {1996},
	note = {Publisher: ACM},
	pages = {119--128},
}

@book{Hadamard1997a,
	title = {The {Mathematician}'s {Mind}},
	abstract = {Fifty years ago when Jacques Hadamard set out to explore how mathematicians invent new ideas, he considered the creative experiences of some of the greatest thinkers of his generation, such as George Polya, Claude Lévi-Strauss, and Albert Einstein. It appeared that inspiration could strike anytime, particularly after an individual had worked hard on a problem for days and then turned attention to another activity. In exploring this phenomenon, Hadamard produced one of the most famous and cogent cases for the existence of unconscious mental processes in mathematical invention and other forms of creativity. Written before the explosion of research in computers and cognitive science, his book, originally titled The Psychology of Invention in the Mathematical Field, remains an important tool for exploring the increasingly complex problem of mental life. The roots of creativity for Hadamard lie not in consciousness, but in the long unconscious work of incubation, and in the unconscious aesthetic selection of ideas that thereby pass into consciousness. His discussion of this process comprises a wide range of topics, including the use of mental images or symbols, visualized or auditory words, "meaningless" words, logic, and intuition. Among the important documents collected is a letter from Albert Einstein analyzing his own mechanism of thought.},
	urldate = {2022-03-05},
	publisher = {Princeton University Press},
	author = {Hadamard, Jacques},
	month = dec,
	year = {1997},
	doi = {10.1515/9780691212906/HTML},
	note = {Publication Title: The Mathematician's Mind},
}

@article{garnet,
	title = {Garnet: {Comprehensive} {Support} for {Graphical}, {Highly} {Interactive} {User} {Interfaces}},
	volume = {23},
	issn = {00189162},
	doi = {10.1109/2.60882},
	number = {11},
	urldate = {2022-03-16},
	journal = {Computer},
	author = {Myers, Brad A. and Giuse, Dario A. and Dannenberg, Roger B. and Vander Zanden, Brad and Kosbie, David S. and Pervin, Edward and Mickish, Andrew and Marchal, Philippe},
	year = {1990},
	pages = {71--85},
}

@article{myers_garnet_1995,
	title = {Garnet {Comprehensive} {Support} for {Graphical}, {Highly} {Interactive} {User} {Interfaces}},
	doi = {10.1016/B978-0-08-051574-8.50037-6},
	urldate = {2022-03-16},
	journal = {Readings in Human–Computer Interaction},
	author = {Myers, Brad A. and Giuse, Dario A. and Dannenberg, Roger B. and Zanden, Brad Vander and Kosbie, David S. and Pervin, Edward and Mickish, Andrew and Marchal, Philippe},
	month = jan,
	year = {1995},
	note = {Publisher: Morgan Kaufmann},
	pages = {357--371},
}

@article{Boy2016,
	title = {Suggested {Interactivity}: {Seeking} {Perceived} {Affordances} for {Information} {Visualization}},
	volume = {22},
	issn = {10772626},
	doi = {10.1109/TVCG.2015.2467201},
	abstract = {In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances - SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.},
	number = {1},
	urldate = {2022-02-02},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Boy, Jeremy and Eveillard, Louis and Detienne, Françoise and Fekete, Jean Daniel},
	month = jan,
	year = {2016},
	note = {Publisher: IEEE Computer Society},
	keywords = {Brushes, Electronic publishing, Encyclopedias, Internet, Silicon, Visualization},
	pages = {639--648},
}

@article{Myers1998,
	title = {Scripting graphical applications by demonstration},
	volume = {98},
	url = {http://www.cs.cmu.edu/-barn},
	doi = {10.1145/274644.274716},
	abstract = {Writing scripts (often called `macros') can be helpful for automating repetitive tasks. Scripting facilities for text editors like Emacs and Microsoft Word have been widely used and available. However, for graphical applications, scripting has been tried many times but has never been successful. This is mainly due to the data description problem of determining how to generalize the particular objects selected at demonstration time. Previous systems have mostly tried to solve this using inferencing, but this has a number of problems, including guessing wrong and providing appropriate feedback and control to users. Therefore, the Topaz framework does not use inferencing and instead allows the user to specify how the appropriate objects should be found. This is achieved by recording changes to which objects are selected and searches for objects, so that scripts can be written with respect to the selected object, in the same way as Emacs keyboard macros. Furthermore, all values can be explicitly generalized in a number of ways, and scripts can be invoked as a result of other commands. By leveraging off of Amulet's command object architecture, programmers get these capabilities for free in their applications. The result is that much more sophisticated scripting capabilities available in applications with no extra work for programmers.},
	urldate = {2022-02-02},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Myers, Brad A.},
	year = {1998},
	note = {Publisher: ACM},
	keywords = {Amulet, Command Objects, Macros, Programming by Demon-stration (PBD), Scripting, Selection, Toolkits, User Interface Development Environments},
	pages = {534--541},
}

@article{Mesbah2012,
	title = {Automated analysis of {CSS} rules to support style maintenance},
	issn = {02705257},
	doi = {10.1109/ICSE.2012.6227174},
	abstract = {CSS is a widely used language for describing the presentation semantics of HTML elements on the web. The language has a number of characteristics, such as inheritance and cascading order, which makes maintaining CSS code a challenging task for web developers. As a result, it is common for unused rules to be accumulated over time. Despite these challenges, CSS analysis has not received much attention from the research community. We propose an automated technique to support styling code maintenance, which (1) analyzes the runtime relationship between the CSS rules and DOM elements of a given web application (2) detects unmatched and ineffective selectors, overridden declaration properties, and undefined class values. Our technique, implemented in an open source tool called Cilla, has a high precision and recall rate. The results of our case study, conducted on fifteen open source and industrial web-based systems, show an average of 60\% unused CSS selectors in deployed applications, which points to the ubiquity of the problem. © 2012 IEEE.},
	urldate = {2021-12-02},
	journal = {Proceedings - International Conference on Software Engineering},
	author = {Mesbah, Ali and Mirshokraie, Shabnam},
	year = {2012},
	note = {ISBN: 9781467310673},
	keywords = {CSS, Cascading style sheets, dynamic analysis, software maintenance, web applications},
	pages = {408--418},
}

@article{Chugh2016,
	title = {Programmatic and direct manipulation, together at last},
	volume = {13-17-June},
	doi = {10.1145/2908080.2908103},
	abstract = {Direct manipulation interfaces and programmatic systems have distinct and complementary strengths. The former provide intuitive, immediate visual feedback and enable rapid prototyping, whereas the latter enable complex, reusable abstractions. Unfortunately, existing systems typically force users into just one of these two interaction modes. We present a system called SKETCH-N-SKETCH that integrates programmatic and direct manipulation for the particular domain of Scalable Vector Graphics (SVG). In SKETCH-N-SKETCH, the user writes a program to generate an output SVG canvas. Then the user may directly manipulate the canvas while the system immediately infers a program update in order to match the changes to the output, a workflow we call live synchronization. To achieve this, we propose (i) a technique called trace-based program synthesis that takes program execution history into account in order to constrain the search space and (ii) heuristics for dealing with ambiguities. Based on our experience with examples spanning 2,000 lines of code and from the results of a preliminary user study, we believe that SKETCH-N-SKETCH provides a novel workflow that can augment traditional programming systems. Our approach may serve as the basis for live synchronization in other application domains, as well as a starting point for yet more ambitious ways of combining programmatic and direct manipulation.},
	urldate = {2021-10-06},
	journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
	author = {Chugh, Ravi and Hempel, Brian and Spradlin, Mitchell and Albers, Jacob},
	month = jun,
	year = {2016},
	note = {Publisher: Association for Computing Machinery},
	keywords = {Prodirect manipulation, SVG, Sketch-n-sketch},
	pages = {341--354},
}

@inproceedings{Falleri2014,
	title = {Fine-grained and accurate source code differencing},
	isbn = {978-1-4503-3013-8},
	doi = {10.1145/2642937.2642982},
	abstract = {At the heart of software evolution is a sequence of edit actions, called an edit script, made to a source code file. Since software systems are stored version by version, the edit script has to be computed from these versions, which is known as a complex task. Existing approaches usually compute edit scripts at the text granularity with only add line and delete line actions. However, inferring syntactic changes from such an edit script is hard. Since moving code is a frequent action performed when editing code, it should also be taken into account. In this paper, we tackle these issues by introducing an algorithm computing edit scripts at the abstract syntax tree granularity including move actions. Our objective is to compute edit scripts that are short and close to the original developer intent. Our algorithm is implemented in a freely-available and extensible tool that has been intensively validated.},
	urldate = {2021-06-23},
	booktitle = {{ASE} 2014 - {Proceedings} of the 29th {ACM}/{IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Falleri, Jean Rémy and Morandat, Floréal and Blanc, Xavier and Martinez, Matias and Monperrus, Martin},
	year = {2014},
	keywords = {AST, Program comprehension, Software evolution, Tree differencing},
	pages = {313--323},
}

@article{usabilityInteractionTools,
	title = {Usability requirements for interaction-oriented development tools},
	journal = {Psychology of Programming},
	author = {Letondal, Catherine and Chatty, Stéphane and Phillips, W Greg and André, Fabien and Conversy, Stéphane},
	year = {2010},
	note = {Publisher: Citeseer},
	pages = {12--26},
}

@article{Pike2009,
	title = {The {Science} of {Interaction}:},
	volume = {8},
	issn = {14738716},
	url = {https://journals.sagepub.com/doi/abs/10.1057/ivs.2009.22},
	doi = {10.1057/IVS.2009.22},
	abstract = {There is a growing recognition within the visual analytics community that interaction and inquiry are inextricable. It is through the interactive manipulation of a visual interface–the analytic dis...},
	number = {4},
	urldate = {2022-02-15},
	journal = {http://dx.doi.org/10.1057/ivs.2009.22},
	author = {Pike, William A. and Stasko, John and Chang, Remco and O'Connell, Theresa A.},
	month = jan,
	year = {2009},
	note = {Publisher: SAGE PublicationsSage UK: London, England},
	keywords = {collaboration, interaction theory, reasoning, visual analytics},
	pages = {263--274},
}

@article{Catley2008a,
	title = {Seeing the {Wood} for the {Trees}: {An} {Analysis} of {Evolutionary} {Diagrams} in {Biology} {Textbooks}},
	volume = {58},
	issn = {0006-3568},
	url = {https://academic.oup.com/bioscience/article/58/10/976/245951},
	doi = {10.1641/B581011},
	abstract = {This study presents the findings of an analysis of evolutionary diagrams found in 31 biology textbooks for students ranging from middle school to the undergraduate level. Since the early 1990s, cladograms have found their way into high school biology textbooks, yet we know little about their effectiveness as interpretive and instructional tools in biology education. In this article we document the frequency and types of cladograms found in 31 textbooks, and classify and survey the other types of evolutionary diagrams used in the texts. Although cladograms comprised approximately 72 percent of the diagrams overall, we found virtually no attempt to explain their structure and theoretical underpinnings. Various other noncladogenic evolutionary diagrams, comprising 28 percent of the total, were distributed throughout all textbooks studied. On the basis of our analysis, we conclude that many of these evolutionary diagrams are confusing and may reinforce alternative conceptions of macroevolution. Biology educators should therefore recognize these problems and take measures to ameliorate their effects. © 2008 American Institute of Biological Sciences.},
	number = {10},
	urldate = {2022-02-10},
	journal = {BioScience},
	author = {Catley, Kefyn M. and Novick, Laura R.},
	month = nov,
	year = {2008},
	note = {Publisher: Oxford Academic},
	keywords = {Alternative conceptions, Biology textbooks, Cladograms, Evolutionary diagrams, Macroevolution},
	pages = {976--987},
}

@article{Rittle-Johnson2001,
	title = {Developing conceptual understanding and procedural skill in mathematics: {An} iterative process},
	volume = {93},
	issn = {00220663},
	url = {/record/2001-06601-010?doi=1},
	doi = {10.1037/0022-0663.93.2.346},
	abstract = {The authors propose that conceptual and procedural knowledge develop in an iterative fashion and that improved problem representation is 1 mechanism underlying the relations between them. Two experiments were conducted with 5th- and 6th-grade students learning about decimal fractions. In Experiment 1, children's initial conceptual knowledge predicted gains in procedural knowledge, and gains in procedural knowledge predicted improvements in conceptual knowledge. Correct problem representations mediated the relation between initial conceptual knowledge and improved procedural knowledge. In Experiment 2, amount of support for correct problem representation was experimentally manipulated, and the manipulations led to gains in procedural knowledge. Thus, conceptual and procedural knowledge develop iteratively, and improved problem representation is 1 mechanism in this process.},
	number = {2},
	urldate = {2022-02-10},
	journal = {Journal of Educational Psychology},
	author = {Rittle-Johnson, Bethany and Siegler, Robert S. and Alibali, Martha Wagner},
	year = {2001},
	note = {Publisher: American Psychological Association Inc.},
	pages = {346--362},
}

@article{Alper2017a,
	title = {Visualization literacy at elementary school},
	volume = {2017-May},
	url = {http://dx.doi.org/10.1145/3025453.3025877},
	doi = {10.1145/3025453.3025877},
	abstract = {This work advances our understanding of children's visualization literacy, and aims to improve it with a novel approach for teaching visualization at elementary schools. We first contribute an analysis of data graphics and activities employed in grade K to 4 educational materials, and the results of a survey conducted with 16 elementary school teachers. We find that visualization education could benefit from integrating pedagogical strategies for teaching abstract concepts with established interactive visualization techniques. Building on these insights, we develop and study design principles for novel interactive teaching material aimed at increasing chil-drens visualization literacy. We specifically contribute lest la Vis, an online platform for teachers and students to respectively teach and learn about pictographs and bar charts, and report on our initial observations of its use in grades K and 2. Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	urldate = {2022-02-02},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Alper, Basak and Riche, Nathalie Henry and Chevalier, Fanny and Boy, Jeremy and Sezgin, Metin},
	month = may,
	year = {2017},
	note = {Publisher: Association for Computing Machinery
ISBN: 9781450346559},
	keywords = {Qualitative analysis, Visualization literacy},
	pages = {5485--5497},
}

@article{Liu2010a,
	title = {Mental models, visual reasoning and interaction in information visualization: {A} top-down perspective},
	volume = {16},
	issn = {10772626},
	doi = {10.1109/TVCG.2010.177},
	abstract = {Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development. © 2006 IEEE.},
	number = {6},
	urldate = {2022-02-02},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Zhicheng and Stasko, John},
	year = {2010},
	pmid = {20975137},
	keywords = {Mental model, distributed cognition, information visualization, interaction, model-based reasoning, theory},
	pages = {999--1008},
}

@article{Beaudouin-Lafon2021,
	title = {{MathMap}: {Supporting} {Exploratory} {Problem} {Solving} with {Algebra}},
	url = {https://doi.org/10.1145/3474349.3480226},
	doi = {10.1145/3474349.3480226},
	abstract = {Tools that support problem-solving in mathematics tend to focus on reaching a solution directly. In practice, it is common to go down paths that do not obviously lead to the solution. This part of the process should be reflected in the tools students use to help them better learn problem-solving strategies. MathMap is an application designed to help high-school students learn how to solve algebraic problems by encouraging them to use multiple strategies, maintain the history of previous attempts, and allows them to meaningfully compare methods with other students.},
	urldate = {2022-02-02},
	journal = {Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology, UIST 2021},
	author = {Beaudouin-Lafon, Matthew and Xia, Haijun},
	month = oct,
	year = {2021},
	note = {Publisher: Association for Computing Machinery, Inc
ISBN: 9781450386555},
	keywords = {Computer Algebra Systems, Exploration, Math},
	pages = {47--50},
}

@article{Yi2007a,
	title = {Toward a deeper understanding of the role of interaction in information visualization},
	volume = {13},
	issn = {10772626},
	doi = {10.1109/TVCG.2007.70515},
	abstract = {Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction. © 2007 IEEE.},
	number = {6},
	urldate = {2022-01-26},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yi, Ji Soo and Kang, Youn Ah and Stasko, John T. and Jacko, Julie A.},
	month = nov,
	year = {2007},
	keywords = {Information visualization, Interaction, Interaction techniques, Taxonomy, Visual analytics},
	pages = {1224--1231},
}

@article{Wang2019,
	title = {Upgrade: {Sourcing} student open-ended solutions to create scalable learning opportunities},
	url = {https://doi.org/10.1145/3330430.3333614},
	doi = {10.1145/3330430.3333614},
	abstract = {In schools and colleges around the world, open-ended homework assignments are commonly used. However, such assignments require substantial instructor effort for grading, and tend not to support opportunities for repeated practice. We propose UpGrade, a novel learnersourcing approach that generates scalable learning opportunities using prior student solutions to open-ended problems. UpGrade creates interactive questions that offer automated and real-time feedback, while enabling repeated practice. In a two-week experiment in a college-level HCI course, students answering UpGrade-created questions instead of traditional open-ended assignments achieved indistinguishable learning outcomes in {\textasciitilde}30\% less time. Further, no manual grading effort is required. To enhance quality control, UpGrade incorporates a psychometric approach using crowd workers’ answers to automatically prune out low quality questions, resulting in a question bank that exceeds reliability standards for classroom use.},
	urldate = {2021-12-06},
	journal = {Proceedings of the 6th 2019 ACM Conference on Learning at Scale, L@S 2019},
	author = {Wang, Xu and Talluri, Srinivasa Teja and Rose, Carolyn and Koedinger, Kenneth},
	month = jun,
	year = {2019},
	note = {Publisher: Association for Computing Machinery, Inc
ISBN: 9781450368049},
	keywords = {Crowdsourcing, Deliberate practice, Multiple-choice question, Online education, Open-ended assignment},
}

@article{Pane1996a,
	title = {Assessing dynamics in computer-based instruction},
	doi = {10.1145/238386.238482},
	abstract = {We present an evaluation of a multimedia educational software system that includes text, graphics, animations, and simulations. When compared with an informationally equivalent control environment that used text and carefully selected still images, we found little evidence that the dynamic presentations enhanced student understanding of the declarative information in this lesson. Furthermore, students cannot be relied on to take full advantage of exploratory opportunities in computer-based instruction. These results prescribe further investigation of whether and how computer-based multimedia can be used effectively in education and training.},
	urldate = {2022-01-26},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Pane, John F. and Corbett, Albert T. and John, Bonnie E.},
	year = {1996},
	note = {Publisher: ACM},
	keywords = {animation, computer-based leaming, multimedia, simulation},
	pages = {197--204},
}

@article{Gleicher,
	title = {Differential {Manipulation}},
	abstract = {Direct manipulation has proven to be an excellent method for interacting with geometric objects. Unfortunately , traditional approaches for implementing direct manipulation suffer from a lack of generality, requiring the system designer to hand craft interfaces to different types of objects. In this paper we present differential manipulation, a new paradigm for direct manipulation of geometric objects. By interpreting graphical entities as physical objects, we obtain a uniform interface to a wide variety of geometric objects, making it simple to add new types of complicated or compound objects. Geometric constraints fit neatly into the paradigm. Résumé La manipulation directe est une excellente méthode pour le traitement interactif des objets géométriques. Malheureusement, les approches traditionelles pour l'implémentation de la manipulation directe manquent de généralité en nécessitant que différentes interfaces soient associéesassociées`associéesà différents types d'objets. Dans cet article nous présentons un nouveau paradigme, la manipulation différentielle, pour la manipulation directe des ob-jets géométriques. En interprétant les entités graphiques comme des objets physiques, nous obtenons une seule interface pouvantêtrepouvantˆpouvantêtre utilisée pour une grande variété d'objets géométriques, facilitant ainsi l'addition de nou-veaux types d'objets complexes ou composés. Les con-traintes géométriques peuventêtrepeuventˆpeuventêtre proprement incluses avec ce paradigme.},
	urldate = {2021-12-01},
	author = {Gleicher, Michael and Witkin, Andrew},
	keywords = {Direct Manipulation, Geometric Modeling, Interaction Tech-niques},
}

@article{AnShengwei2019,
	title = {Augmented example-based synthesis using relational perturbation properties},
	volume = {4},
	url = {https://dl.acm.org/doi/abs/10.1145/3371124},
	doi = {10.1145/3371124},
	abstract = {Example-based specifications for program synthesis are inherently ambiguous and may cause synthesizers to generate programs that do not exhibit intended behavior on unseen inputs. Existing synthesi...},
	number = {POPL},
	urldate = {2021-10-15},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {{AnShengwei} and {SinghRishabh} and {MisailovicSasa} and {SamantaRoopsha}},
	month = dec,
	year = {2019},
	note = {Publisher: 
		ACM
		PUB27
		New York, NY, USA
	},
	keywords = {Ambiguity-resolution, Example-based Synthesis, Program Synthesis},
}

@article{LubinJustin2020,
	title = {Program sketching with live bidirectional evaluation},
	volume = {4},
	url = {https://dl.acm.org/doi/abs/10.1145/3408991},
	doi = {10.1145/3408991},
	abstract = {We present a system called Smyth for program sketching in a typed functional language whereby the concrete evaluation of ordinary assertions gives rise to input-output examples, which are then used...},
	number = {ICFP},
	urldate = {2021-10-07},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {{LubinJustin} and {CollinsNick} and {OmarCyrus} and {ChughRavi}},
	month = aug,
	year = {2020},
	note = {Publisher: 
		ACM
		PUB27
		New York, NY, USA
	},
	keywords = {Bidirectional Evaluation, Examples, Program Synthesis, Sketches},
	pages = {29},
}

@article{Gleicher1994,
	title = {Drawing with constraints},
	volume = {11},
	issn = {1432-2315},
	url = {https://link.springer.com/article/10.1007/BF01900698},
	doi = {10.1007/BF01900698},
	abstract = {The success of constraint-based approaches to drawing has been limited by difficulty in creating constraints, solving them, and presenting them to users. In this paper, we discuss techniques used in theBriar drawing program to address all of these issues. Briar's approach separates the problem of initially establishing constraints from the problem of maintaining them during subsequent editing. We describe how non-constraint-based drawing tools can be augmented to specify constraints in addition to positions. These constraints are then maintained as the user drags the model, which allows the user to explore configurations consistent with the constraints. Visual methods are provided for displaying and editing the constraints.},
	number = {1},
	urldate = {2021-12-01},
	journal = {The Visual Computer 1994 11:1},
	author = {Gleicher, Michael and Witkin, Andrew},
	month = jan,
	year = {1994},
	note = {Publisher: Springer},
	keywords = {Artificial Intelligence, Computer Graphics, Computer Science, Image Processing and Computer Vision, general},
	pages = {39--51},
}

@article{Chugh2016a,
	title = {Prodirect manipulation: {Bidirectional} programming for the masses},
	url = {http://dx.doi.org/10.1145/2889160.2889210},
	doi = {10.1145/2889160.2889210},
	abstract = {Software interfaces today generally fall at either end of a spectrum. On one end are programmable systems, which allow expert users (i.e. programmers) to write software artifacts that describe complex abstractions, but programs are disconnected from their eventual output. On the other end are domain-specific graphical user interfaces (GUIs), which allow end users (i.e. non-programmers) to easily create varied content but present insurmountable walls when a desired feature is not built-in. Both programmatic and direct manipulation have distinct strengths, but users must typically choose one over the other or use some ad-hoc combination of systems. Our goal, put simply, is to bridge this divide. We envision novel software systems that tightly couple programmatic and direct manipulation - - a combination we dub prodirect manipulation - - for a variety of use cases. This will require advances in a broad range of software engineering disciplines, from program analysis and program synthesis technology to user interface design and evaluation. In this extended abstract, we propose two general strategies - - real-time program synthesis and domain-specific synthesis of general-purpose programs - - that may prove fruitful for overcoming the technical challenges. We also discuss metrics that will be important in evaluating the usability and utility of prodirect manipulation systems.},
	urldate = {2021-10-07},
	journal = {Proceedings - International Conference on Software Engineering},
	author = {Chugh, Ravi},
	month = may,
	year = {2016},
	note = {Publisher: IEEE Computer Society},
	keywords = {Bidirectional programming, End user programming, Human-computer interaction, Prodirect manipulation, Program synthesis},
	pages = {781--784},
}

@article{Hempel2016,
	title = {Semi-automated {SVG} programming via direct manipulation},
	doi = {10.1145/2984511.2984575},
	abstract = {Direct manipulation interfaces provide intuitive and interactive features to a broad range of users, but they often exhibit two limitations: the built-in features cannot possibly cover all use cases, and the internal representation of the content is not readily exposed. We believe that if direct manipulation interfaces were to (a) use general-purpose programs as the representation format, and (b) expose those programs to the user, then experts could customize these systems in powerful new ways and non-experts could enjoy some of the benefits of programmable systems. In recent work, we presented a prototype SVG editor called Sketch-n-Sketch that offered a step towards this vision. In that system, the user wrote a program in a general-purpose lambda-calculus to generate a graphic design and could then directly manipulate the output to indirectly change design parameters (i.e. constant literals) in the program in real-time during the manipulation. Unfortunately, the burden of programming the desired relationships rested entirely on the user. In this paper, we design and implement new features for Sketch-n-Sketch that assist in the programming process itself. Like typical direct manipulation systems, our extended Sketch-n-Sketch now provides GUI-based tools for drawing shapes, relating shapes to each other, and grouping shapes together. Unlike typical systems, however, each tool carries out the user's intention by transforming their general-purpose program. This novel, semi-automated programming workflow allows the user to rapidly create highlevel, reusable abstractions in the program while at the same time retaining direct manipulation capabilities. In future work, our approach may be extended with more graphic design features or realized for other application domains.},
	urldate = {2021-10-06},
	journal = {UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
	author = {Hempel, Brian and Chugh, Ravi},
	month = oct,
	year = {2016},
	note = {Publisher: Association for Computing Machinery, Inc},
	keywords = {Direct manipulation, Live programming, SVG},
	pages = {379--390},
}

@article{MayerMikael2018,
	title = {Bidirectional evaluation with direct manipulation},
	volume = {2},
	url = {https://dl.acm.org/doi/abs/10.1145/3276497},
	doi = {10.1145/3276497},
	abstract = {We present an evaluation update (or simply, update) algorithm for a full-featured functional programming language, which synthesizes program changes based on output changes. Intuitively, the update...},
	number = {OOPSLA},
	urldate = {2021-10-06},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {{Mayer Mikaël} and {Kuncak Viktor} and {Chugh Ravi}},
	month = oct,
	year = {2018},
	note = {Publisher: 
		ACM
		PUB27
		New York, NY, USA
	},
	keywords = {Bidirectional Programming, Direct Manipulation, Sketch-n-Sketch},
	pages = {1--28},
}

@article{Nathan2007a,
	title = {Combinators for bidirectional tree transformations},
	volume = {29},
	url = {https://dl.acm.org/doi/abs/10.1145/1232420.1232424},
	doi = {10.1145/1232420.1232424},
	abstract = {We propose a novel approach to the view-update problem for tree-structured data: a domain-specific programming language in which all expressions denote bidirectional transformations on trees. In on...},
	number = {3},
	urldate = {2021-09-24},
	journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
	author = {Nathan, FosterJ. and B., GreenwaldMichael and T., MooreJonathan and C., PierceBenjamin and {SchmittAlan}},
	month = may,
	year = {2007},
	note = {Publisher: 
		ACM
		PUB27
		New York, NY, USA
	},
	keywords = {Bidirectional programming, Harmony, XML, lenses, view update problem},
}

@article{Lynch1991,
	title = {Science in the age of mechanical reproduction: moral and epistemic relations between diagrams and photographs},
	volume = {6},
	issn = {1572-8404},
	url = {https://link.springer.com/article/10.1007/BF02426838},
	doi = {10.1007/BF02426838},
	abstract = {Sociologists, philosophers and historians of science are gradually recognizing the importance of visual representation. This is part of a more general movement away from a theory-centric view of science and towards an interest in practical aspects of observation and experimentation. Rather than treating science as a matter of demonstrating the logical connection between theoretical and empirical statements, an increasing number of investigations are examining how scientists compose and use diagrams, graphs, photographs, micrographs, maps, charts, and related visual displays. This paper focuses on diagrams in biology, and tries to demonstrate how diagrams are an integral part of the production of scientific knowledge. In order to disclose some of the distinctive practical and analytical uses of diagrams, the paper contrasts the way diagrams and photographs are used in biological texts. Both diagrams and photographs are shown to be “constructions” that separately and together mediate the investigation of scientific phenoman.},
	number = {2},
	urldate = {2021-09-23},
	journal = {Biology and Philosophy 1991 6:2},
	author = {Lynch, Michael},
	year = {1991},
	note = {Publisher: Springer},
	keywords = {Evolutionary Biology, Philosophy of Biology},
	pages = {205--226},
}

@article{Li2021,
	title = {Whatwe can learn from visual artists about sofware development},
	doi = {10.1145/3411764.3445682},
	abstract = {This paper explores software's role in visual art production by examining how artists use and develop software. We conducted interviews with professional artists who were collaborating with software developers, learning software development, and building and maintaining software.We found artists were motivated to learn software development for intellectual growth and access to technical communities. Artists valued efcient workfows through skilled manual execution and personal software development, but avoided high-level forms of software automation. Artists identifed conficts between their priorities and those of professional developers and computational art communities, which infuenced how they used computational aesthetics in their work. These fndings contribute to eforts in systems engineering research to integrate end-user programming and creativity support across software and physical media, suggesting opportunities for artists as collaborators. Artists' experiences writing software can guide technical implementations of domain-specifc representations, and their experiences in interdisciplinary production can aid inclusive community building around computational tools.},
	urldate = {2021-07-26},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Li, Jingyi and Hashim, Sonia and Jacobs, Jennifer},
	month = may,
	year = {2021},
	note = {Publisher: Association for Computing Machinery},
	keywords = {Creativity support tools, Software development, Visual art},
}

@article{Bille2005,
	title = {A survey on tree edit distance and related problems},
	volume = {337},
	issn = {03043975},
	doi = {10.1016/j.tcs.2004.12.030},
	abstract = {We survey the problem of comparing labeled trees based on simple local operations of deleting, inserting, and relabeling nodes. These operations lead to the tree edit distance, alignment distance, and inclusion problem. For each problem we review the results available and present, in detail, one or more of the central algorithms for solving the problem. © 2005 Elsevier B.V. All rights reserved.},
	number = {1-3},
	urldate = {2021-06-23},
	journal = {Theoretical Computer Science},
	author = {Bille, Philip},
	month = jun,
	year = {2005},
	note = {Publisher: Elsevier},
	keywords = {Tree alignment, Tree edit distance, Tree inclusion, Tree matching},
	pages = {217--239},
}

@article{Miltner2019,
	title = {On the fly synthesis of edit suggestions},
	volume = {3},
	issn = {2475-1421},
	url = {https://doi.org/10.1145/3360569},
	doi = {10.1145/3360569},
	abstract = {When working with a document, users often perform context-specific repetitive edits – changes to the document that are similar but specific to the contexts at their locations. Programming by demonstration/examples (PBD/PBE) systems automate these tasks by learning programs to perform the repetitive edits from demonstration or examples. However, PBD/PBE systems are not widely adopted, mainly because they require modal UIs – users must enter a special mode to give the demonstration/examples. This paper presents Blue-Pencil, a modeless system for synthesizing edit suggestions on the fly. Blue-Pencil observes users as they make changes to the document, silently identifies repetitive changes, and automatically suggests transformations that can apply at other locations. Blue-Pencil is parameterized – it allows the ”plug-and-play” of different PBE engines to support different document types and different kinds of transformations. We demonstrate this parameterization by instantiating Blue-Pencil to several domains – C\# and SQL code, markdown documents, and spreadsheets – using various existing PBE engines. Our evaluation on 37 code editing sessions shows that Blue-Pencil synthesized edit suggestions with a precision of 0.89 and a recall of 1.0, and took 199 ms to return suggestions on average. Finally, we report on several improvements based on feedback gleaned from a field study with professional programmers to investigate the use of Blue-Pencil during long code editing sessions. Blue-Pencil has been integrated with Visual Studio IntelliCode to power the IntelliCode refactorings feature.},
	number = {OOPSLA},
	urldate = {2021-06-17},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Miltner, Anders and Gulwani, Sumit and Le, Vu and Leung, Alan and Radhakrishna, Arjun and Soares, Gustavo and Tiwari, Ashish and Udupa, Abhishek},
	month = oct,
	year = {2019},
	note = {Publisher: Association for Computing Machinery (ACM)},
	keywords = {Program synthesis, Program transformation, Programming by example, Refactoring},
	pages = {1--29},
}

@book{Gulwani2017,
	title = {Program {Synthesis}},
	volume = {4},
	isbn = {978-1-68083-292-1},
	url = {www.nowpublishers.com;},
	urldate = {2021-06-06},
	author = {Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh and -Delft, Boston},
	month = oct,
	year = {2017},
}

@inproceedings{Albarghouthi2013,
	title = {Recursive program synthesis},
	volume = {8044 LNCS},
	isbn = {978-3-642-39798-1},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-39799-8_67},
	doi = {10.1007/978-3-642-39799-8_67},
	abstract = {Input-output examples are a simple and accessible way of describing program behaviour. Program synthesis from input-output examples has the potential of extending the range of computational tasks achievable by end-users who have no programming knowledge, but can articulate their desired computations by describing input-output behaviour. In this paper, we present Escher, a generic and efficient algorithm that interacts with the user via input-output examples, and synthesizes recursive programs implementing intended behaviour. Escher is parameterized by the components (instructions) that can be used in the program, thus providing a generic synthesis algorithm that can be instantiated to suit different domains. To search through the space of programs, Escher adopts a novel search strategy that utilizes special data structures for inferring conditionals and synthesizing recursive procedures. Our experimental evaluation of Escher demonstrates its ability to efficiently synthesize a wide range of programs, manipulating integers, lists, and trees. Moreover, we show that Escher outperforms a state-of-the-art SAT-based synthesis tool from the literature. © 2013 Springer-Verlag.},
	urldate = {2021-05-25},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Albarghouthi, Aws and Gulwani, Sumit and Kincaid, Zachary},
	year = {2013},
	note = {ISSN: 03029743},
	pages = {934--950},
}

@article{Novick1999a,
	title = {Evidence for abstract, schematic knowledge of three spatial diagram representations},
	volume = {27},
	issn = {1532-5946},
	url = {https://link.springer.com/article/10.3758/BF03211413},
	doi = {10.3758/BF03211413},
	abstract = {Spatial diagram representations such as hierarchies, matrices, and networks are important tools for thinking. Our data suggest that college students possess abstract schemas for these representations that include at least rudimentary information about their applicability conditions. In Experiment 1, subjects were better able to select the appropriate spatial diagram representation for a problem when cued to use general category information in memory about those representations than when cued to use specific example problems given during the experiment. The results of Experiment 2 showed that the superior performance in the general category condition was not based on a comparison of the test problems with examples in memory. The results of Experiment 3 showed that the superior performance was not due to learning that occurred during the experiment or to transfer appropriate processing. The General Discussion section considers the nature of students’ representation schemas and the question of why college students have only rudimentary schemas for common and widely applicable diagrammatic representations.},
	number = {2},
	urldate = {2022-02-10},
	journal = {Memory \& Cognition 1999 27:2},
	author = {Novick, Laura R. and Hurley, Sean M. and Francis, Melissa},
	year = {1999},
	pmid = {10226439},
	note = {Publisher: Springer},
	keywords = {Cognitive Psychology},
	pages = {288--308},
}

@article{Cox1999,
	title = {Representation construction, externalised cognition and individual differences},
	volume = {9},
	issn = {0959-4752},
	doi = {10.1016/S0959-4752(98)00051-6},
	abstract = {This article discusses the cognitive differences between reasoning with self-constructed external representations (ERs) and reasoning with presented representations (e.g. textbook diagrams). Examples of ERs produced by subjects solving reasoning problems are provided. It is argued that effective reasoning with ERs involves a three-way interaction between (a) the cognitive and semantic properties of the representation; (b) the match between the demands of the task and the type of information read-off afforded by the representation and (c) the effects of within-subject factors (e.g. prior knowledge, cognitive style). It is suggested that providing direct instruction in the use of ERs could usefully address each factor.},
	number = {4},
	urldate = {2022-02-09},
	journal = {Learning and Instruction},
	author = {Cox, Richard},
	month = aug,
	year = {1999},
	note = {Publisher: Pergamon},
	keywords = {Diagrammatic reasoning, External representations, Human problem solving, Individual differences},
	pages = {343--363},
}

@article{Moody2009,
	title = {The physics of notations: {Toward} a scientific basis for constructing visual notations in software engineering},
	volume = {35},
	issn = {00985589},
	doi = {10.1109/TSE.2009.67},
	abstract = {Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields. © 2009 IEEE.},
	number = {6},
	urldate = {2022-02-09},
	journal = {IEEE Transactions on Software Engineering},
	author = {Moody, Daniel},
	year = {2009},
	keywords = {Analysis, Communication, Concrete syntax, Diagrams, Modeling, Visual syntax, Visualization},
	pages = {756--779},
}

@article{Knoblich1999,
	title = {Constraint {Relaxation} and {Chunk} {Decomposition} in {Insight} {Problem} {Solving}},
	volume = {25},
	issn = {02787393},
	url = {/record/1999-01477-011},
	doi = {10.1037/0278-7393.25.6.1534},
	abstract = {Insight problem solving is characterized by impasses, states of mind in which the thinker does not know what to do next. The authors hypothesized that impasses are broken by changing the problem representation, and 2 hypothetical mechanisms for representational change are described: the relaxation of constraints on the solution and the decomposition of perceptual chunks. These 2 mechanisms generate specific predictions about the relative difficulty of individual problems and about differential transfer effects. The predictions were tested in 4 experiments using matchstick arithmetic problems. The results were consistent with the predictions. Representational change is a more powerful explanation for insight than alternative hypotheses, if the hypothesized change processes are specified in detail. Overcoming impasses in insight is a special case of the general need to override the imperatives of past experience in the face of novel conditions.},
	number = {6},
	urldate = {2022-02-09},
	journal = {Journal of Experimental Psychology: Learning Memory and Cognition},
	author = {Knoblich, Günther and Ohlsson, Stellan and Haider, Hilde and Rhenius, Detlef},
	year = {1999},
	note = {Publisher: American Psychological Association Inc.},
	pages = {1534--1555},
}

@article{Scaife1996,
	title = {External cognition: how do graphical representations work?},
	volume = {45},
	issn = {1071-5819},
	doi = {10.1006/IJHC.1996.0048},
	abstract = {Advances in graphical technology have now made it possible for us to interact with information in innovative ways, most notably by exploring multimedia environments and by manipulating three-dimensional virtual worlds. Many benefits have been claimed for this new kind of interactivity, a general assumption being that learning and cognitive processing are facilitated. We point out, however, that little is known about the cognitive value of any graphical representations, be they good old-fashioned (e.g. diagrams) or more advanced (e.g. animations, multimedia, virtual reality). In our paper, we critique the disparate literature on graphical representations, focusing on four representative studies. Our analysis reveals a fragmented and poorly understood account of how graphical representations work, exposing a number of assumptions and fallacies. As an alternative we propose a new agenda for graphical representation research. This builds on the nascent theoretical approach within cognitive science that analyses the role played by external representations in relation to internal mental ones. We outline some of the central properties of this relationship that are necessary for the processing of graphical representations. Finally, we consider how this analysis can inform the selection and design of both traditional and advanced forms of graphical technology. © 1996 Academic Press Limited.},
	number = {2},
	urldate = {2022-02-09},
	journal = {International Journal of Human-Computer Studies},
	author = {Scaife, Mike and Rogers, Yvonne},
	month = aug,
	year = {1996},
	note = {Publisher: Academic Press},
	pages = {185--213},
}

@article{Dix1998,
	title = {Starting simple - {Adding} value to static visualisation through simple interaction},
	url = {http://www.hiraeth.com/alan/papers/simple98/},
	doi = {10.1145/948496.948514},
	abstract = {Interactive visualisation has been one of the most exciting areas in HCI over recent years. The key term here is 'interactive', and in this paper we assert that virtually any static representation can become more powerful by the addition of simple interactive elements. This is demonstrated by adding interactivity to standard representations including stacked histograms, pie charts and scatter plots. We show how adding interactivity can help resolve many of the trade-offs inherent in static visualisations by allowing multiple options to be available and most importantly for them to be interactively related. Many years of creativity and effort have been invested in traditional generic and bespoke visualisations. Adding interactivity leverages this accumulated experience, but also adds an extra dimension.},
	urldate = {2022-02-02},
	journal = {Proceedings of the Workshop on Advanced Visual Interfaces AVI},
	author = {Dix, Alan and Ellis, Geoffrey},
	year = {1998},
	keywords = {Information visualisation, Interactive graphics, Visual interaction},
	pages = {124--134},
}

@article{Weitzman1994,
	title = {Automatic presentation of multimedia documents using relational grammars},
	doi = {10.1145/192593.192718},
	abstract = {This paper describes an approach to the automatic presentation of multimedia documents based on parsing and syntax-directed translation using Relational Grammars. This translation is followed by a constraint solving mechanism to create the final layout. Grammatical rules provide the mechanism for mapping from a representation of the content of a presentation to forms that specify the media objects to be realized. These realization forms include sets of spatial and temporal constraints between elements of the presentation. Individual grammars encapsulate the "look and feel" of a presentation and can be used as generators of that style. By making the grammars sensitive to the requirements of the output medium, parsing can introduce flexibility into the information realization process.},
	urldate = {2021-10-04},
	journal = {Proceedings of the 2nd ACM International Conference on Multimedia, MULTIMEDIA 1994},
	author = {Weitzman, Louis and Wittenburg, Kent},
	month = oct,
	year = {1994},
	note = {Publisher: Association for Computing Machinery, Inc},
	keywords = {Automatic design, Constraints, Grammar-directed design, Parsing, Relational grammars, Visual languages},
	pages = {443--451},
}

@inproceedings{Lerner2020,
	title = {Projection {Boxes}: {On}-the-fly {Reconfigurable} {Visualization} for {Live} {Programming}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376494},
	doi = {10.1145/3313831.3376494},
	abstract = {Live programming is a regime in which the programming environment provides continual feedback, most often in the form of runtime values. In this paper, we present Projection Boxes, a novel visualization technique for displaying runtime values of programs. The key idea behind projection boxes is to start with a full semantics of the program, and then use projections to pick a subset of the semantics to display. By varying the projection used, projection boxes can encode both previously known visualization techniques, and also new ones. As such, projection boxes provide an expressive and configurable framework for displaying runtime information. Through a user study we demonstrate that (1) users find projection boxes and their configurability useful (2) users are not distracted by the always-on visualization (3) a key driving force behind the need for a configurable visualization for live programming lies with the wide variation in programmer preferences.},
	urldate = {2021-05-25},
	booktitle = {Conference on {Human} {Factors} in {Computing} {Systems} - {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Lerner, Sorin},
	month = apr,
	year = {2020},
	keywords = {debugging, live programming, program visualization, programming environment},
}

@article{amulet,
	title = {The amulet environment: {New} models for effective user interface software development},
	volume = {23},
	issn = {00985589},
	doi = {10.1109/32.601073},
	abstract = {The Amulet user interface development environment makes it easier for programmers to create highly-interactive, graphical user interface software for Unix, Windows and the Macintosh. Amulet uses new models for objects, constraints, animation, input, output, commands, and undo. The object system is a prototype-instance model in which there is no distinction between classes and instances or between methods and data. The constraint system allows any value of any object to be computed by arbitrary code and supports multiple constraint solvers. Animations can be attached to existing objects with a single line of code. Input from the user is handled by "interactor" objects which support reuse of behavior objects. The output model provides a declarative definition of the graphics and supports automatic refresh. Command objects encapsulate all of the information needed about operations, including support for various ways to undo them. A key feature of the Amulet design is that all graphical objects and behaviors of those objects are explicitly represented at run-time, so the system can provide a number of high-level built-in functions, including automatic display and editing of objects, and external analysis and control of interfaces. Amulet integrates these capabilities in a flexible and effective manner. © 1997 IEEE.},
	number = {6},
	urldate = {2022-03-16},
	journal = {IEEE Transactions on Software Engineering},
	author = {Myers, Brad A. and McDaniel, Richard G. and Miller, Robert C. and Ferrency, Alan S. and Faulring, Andrew and Kyle, Bruce D.},
	year = {1997},
	keywords = {Toolkits, User interface development environments, User interface management systems (uimss), User interface tools},
	pages = {347--365},
}

@article{deltablue,
	title = {Multi-way versus one-way constraints in user interfaces: {Experience} with the deltablue algorithm},
	volume = {23},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1002/spe.4380230507},
	doi = {10.1002/SPE.4380230507},
	abstract = {The efficient satisfaction of constraints is essential to the performance of constraint‐based user interfaces. In the past, most constraint‐based user interfaces have used one‐way rather than multi‐way constraints because of a widespread belief that one‐way constraints were more efficient. In this paper we argue that many user interface construction problems are handled more naturally and elegantly by multi‐way constraints than by one‐way constraints. We present pseudocode for an incremental multi‐way constraint satisfaction algorithm, DeltaBlue, and describe experience in using the algorithm in two user interface toolkits. Finally, we provide performance figures demonstrating that multi‐way constraint solvers can be entirely competitive in performance with one‐way constraint solvers. Copyright © 1993 John Wiley \& Sons, Ltd},
	number = {5},
	urldate = {2022-03-16},
	journal = {Software: Practice and Experience},
	author = {Sannella, Michael and Maloney, John and Freeman‐Benson, Bjorn and Borning, Alan},
	month = may,
	year = {1993},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Constraint satisfaction, Constraints, DeltaBlue, Local propagation, User interface implementation techniques},
	pages = {529--566},
}

@article{interactiveDynamicsTaxonomy,
	title = {Interactive {Dynamics} for {Visual} {Analysis}},
	volume = {10},
	issn = {15427749},
	url = {https://dl.acm.org/doi/abs/10.1145/2133416.2146416},
	doi = {10.1145/2133416.2146416},
	abstract = {The increasing scale and availability of digital data provides an extraordinary resource for informing public policy, scientific discovery, business strategy, and even our personal lives. To get th...},
	number = {2},
	urldate = {2022-02-02},
	journal = {Queue},
	author = {Heer, Jeffrey and Shneiderman, Ben},
	month = feb,
	year = {2012},
	note = {Publisher: ACM PUB27 New York, NY, USA},
	pages = {30--55},
}

@article{datavizCriticalReflection,
	title = {Critical reflections on visualization authoring systems},
	volume = {26},
	issn = {19410506},
	doi = {10.1109/TVCG.2019.2934281},
	abstract = {An emerging generation of visualization authoring systems support expressive information visualization without textual programming. As they vary in their visualization models, system architectures, and user interfaces, it is challenging to directly compare these systems using traditional evaluative methods. Recognizing the value of contextualizing our decisions in the broader design space, we present critical reflections on three systems we developed-Lyra, Data Illustrator, and Charticulator. This paper surfaces knowledge that would have been daunting within the constituent papers of these three systems. We compare and contrast their (previously unmentioned) limitations and trade-offs between expressivity and learnability. We also reflect on common assumptions that we made during the development of our systems, thereby informing future research directions in visualization authoring systems.},
	number = {1},
	urldate = {2022-03-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, Arvind and Lee, Bongshin and Ren, Donghao and Heer, Jeffrey and Stasko, John and Thompson, John and Brehmer, Matthew and Liu, Zhicheng},
	month = jan,
	year = {2020},
	pmid = {31442976},
	note = {arXiv: 1907.13568
Publisher: IEEE Computer Society},
	keywords = {Critical reflection, Expressivity, Learnability, Reusability, Visualization authoring},
	pages = {461--471},
}

@article{grammarOfGraphics,
	title = {The {Grammar} of {Graphics}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-21551-3_13},
	doi = {10.1007/978-3-642-21551-3_13},
	abstract = {The Grammar of Graphics, or GOG, denotes a system with seven orthogonal components. By orthogonal, we mean there are seven graphical component sets whose elements are aspects of the general system and that every combination of aspects in the product of all these sets is meaningful. This sense of the word orthogonality, a term used by computer designers to describe a combinatoric system of components or building blocks, is in some sense similar to the orthogonal factorial analysis of variance (ANOVA), where factors have levels and all possible combinations of levels exist in the ANOVA design. If we interpret each combination of features in a GOG system as a point in a network, then the world described by GOG is represented in a seven-dimensional rectangular lattice.},
	urldate = {2022-03-16},
	journal = {Handbook of Computational Statistics},
	author = {Wilkinson, Leland},
	year = {2012},
	note = {Publisher: Springer, Berlin, Heidelberg},
	pages = {375--414},
}

@article{d3,
	title = {D3 data-driven documents},
	volume = {17},
	issn = {10772626},
	doi = {10.1109/TVCG.2011.185},
	abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations. © 2011 IEEE.},
	number = {12},
	urldate = {2022-03-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
	year = {2011},
	keywords = {2D graphics., Information visualization, toolkits, user interfaces},
	pages = {2301--2309},
}

@article{vegalite,
	title = {Vega-{Lite}: {A} {Grammar} of {Interactive} {Graphics}},
	volume = {23},
	issn = {10772626},
	doi = {10.1109/TVCG.2016.2599030},
	abstract = {We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.},
	number = {1},
	urldate = {2022-03-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
	month = jan,
	year = {2017},
	pmid = {27875150},
	note = {Publisher: IEEE Computer Society},
	keywords = {Information visualization, declarative specification, interaction, systems, toolkits},
	pages = {341--350},
}

@article{VisualexplanationsImprovesLearning,
	title = {Creating visual explanations improves learning},
	volume = {1},
	issn = {23657464},
	url = {https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-016-0031-6},
	doi = {10.1186/S41235-016-0031-6/FIGURES/7},
	abstract = {Many topics in science are notoriously difficult for students to learn. Mechanisms and processes outside student experience present particular challenges. While instruction typically involves visualizations, students usually explain in words. Because visual explanations can show parts and processes of complex systems directly, creating them should have benefits beyond creating verbal explanations. We compared learning from creating visual or verbal explanations for two STEM domains, a mechanical system (bicycle pump) and a chemical system (bonding). Both kinds of explanations were analyzed for content and learning assess by a post-test. For the mechanical system, creating a visual explanation increased understanding particularly for participants of low spatial ability. For the chemical system, creating both visual and verbal explanations improved learning without new teaching. Creating a visual explanation was superior and benefitted participants of both high and low spatial ability. Visual explanations often included crucial yet invisible features. The greater effectiveness of visual explanations appears attributable to the checks they provide for completeness and coherence as well as to their roles as platforms for inference. The benefits should generalize to other domains like the social sciences, history, and archeology where important information can be visualized. Together, the findings provide support for the use of learner-generated visual explanations as a powerful learning tool.},
	number = {1},
	urldate = {2022-03-16},
	journal = {Cognitive Research: Principles and Implications},
	author = {Bobek, Eliza and Tversky, Barbara},
	month = dec,
	year = {2016},
	note = {Publisher: Springer},
	keywords = {Complex system, Diagrammatic reasoning, Dynamic system, Learning, Process, STEM, Spatial ability, Structure, Visual communication},
	pages = {1--14},
}

@article{aleven2016instruction,
	title = {Instruction based on adaptive learning technologies},
	journal = {Handbook of research on learning and instruction},
	author = {Aleven, Vincent and McLaughlin, Elizabeth A and Glenn, R Amos and Koedinger, Kenneth R},
	year = {2016},
	note = {Publisher: Routledge Abingdon},
	pages = {522--560},
}

@article{maras_client-side_2011,
	title = {Client-side web application slicing},
	doi = {10.1109/ASE.2011.6100110},
	abstract = {Highly interactive web applications that offer user experience and responsiveness of standard desktop applications are becoming prevalent in the web application domain. However, with these benefits come certain drawbacks. For example, the event-based architectural style, and poor support for code organization, often lead to a situation where code responsible for a certain behavior is intermixed with irrelevant code. This makes development, debugging and reuse difficult. One way of locating code implementing a certain behavior is program slicing, a method that, given a subset of a program's behavior, reduces the program to a minimal form that still produces that behavior. In this paper we present a semi-automatic client-side web application slicing method, describe the web page dependency graph, and show how it can be used to extract only the code implementing a certain behavior. © 2011 IEEE.},
	urldate = {2022-03-15},
	journal = {2011 26th IEEE/ACM International Conference on Automated Software Engineering, ASE 2011, Proceedings},
	author = {Maras, Josip and Carlson, Jan and Crnković, Ivica},
	year = {2011},
	note = {ISBN: 9781457716393},
	keywords = {JavaScript, code reuse, dynamic program slicing, web application},
	pages = {504--507},
}

@article{pane_assessing_1996,
	title = {Assessing dynamics in computer-based instruction},
	doi = {10.1145/238386.238482},
	abstract = {We present an evaluation of a multimedia educational software system that includes text, graphics, animations, and simulations. When compared with an informationally equivalent control environment that used text and carefully selected still images, we found little evidence that the dynamic presentations enhanced student understanding of the declarative information in this lesson. Furthermore, students cannot be relied on to take full advantage of exploratory opportunities in computer-based instruction. These results prescribe further investigation of whether and how computer-based multimedia can be used effectively in education and training.},
	urldate = {2022-03-15},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Pane, John F. and Corbett, Albert T. and John, Bonnie E.},
	year = {1996},
	note = {Publisher: ACM},
	keywords = {animation, computer-based leaming, multimedia, simulation},
	pages = {197--204},
}

@inproceedings{wordProblemGen,
	title = {Personalized mathematical word problem generation},
	booktitle = {Twenty-{Fourth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Polozov, Oleksandr and O'Rourke, Eleanor and Smith, Adam M and Zettlemoyer, Luke and Gulwani, Sumit and Popović, Zoran},
	year = {2015},
}

@inproceedings{wilson2005combining,
	title = {Combining dynamic geometry, automated geometry theorem proving and diagrammatic proofs},
	booktitle = {Workshop on {User} {Interfaces} for {Theorem} {Provers} ({UITP})},
	author = {Wilson, Sean and Fleuriot, Jacques D},
	year = {2005},
}

@inproceedings{synthDeduction,
	title = {Automatically {Generating} {Problems} and {Solutions} for {Natural} {Deduction}},
	isbn = {978-1-57735-633-2},
	url = {https://www.microsoft.com/en-us/research/publication/automatically-generating-problems-solutions-natural-deduction/},
	abstract = {Natural deduction, which is a method for establishing validity of propositional type arguments, helps develop important reasoning skills and is thus a key ingredient in a course on introductory logic. We present two core components, namely solution generation and practice problem generation, for enabling computer-aided education for this important subject domain. The key enabling technology is use of an offline-computed data-structure called Universal Proof Graph (UPG) that encodes all possible applications of inference rules over all small propositions abstracted using their bitvector-based truth-table representation. This allows an efficient forward search for solution generation. More interestingly, this allows generating fresh practice problems that have given solution characteristics by performing a backward search in UPG. We obtained around 300 natural deduction problems from various textbooks. Our solution generation procedure can solve many more problems than the traditional forward-chaining based procedure, while our problem generation procedure can efficiently generate several variants with desired characteristics.},
	booktitle = {{IJCAI} '13 {Proceedings} of the {Twenty}-{Third} international joint conference on {Artificial} {Intelligence}},
	author = {Ahmed, Umair Z and Gulwani, Sumit and Karkare, Amey},
	month = aug,
	year = {2013},
	pages = {1968--1975},
}

@article{ackermann_-contextualized_nodate,
	title = {From {De}-contextualized to {Situated} {Knowledge}: {Revisiting} {Piaget}'s {Water}-{Level} {Experiment}},
	urldate = {2022-03-11},
	author = {Ackermann, Edith K},
}

@book{holtGeometry,
	title = {Holt geometry},
	publisher = {Holt, Rinehart and Winston},
	author = {Burger, Edward B and Chard, David J and Hall, Earlene J and Kennedy, Paul A and Leinwand, Steven J and Renfro, Freddie L and Seymour, Dale G and Wattis, Bert K},
	year = {2007},
}

@article{Allen-Zhu2020,
	title = {Backward {Feature} {Correction}: {How} {Deep} {Learning} {Performs} {Deep} {Learning}},
	url = {https://arxiv.org/abs/2001.04413v5},
	doi = {10.48550/arxiv.2001.04413},
	abstract = {How does a 110-layer ResNet learn a high-complexity classifier using
relatively few training examples and short training time? We present a theory
towards explaining this in terms of Hierarchical Learning. We refer
hierarchical learning as the learner learns to represent a complicated target
function by decomposing it into a sequence of simpler functions to reduce
sample and time complexity. We formally analyze how multi-layer neural networks
can perform such hierarchical learning efficiently and automatically by
applying SGD. On the conceptual side, we present, to the best of our knowledge, the FIRST
theory result indicating how deep neural networks can still be sample and time
efficient using SGD on certain hierarchical learning tasks, when NO KNOWN
existing algorithm is efficient. We establish a new principle called "backward
feature correction", where training higher-level layers in the network can
improve the features of lower-level ones. We believe this is the key to
understand the deep learning process in multi-layer neural networks. On the technical side, we show for regression and even binary classification,
for every input dimension \$d{\textgreater}0\$, there is a concept class of degree \${\textbackslash}omega(1)\$
polynomials so that, using \${\textbackslash}omega(1)\$-layer neural networks as learners, SGD
can learn any function from this class in \${\textbackslash}mathsf\{poly\}(d)\$ time and sample
complexity to any \${\textbackslash}frac\{1\}\{{\textbackslash}mathsf\{poly\}(d)\}\$ error, through learning to
represent it as a composition of \${\textbackslash}omega(1)\$ layers of quadratic functions. In
contrast, we do not know any other simple algorithm (including layer-wise
training or applying kernel method sequentially) that can learn this concept
class in \${\textbackslash}mathsf\{poly\}(d)\$ time even to any \$d{\textasciicircum}\{-0.01\}\$ error. As a side
result, we prove \$d{\textasciicircum}\{{\textbackslash}omega(1)\}\$ lower bounds for several non-hierarchical
learners, including any kernel methods, neural tangent or neural compositional
kernels.},
	urldate = {2022-03-08},
	author = {Allen-Zhu, Zeyuan and Research, Microsoft and Li, Redmond Yuanzhi},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.04413
ISBN: 2001.04413v5},
}

@article{drawingToLearn,
	title = {Drawing to learn in science},
	volume = {333},
	issn = {00368075},
	url = {https://www.science.org/doi/abs/10.1126/science.1204153},
	doi = {10.1126/SCIENCE.1204153/SUPPL_FILE/1204153.AINSWORTH.SOM.PDF},
	abstract = {Emerging research suggests drawing should be explicitly recognized as a key element in science education.},
	number = {6046},
	urldate = {2021-11-18},
	journal = {Science},
	author = {Ainsworth, Shaaron and Prain, Vaughan and Tytler, Russell},
	month = aug,
	year = {2011},
	pmid = {21868658},
	note = {Publisher: 
American Association for the Advancement of Science},
	pages = {1096--1097},
}

@inproceedings{smallStepPBE,
	title = {Small-step live programming by example},
	isbn = {978-1-4503-7514-6},
	url = {http://dx.doi.org/10.1145/3379337.3415869},
	doi = {10.1145/3379337.3415869},
	abstract = {Live programming is a paradigm in which the programming environment continually displays runtime values. Program synthesis is a technique that can generate programs or program snippets from examples. {\textbackslash}deltextThis paper presents a new programming paradigm called Synthesis-Aided Live Programming that combines these two prior ideas in a synergistic way. When using Synthesis-Aided Live Programming, programmers can change the runtime values displayed by the live {\textbackslash}addtextPrevious works that combine the two have taken a holistic approach to the way examples describe the behavior of functions and programs. This paper presents a new programming paradigm called Small-Step Live Programming by Example that lets the user apply Programming by Example locally. When using Small-Step Live Programming by Example, programmers can change the runtime values displayed by the live visualization to generate local program snippets. \% Live programming and program \% synthesis work perfectly together because the live programming environment \% reifies values, which makes it easy for programmers to provide the examples \% needed by the synthesizer. We implemented this new paradigm in a tool called {\textbackslash}toolname, and performed a user study on \$13\$ programmers. Our study finds that Small-Step Live Programming by Example with {\textbackslash}toolname helps users solve harder problems faster, and that for certain types of queries, users prefer it to searching the web. Additionally, we identify the {\textbackslash}usersynthgap, in which users' mental models of the tool do not match its ability, and needs to be taken into account in the design of future synthesis tools.},
	urldate = {2021-05-22},
	booktitle = {{UIST} 2020 - {Proceedings} of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Ferdowsifard, Kasra and Ordookhanians, Allen and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
	month = oct,
	year = {2020},
	keywords = {Live programming, Program synthesis},
	pages = {614--626},
}

@misc{doingWithImages,
	title = {Doing with images makes symbols},
	url = {https://archive.org/details/AlanKeyD1987},
	journal = {Distinguished lecture series, Apple Computer},
	author = {Kay, Alan},
	year = {1987},
}

@article{samenessAndDifference,
	title = {Sameness and {Difference} in {Transfer}},
	volume = {15},
	issn = {10508406},
	url = {https://www.tandfonline.com/doi/abs/10.1207/s15327809jls1504_3},
	doi = {10.1207/S15327809JLS1504_3},
	abstract = {Discussions about transfer have mainly dealt with how people manage to do something in a situation thanks to having done something similar in a previous situation. From an educational point of view...},
	number = {4},
	urldate = {2022-03-08},
	journal = {Journal of the Learning Sciences},
	author = {Marton, Ference},
	year = {2006},
	note = {Publisher: Lawrence Erlbaum Associates, Inc.},
	pages = {499--535},
}

@incollection{ferdowsifard_small-step_2020,
	address = {New York, NY, USA},
	title = {Small-{Step} {Live} {Programming} by {Example}},
	isbn = {9781450375146},
	url = {https://doi.org/10.1145/3379337.3415869},
	abstract = {Live programming is a paradigm in which the programming environment continually displays runtime values. Program synthesis is a technique that can generate programs or program snippets from examples. {\textbackslash}deltextThis paper presents a new programming paradigm called Synthesis-Aided Live Programming that combines these two prior ideas in a synergistic way. When using Synthesis-Aided Live Programming, programmers can change the runtime values displayed by the live {\textbackslash}addtextPrevious works that combine the two have taken a holistic approach to the way examples describe the behavior of functions and programs. This paper presents a new programming paradigm called Small-Step Live Programming by Example that lets the user apply Programming by Example locally. When using Small-Step Live Programming by Example, programmers can change the runtime values displayed by the live visualization to generate local program snippets. \% Live programming and program \% synthesis work perfectly together because the live programming environment \% reifies values, which makes it easy for programmers to provide the examples \% needed by the synthesizer. We implemented this new paradigm in a tool called {\textbackslash}toolname, and performed a user study on \$13\$ programmers. Our study finds that Small-Step Live Programming by Example with {\textbackslash}toolname helps users solve harder problems faster, and that for certain types of queries, users prefer it to searching the web. Additionally, we identify the {\textbackslash}usersynthgap, in which users' mental models of the tool do not match its ability, and needs to be taken into account in the design of future synthesis tools.},
	urldate = {2021-05-22},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Ferdowsifard, Kasra and Ordookhanians, Allen and Peleg, Hila and Lerner, Sorin and Polikarpova, Nadia},
	month = oct,
	year = {2020},
	keywords = {live programming, program synthesis},
	pages = {614--626},
}

@inproceedings{head_writing_2017,
	address = {New York, NY, USA},
	series = {L@{S} '17},
	title = {Writing {Reusable} {Code} {Feedback} at {Scale} with {Mixed}-{Initiative} {Program} {Synthesis}},
	isbn = {978-1-4503-4450-0},
	url = {https://doi.org/10.1145/3051457.3051467},
	doi = {10.1145/3051457.3051467},
	abstract = {In large introductory programming classes, teacher feedback on individual incorrect student submissions is often infeasible. Program synthesis techniques are capable of fixing student bugs and generating hints automatically, but they lack the deep domain knowledge of a teacher and can generate functionally correct but stylistically poor fixes. We introduce a mixed-initiative approach which combines teacher expertise with data-driven program synthesis techniques. We demonstrate our novel approach in two systems that use different interaction mechanisms. Our systems use program synthesis to learn bug-fixing code transformations and then cluster incorrect submissions by the transformations that correct them. The MistakeBrowser system learns transformations from examples of students fixing bugs in their own submissions. The FixPropagator system learns transformations from teachers fixing bugs in incorrect student submissions. Teachers can write feedback about a single submission or a cluster of submissions and propagate the feedback to all other submissions that can be fixed by the same transformation. Two studies suggest this approach helps teachers better understand student bugs and write reusable feedback that scales to a massive introductory programming classroom.},
	urldate = {2021-05-17},
	booktitle = {Proceedings of the {Fourth} (2017) {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Head, Andrew and Glassman, Elena and Soares, Gustavo and Suzuki, Ryo and Figueredo, Lucas and D'Antoni, Loris and Hartmann, Björn},
	month = apr,
	year = {2017},
	keywords = {program synthesis, programming education},
	pages = {89--98},
}

@misc{noauthor_holt_nodate,
	title = {Holt {Geometry} {Pennsylvania}},
	url = {https://www.goodreads.com/work/best_book/20404935-holt-geometry-pennsylvania-student-edition-grades-9-12-2007},
	abstract = {Holt Geometry Pennsylvania book. Read reviews from world’s largest community for readers. , Holt Geometry Pennsylvania book. Read reviews from world’s largest community for readers.},
	urldate = {2021-05-18},
}

@article{shin_synthetic_2019,
	title = {Synthetic {Datasets} for {Neural} {Program} {Synthesis}},
	url = {http://arxiv.org/abs/1912.12345},
	abstract = {The goal of program synthesis is to automatically generate programs in a particular language from corresponding specifications, e.g. input-output behavior. Many current approaches achieve impressive results after training on randomly generated I/O examples in limited domain-specific languages (DSLs), as with string transformations in RobustFill. However, we empirically discover that applying test input generation techniques for languages with control flow and rich input space causes deep networks to generalize poorly to certain data distributions; to correct this, we propose a new methodology for controlling and evaluating the bias of synthetic data distributions over both programs and specifications. We demonstrate, using the Karel DSL and a small Calculator DSL, that training deep networks on these distributions leads to improved cross-distribution generalization performance.},
	urldate = {2021-05-14},
	journal = {arXiv:1912.12345 [cs, stat]},
	author = {Shin, Richard and Kant, Neel and Gupta, Kavi and Bender, Christopher and Trabucco, Brandon and Singh, Rishabh and Song, Dawn},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.12345},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Programming Languages, Statistics - Machine Learning},
}

@article{thompson_learning_2000,
	title = {Learning {Mathematics} {Vocabulary}: {Potential} {Pitfalls} and {Instructional} {Strategies}},
	volume = {93},
	issn = {0025-5769},
	shorttitle = {Learning {Mathematics} {Vocabulary}},
	url = {https://www.jstor.org/stable/27971502},
	number = {7},
	urldate = {2019-04-09},
	journal = {The Mathematics Teacher},
	author = {Thompson, Denisse R. and Rubenstein, Rheta N.},
	year = {2000},
	pages = {568--574},
}

@incollection{multimediaPrinciple,
	title = {Multimedia learning},
	volume = {41},
	url = {http://www.sciencedirect.com/science/article/pii/S0079742102800056},
	abstract = {This chapter discusses the multimedia learning. Multimedia learning occurs when a learner builds a mental representation from words and pictures that have been presented. For purposes of research program, multimedia instructional messages are presentations of material using words and pictures that are intended to foster learning. The pictures can be static graphics such as photos, drawings, maps, charts, figures, and tables or dynamic graphics such as video or animation. Multimedia learning occurs if one constructs a mental representation of the lightning system based on the words and pictures in the multimedia instructional message. In this case, one must build a cause-and-effect model of how a change in one part of the system causes a principle-based change in another part, and so on. For example, when cool air comes over a warm surface, the cool air becomes heated and rises.},
	urldate = {2019-05-11},
	booktitle = {Psychology of {Learning} and {Motivation}},
	publisher = {Academic Press},
	author = {Mayer, Richard E.},
	month = jan,
	year = {2002},
	doi = {10.1016/S0079-7421(02)80005-6},
	pages = {85--139},
}

@incollection{cheng_towards_2009,
	address = {Dordrecht},
	series = {Models and {Modeling} in {Science} {Education}},
	title = {Towards a {Better} {Utilization} of {Diagrams} in {Research} into the {Use} of {Representative} {Levels} in {Chemical} {Education}},
	isbn = {978-1-4020-8872-8},
	url = {https://doi.org/10.1007/978-1-4020-8872-8_4},
	abstract = {The representation of chemical concepts – indeed scientific concepts generally{\textasciitilde}– is inherently multimodal, i.e. it involves the combination of more than one mode of representation. Consequently, the successful learning of chemistry involves the construction of mental associations among the macroscopic, microscopic and symbolic levels of representation of chemical phenomena using different modes of representation. Traditional linguistically framed research studies are only capable of capturing some aspects of that understanding. We suggest that students’ understanding of diagrammatic representations{\textasciitilde}– the visual mode{\textasciitilde}– should be more extensively exploited in chemical educational research. Studies that have probed students’ understanding through their construction of and through their interpretation of presented diagrams are reviewed. Further potential of the use of the visual mode of representation in such research, especially in respect of the macro/sub-micro/symbolic representational triplet, is also discussed.},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {Multiple {Representations} in {Chemical} {Education}},
	publisher = {Springer Netherlands},
	author = {Cheng, Maurice and Gilbert, John K.},
	editor = {Gilbert, John K. and Treagust, David},
	year = {2009},
	doi = {10.1007/978-1-4020-8872-8_4},
	keywords = {Chemical Education, Diagrammatic Representation, Good Utilization, Verbal Mode, Visual Mode},
	pages = {55--73},
}

@article{bosse_translations_2011,
	title = {Translations among {Mathematical} {Representations}: {Teacher} {Beliefs} and {Practices}},
	issn = {1473-0111},
	shorttitle = {Translations among {Mathematical} {Representations}},
	abstract = {Student ability, teacher expectations, respective degrees of difficulty, and curriculum and instructional practices all work together to provide students experiences leading to differing levels of success in respect to mathematical translations. Herein, we discuss teacher beliefs and instructional practices, investigate why some translations seem to be more difficult than others, and provide instructional recommendations to assist students and teachers with mathematical translations. Through formal and informal observations of high school Algebra and Pre-Calculus teachers and students, possible links of causality have been observed to explain students' difficulties in translating among mathematical representations (verbal, symbolic (or algebraic), tabular (or numeric) and graphical). Affecting students' success are dimensions including: teachers' expectations of students being able to perform these translations; what teachers directly instruct and model in the classroom regarding translations; the complexity of some of these translations; and the level of the mathematics depicted in some of the representations. These dimensions and roles as causal factors in students translating from one representation to another are discussed in this paper. (Contains 7 figures.)},
	language = {en},
	urldate = {2019-05-10},
	journal = {International Journal for Mathematics Teaching and Learning},
	author = {Bosse, Michael J. and Adu-Gyamfi, Kwaku and Cheetham, Meredith},
	month = jun,
	year = {2011},
	keywords = {Academic Ability, Academic Achievement, Algebra, Calculus, Educational Practices, High Schools, Investigations, Mathematics Teachers, Student Attitudes, Teacher Attitudes, Teaching Methods},
}

@article{clement_translation_1981,
	title = {Translation {Difficulties} in {Learning} {Mathematics}},
	volume = {88},
	issn = {0002-9890},
	url = {https://www.jstor.org/stable/2320560},
	doi = {10.2307/2320560},
	number = {4},
	urldate = {2018-11-07},
	journal = {The American Mathematical Monthly},
	author = {Clement, John and Lochhead, Jack and Monk, George S.},
	year = {1981},
	pages = {286--290},
}

@article{koedinger_trade-offs_2008,
	title = {Trade-offs between grounded and abstract representations: evidence from algebra problem solving},
	volume = {32},
	issn = {0364-0213},
	shorttitle = {Trade-offs between grounded and abstract representations},
	doi = {10.1080/03640210701863933},
	abstract = {This article explores the complementary strengths and weaknesses of grounded and abstract representations in the domain of early algebra. Abstract representations, such as algebraic symbols, are concise and easy to manipulate but are distanced from any physical referents. Grounded representations, such as verbal descriptions of situations, are more concrete and familiar, and they are more similar to physical objects and everyday experience. The complementary computational characteristics of grounded and abstract representations lead to trade-offs in problem-solving performance. In prior research with high school students solving relatively simple problems, Koedinger and Nathan (2004) demonstrated performance benefits of grounded representations over abstract representations-students were better at solving simple story problems than the analogous equations. This article extends this prior work to examine both simple and more complex problems in two samples of college students. On complex problems with two references to the unknown, a "symbolic advantage" emerged, such that students were better at solving equations than analogous story problems. Furthermore, the previously observed "verbal advantage" on simple problems was replicated. We thus provide empirical support for a trade-off between grounded, verbal representations, which show advantages on simpler problems, and abstract, symbolic representations, which show advantages on more complex problems.},
	language = {eng},
	number = {2},
	journal = {Cognitive Science},
	author = {Koedinger, Kenneth R. and Alibali, Martha W. and Nathan, Mitchell J.},
	month = mar,
	year = {2008},
	pmid = {21635340},
	pages = {366--397},
}

@phdthesis{groundedFeedback,
	type = {Thesis},
	title = {Toward {Sense} {Making} with {Grounded} {Feedback}},
	url = {https://kilthub.cmu.edu/articles/Toward_Sense_Making_with_Grounded_Feedback/6724007},
	abstract = {In STEM domains, robust learning includes not only fluency with procedures, but also recognition and application of the conceptual principles that underlie them. Grounded feedback is one instructional approach proposed to help students integrate conceptual knowledge into their learning of procedures. Grounded feedback functions primarily by having students take an action in the target domain (often symbolic) and receiving feedback in a representation that is easier to reason with. This thesis defines grounded feedback and evaluates its effectiveness. I define grounded feedback with four characteristics: (1) The feedback reflects students’ inputs according to rules that are inherent to the topic of study. For example, an inputted equation with two variables may be shown as a graph. (2) The feedback facilitates selfevaluation - by examining the feedback, students can evaluate for themselves if their answers are correct or not. (3) Students do not directly manipulate the feedback representation. Instead, the inputs are in a format that matches the domain learning goals. (4) The feedback conveys information about the nature of errors, not just that a particular action was incorrect. For example, the feedback may indicate the direction or magnitude of the error. Some prior experiments on systems with the four characteristics of grounded feedback found greater learning of target procedures (Nathan 1998) and greater transfer (Mathan \& Koedinger 20015), relative to robust controls. Over four studies with 4th and 5th graders, this thesis explores three tutor designs for fraction addition that incorporate visualizations of magnitude, including grounded feedback. Two studies of grounded feedback show effects of robust learning relative to correctness feedback, including greater future learning (in study 2) and transfer (in study 3). Another study found little difference between grounded feedback with and without correctness. In the last study, relative to correctness feedback, two implementations of dynamically linked concrete representations (variations on grounded feedback) showed greater robust learning (pre-test to delayed test). The correctness feedback tutor, used in three of these studies, is a high-bar control, including immediate step-level correctness feedback and adaptive on-demand hints. Indications of more robust learning with the grounded feedback tutor are promising, though not conclusive. Grounded feedback is intended to leverage concrete representations to elicit students’ prior knowledge of relevant concepts. Over two Difficulty Factor Assessments, 5th graders demonstrated difficulty incorporating magnitude information when evaluating fraction addition equations. In particular, students could generally evaluate an equation correctly when it was represented with fraction bars. However, including symbols with the bars interfered with students’ evaluations by triggering incorrect transfer from whole-number addition. Students also did not fully grasp that when two positive fractions are added, the resulting sum is bigger than each addend alone. These findings may help explain why the benefits of grounded feedback are not as strong as proponents of concrete representations might hope. Namely, the target population may not be able to take full advantage of the magnitude visualization because they lack pre-requisite knowledge of how fraction addition involves magnitude.},
	language = {en},
	urldate = {2019-02-25},
	author = {Wiese, Eliane},
	month = jul,
	year = {2018},
	doi = {10.1184/R1/6724007.v1},
}

@article{koedinger_real_2004,
	title = {The {Real} {Story} {Behind} {Story} {Problems}: {Effects} of {Representations} on {Quantitative} {Reasoning}},
	volume = {13},
	issn = {1050-8406},
	shorttitle = {The {Real} {Story} {Behind} {Story} {Problems}},
	url = {https://doi.org/10.1207/s15327809jls1302_1},
	doi = {10.1207/s15327809jls1302_1},
	abstract = {This article explores how differences in problem representations change both the performance and underlying cognitive processes of beginning algebra students engaged in quantitative reasoning. Contrary to beliefs held by practitioners and researchers in mathematics education, students were more successful solving simple algebra story problems than solving mathematically equivalent equations. Contrary to some views of situated cognition, this result is not simply a consequence of situated world knowledge facilitating problem-solving performance, but rather a consequence of student difficulties with comprehending the formal symbolic representation of quantitative relations. We draw on analyses of students' strategies and errors as the basis for a cognitive process explanation of when, why, and how differences in problem representation affect problem solving. We conclude that differences in external representations can affect performance and learning when one representation is easier to comprehend than another or when one representation elicits more reliable and meaningful solution strategies than another.},
	number = {2},
	urldate = {2018-11-07},
	journal = {Journal of the Learning Sciences},
	author = {Koedinger, Kenneth R. and Nathan, Mitchell J.},
	month = apr,
	year = {2004},
	keywords = {Mathematical Notation, Story Problem},
	pages = {129--164},
}

@book{schwartz_abcs_2016,
	title = {The {ABCs} of {How} {We} {Learn}: 26 {Scientifically} {Proven} {Approaches}, {How} {They} {Work}, and {When} to {Use} {Them}},
	isbn = {978-0-393-70940-7},
	shorttitle = {The {ABCs} of {How} {We} {Learn}},
	abstract = {Selected as one of NPR's Best Books of 2016, this book offers superior learning tools for teachers and students, from A to Z. An explosive growth in research on how people learn has revealed many ways to improve teaching and catalyze learning at all ages. The purpose of this book is to present this new science of learning so that educators can creatively translate the science into exceptional practice. The book is highly appropriate for the preparation and professional development of teachers and college faculty, but also parents, trainers, instructional designers, psychology students, and simply curious folks interested in improving their own learning.  Based on a popular Stanford University course, The ABCs of How We Learn uses a novel format that is suitable as both a textbook and a popular read. With everyday language, engaging examples, a sense of humor, and solid evidence, it describes 26 unique ways that students learn.  Each chapter offers a concise and approachable breakdown of one way people learn, how it works, how we know it works, how and when to use it, and what mistakes to avoid. The book presents learning research in a way that educators can creatively translate into exceptional lessons and classroom practice.  The book covers field-defining learning theories ranging from behaviorism (R is for Reward) to cognitive psychology (S is for Self-Explanation) to social psychology (O is for Observation). The chapters also introduce lesser-known theories exceptionally relevant to practice, such as arousal theory (X is for eXcitement). Together the theories, evidence, and strategies from each chapter can be combined endlessly to create original and effective learning plans and the means to know if they succeed.},
	language = {en},
	publisher = {W. W. Norton \& Company},
	author = {Schwartz, Daniel L. and Tsang, Jessica M. and Blair, Kristen P.},
	month = jul,
	year = {2016},
	note = {Google-Books-ID: GjOTCgAAQBAJ},
	keywords = {Education / Reference},
}

@inproceedings{abowd_teaching_1997,
	title = {Teaching and learning as multimedia authoring: the classroom 2000 project},
	shorttitle = {Teaching and learning as multimedia authoring},
	booktitle = {Proceedings of the fourth {ACM} international conference on {Multimedia}},
	publisher = {ACM},
	author = {Abowd, Gregory D. and Atkeson, Christopher G. and Feinstein, Ami and Hmelo, Cindy and Kooper, Rob and Long, Sue and Sawhney, Nitin and Tani, Mikiya},
	year = {1997},
	pages = {187--198},
}

@article{externalRepresentation,
	title = {Supporting the use of external representations in problem solving: {The} need for flexible learning environments},
	volume = {6},
	issn = {1043-1020(Print)},
	shorttitle = {Supporting the use of external representations in problem solving},
	abstract = {Investigated the use of multiple external representations (ERs) by 235 undergraduates in their solutions to analytical reasoning problems. Exp 1 consisted of a large corpus of ERs (workscratchings) in Ss' solutions to problems via paper and pencil tests. In Exp 2, data were collected using a computer-based system developed to study the process and time-course of ER use and the mechanisms (such as ER switching) by which Ss resolved impasses in reasoning. Results suggest that flexible environments are needed for supporting analytical reasoning with ERs. Ss' prior knowledge of ER formalisms was an important determinant of effective ER use. A review of research on individual differences in problem solving with ERs is also provided. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2-3},
	journal = {Journal of Artificial Intelligence in Education},
	author = {Cox, Richard and Brna, Paul},
	year = {1995},
	keywords = {Expert Systems, Graphical Displays, Inductive Deductive Reasoning, Language, Learning Environment, Problem Solving},
	pages = {239--302},
}

@book{hadamard_mathematicians_1945,
	title = {The {Mathematician}'s {Mind}: {The} {Psychology} of {Invention} in the {Mathematical} {Field}},
	url = {http://worrydream.com/refs/Hadamard%20-%20The%20psychology%20of%20invention%20in%20the%20mathematical%20field.pdf},
	abstract = {Fifty years ago when Jacques Hadamard set out to explore how mathematicians invent new ideas, he considered the creative experiences of some of the greatest thinkers of his generation, such as George Polya, Claude Lévi-Strauss, and Albert Einstein. It appeared that inspiration could strike anytime, particularly after an individual had worked hard on a problem for days and then turned attention to another activity. In exploring this phenomenon, Hadamard produced one of the most famous and cogent cases for the existence of unconscious mental processes in mathematical invention and other forms of creativity. Written before the explosion of research in computers and cognitive science, his book, originally titled The Psychology of Invention in the Mathematical Field, remains an important tool for exploring the increasingly complex problem of mental life. The roots of creativity for Hadamard lie not in consciousness, but in the long unconscious work of incubation, and in the unconscious aesthetic selection of ideas that thereby pass into consciousness. His discussion of this process comprises a wide range of topics, including the use of mental images or symbols, visualized or auditory words, "meaningless" words, logic, and intuition. Among the important documents collected is a letter from Albert Einstein analyzing his own mechanism of thought.},
	language = {en},
	urldate = {2019-02-14},
	publisher = {Princeton University Press},
	author = {Hadamard, Jacques},
	year = {1945},
}

@article{koedinger_knowledge-learning-instruction_2012,
	title = {The {Knowledge}-{Learning}-{Instruction} {Framework}: {Bridging} the {Science}-{Practice} {Chasm} to {Enhance} {Robust} {Student} {Learning}},
	volume = {36},
	copyright = {Copyright © 2012 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	shorttitle = {The {Knowledge}-{Learning}-{Instruction} {Framework}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1551-6709.2012.01245.x},
	doi = {10.1111/j.1551-6709.2012.01245.x},
	abstract = {Despite the accumulation of substantial cognitive science research relevant to education, there remains confusion and controversy in the application of research to educational practice. In support of a more systematic approach, we describe the Knowledge-Learning-Instruction (KLI) framework. KLI promotes the emergence of instructional principles of high potential for generality, while explicitly identifying constraints of and opportunities for detailed analysis of the knowledge students may acquire in courses. Drawing on research across domains of science, math, and language learning, we illustrate the analyses of knowledge, learning, and instructional events that the KLI framework affords. We present a set of three coordinated taxonomies of knowledge, learning, and instruction. For example, we identify three broad classes of learning events (LEs): (a) memory and fluency processes, (b) induction and refinement processes, and (c) understanding and sense-making processes, and we show how these can lead to different knowledge changes and constraints on optimal instructional choices.},
	language = {en},
	number = {5},
	urldate = {2018-11-12},
	journal = {Cognitive Science},
	author = {Koedinger, Kenneth R. and Corbett, Albert T. and Perfetti, Charles},
	month = jul,
	year = {2012},
	keywords = {Cognitive modeling, Cognitive task analysis, Education, Experimentation, Instructional principles, Knowledge representation, Learning principles},
	pages = {757--798},
}

@article{heffernan_assistments_2014,
	title = {The {ASSISTments} {Ecosystem}: {Building} a {Platform} that {Brings} {Scientists} and {Teachers} {Together} for {Minimally} {Invasive} {Research} on {Human} {Learning} and {Teaching}},
	volume = {24},
	issn = {1560-4306},
	shorttitle = {The {ASSISTments} {Ecosystem}},
	url = {https://doi.org/10.1007/s40593-014-0024-x},
	doi = {10.1007/s40593-014-0024-x},
	abstract = {The ASSISTments project is an ecosystem of a few hundred teachers, a platform, and researchers working together. Development professionals help train teachers and get teachers to participate in studies. The platform and these teachers help researchers (sometimes explicitly and sometimes implicitly) simply by using content the teacher selects. The platform, hosted by Worcester Polytechnic Institute, allows teachers to write individual ASSISTments (composed of questions with answers and associated hints, solutions, web-based videos, etc.) or to use pre-built ASSISTments, bundle them together in a problem set, and assign these to students. The system gives immediate feedback to students while they are working and provides student-level data to teachers on any assignment. The word “ASSISTments” blends tutoring “assistance” with “assessment” reporting to teachers and students. While originally focused on mathematics, the platform now has content from many other subjects (e.g., science, English, Statistics, etc.). Due to the large library of mathematics content, however, it is mostly used by math teachers. Over 50,000 students used ASSISTments last school year (2013–4) and this number has been doubling each year for the last 8 years. The platform allows any user, mostly researchers, to create randomized controlled trials in the content, which has helped us use the tool in over 18 published and an equal number of unpublished studies. The data collected by the system has also been used in a few dozen peer-reviewed data mining publications. This paper will not seek to review these publications, but instead we will share why ASSISTments has been successful and what lessons were learned along the way. The first lesson learned was to build a platform for learning sciences, not a product that focused on a math topic. That is, ASSISTments is a tool, not a curriculum. A second lesson learned is expressed by the mantra “Put the teacher in charge, not the computer.” This second lesson is about building a flexible system that allows teachers to use the tool in concert with the classroom routine. Once teachers are using the tool they are more likely to want to participate in research studies. These lessons were born from the design decisions about what the platform supports and does not support. In conclusion, goals for the future will be presented.},
	language = {en},
	number = {4},
	urldate = {2020-10-14},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Heffernan, Neil T. and Heffernan, Cristina Lindquist},
	month = dec,
	year = {2014},
	pages = {470--497},
}

@article{moreno_teaching_2011,
	title = {Teaching with concrete and abstract visual representations: effects on students’ problem solving, problem representations, and learning perceptions},
	shorttitle = {Teaching with concrete and abstract visual representations},
	abstract = {In 3 experiments, we examined the effects of using concrete and/or abstract visual problem representa-tions during instruction on students ’ problem-solving practice, near transfer, problem representations, and learning perceptions. In Experiments 1 and 2, novice students learned about electrical circuit analysis},
	journal = {Journal of Educational Psychology},
	author = {Moreno, Roxana and Ozogul, Gamze and Reisslein, Martin},
	year = {2011},
	pages = {32--47},
}

@article{matsuda_teaching_2015,
	title = {Teaching the {Teacher}: {Tutoring} {SimStudent} {Leads} to {More} {Effective} {Cognitive} {Tutor} {Authoring}},
	volume = {25},
	issn = {1560-4306},
	shorttitle = {Teaching the {Teacher}},
	url = {https://doi.org/10.1007/s40593-014-0020-1},
	doi = {10.1007/s40593-014-0020-1},
	abstract = {SimStudent is a machine-learning agent initially developed to help novice authors to create cognitive tutors without heavy programming. Integrated into an existing suite of software tools called Cognitive Tutor Authoring Tools (CTAT), SimStudent helps authors to create an expert model for a cognitive tutor by tutoring SimStudent on how to solve problems. There are two different ways to author an expert model with SimStudent. In the context of Authoring by Tutoring, the author interactively tutors SimStudent by posing problems to SimStudent, providing feedback on the steps performed by SimStudent, and also demonstrating steps as a response to SimStudent’s hint requests when SimStudent cannot perform steps correctly. In the context of Authoring by Demonstration, the author demonstrates solution steps, and SimStudent attempts to induce underlying domain principles by generalizing those worked-out examples. We conducted evaluation studies to investigate which authoring strategy better facilitates authoring and found two key results. First, the expert model generated with Authoring by Tutoring is better and has higher accuracy while maintaining the same level of completeness than the one generated with Authoring by Demonstration. The reason for this better accuracy is that the expert model generated by tutoring benefits from negative feedback provided for SimStudent’s incorrect production applications. Second, authoring by Tutoring requires less time than Authoring by Demonstration. This enhanced authoring efficiency is partially because (a) when Authoring by Demonstration, the author needs to test the quality of the expert model, whereas the formative assessment of the expert model is done naturally by observing SimStudent’s performance when Authoring by Tutoring, and (b) the number of steps that need to be demonstrated during tutoring decreases as learning progresses.},
	language = {en},
	number = {1},
	urldate = {2019-10-07},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Matsuda, Noboru and Cohen, William W. and Koedinger, Kenneth R.},
	month = mar,
	year = {2015},
	keywords = {Cognitive tutor authoring tools, Inductive logic programming, Intelligent authoring system, Machine learning, Programming by demonstration, SimStudent},
	pages = {1--34},
}

@article{polozov_personalized_2016,
	title = {Personalized {Mathematical} {Word} {Problem} {Generation}},
	url = {https://www.microsoft.com/en-us/research/publication/personalized-mathematical-word-problem-generation/},
	abstract = {Word problems are an established technique for teaching mathematical modeling skills in K-12 education. However, many students find word problems unconnected to their lives, artificial, and uninteresting. Most students find them much more difficult than the corresponding symbolic representations. To account for this phenomenon, an ideal pedagogy might involve an individually crafted progression of unique …},
	language = {en-US},
	urldate = {2018-11-07},
	journal = {IJCAI 2015},
	author = {Polozov, Oleksandr and O’Rourke, Eleanor and Smith, Adam M. and Zettlemoyer, Luke and Gulwani, Sumit and Popović, Zoran},
	month = dec,
	year = {2016},
	keywords = {Answer Set Programming, Word problems},
}

@book{dorier_teaching_2000,
	address = {Dordrecht ;},
	series = {Mathematics education library ; v. 23},
	title = {On the teaching of linear algebra},
	isbn = {978-1-280-20772-3},
	url = {http://ebookcentral.proquest.com/lib/cm/detail.action?docID=3035352},
	abstract = {To a large extent, it lies, no doubt, in what is presented in this work under the title of ‘meta lever‘, a method which it is certainly interesting to develop and further refine. There exists in mathematics courses a strange prudery which forbids one to ask questions such as, ‹‹ Why are we doing this? », ‹‹ At what is the objective aimed? », whereas it is usually easy to reply to such questions, to keep them in mind, and to show that one can challenge these questions and modify the objectives to be more productive or more useful. If we don‘t do this we give a false impression of a gratuitous or arbitrary interpretation of a discipline whose rules are far from being unmotivated or unfounded. One must also consider the time aspect. Simple ideas take a long time to be conceived. Should we not therefore allow the students time to familiarize themselves with new notions? And must we not also recognize that this length of time is generally longer than that of the official length of time accorded to this teaching and that we should be counting in years? When the rudiments of linear algebra were taught at the level of the lycée (college level), the task of first year university teachers was certainly easier : for sure the student's knowledge was not very deep, however it was not negligible and it allowed them to reach a deeper understanding more quickly.},
	language = {eng},
	publisher = {Kluwer Academic Publishers},
	author = {Dorier, Jean-Luc},
	year = {2000},
	keywords = {Algebras, Linear Study and teaching., Electronic books.},
}

@incollection{dorier_research_2002,
	address = {Dordrecht},
	series = {New {ICMI} {Study} {Series}},
	title = {Research into the {Teaching} and {Learning} of {Linear} {Algebra}},
	isbn = {978-0-306-47231-2},
	url = {https://doi.org/10.1007/0-306-47231-7_24},
	language = {en},
	urldate = {2019-02-25},
	booktitle = {The {Teaching} and {Learning} of {Mathematics} at {University} {Level}: {An} {ICMI} {Study}},
	publisher = {Springer Netherlands},
	author = {Dorier, Jean-Luc and Sierpinska, Anna},
	editor = {Holton, Derek and Artigue, Michèle and Kirchgräber, Urs and Hillel, Joel and Niss, Mogens and Schoenfeld, Alan},
	year = {2002},
	doi = {10.1007/0-306-47231-7_24},
	keywords = {Axiomatic Approach, Dynamic Geometry Environment, Linear Algebra, Semiotic Representation, Vector Space},
	pages = {255--273},
}

@article{funt_problem-solving_1980,
	title = {Problem-solving with diagrammatic representations},
	volume = {13},
	issn = {00043702},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0004370280900028},
	doi = {10.1016/0004-3702(80)90002-8},
	abstract = {Diagrams are of substantial benefit to WHISPER, a computer problem-solving system, in testing the stability of a "'blocks world" structure and predicting the event sequences which occur as that structure collapses. WHISPER's components include a high level reasoner which knows some qualitative aspects of Physics, a simulated parallel processing "retina" to "look at" its diagrams, and a set of re-drawing procedures for modifying these diagrams. Roughly modelled after the human eye, WHISPER's retina can fixate at any diagram location, and its resolution decreases away from its center. Diagrams enable WHISPER to work with objects of arbitrary shape, detect collisions and other motion discontinuities, discover coincidental alignments, and easily update its world model after a state change. A theoretical analysis is made of the role of diagrams interacting with, a general deductive mechanism such as WHISPER's high level reasoner.},
	language = {en},
	number = {3},
	urldate = {2019-05-11},
	journal = {Artificial Intelligence},
	author = {Funt, Brian V.},
	month = may,
	year = {1980},
	pages = {201--230},
}

@article{sierpinska_one_nodate,
	title = {On one persistent mistake in linear algebra},
	url = {https://www.academia.edu/6988644/On_one_persistent_mistake_in_linear_algebra},
	abstract = {On one persistent mistake in linear algebra},
	language = {en},
	urldate = {2019-02-25},
	journal = {Proceedings of the 18th International Conference on the Psychology of Mathematics Education, Lisbon, August 1994., Vol.III 65-72.},
	author = {Sierpinska, Anna},
}

@article{mayer_nine_2003,
	title = {Nine {Ways} to {Reduce} {Cognitive} {Load} in {Multimedia} {Learning}},
	volume = {38},
	issn = {0046-1520},
	url = {https://doi.org/10.1207/S15326985EP3801_6},
	doi = {10.1207/S15326985EP3801_6},
	abstract = {First, we propose a theory of multimedia learning based on the assumptions that humans possess separate systems for processing pictorial and verbal material (dual-channel assumption), each channel is limited in the amount of material that can be processed at one time (limited-capacity assumption), and meaningful learning involves cognitive processing including building connections between pictorial and verbal representations (active-processing assumption). Second, based on the cognitive theory of multimedia learning, we examine the concept of cognitive overload in which the learner's intended cognitive processing exceeds the learner's available cognitive capacity. Third, we examine five overload scenarios. For each overload scenario, we offer one or two theory-based suggestions for reducing cognitive load, and we summarize our research results aimed at testing the effectiveness of each suggestion. Overall, our analysis shows that cognitive load is a central consideration in the design of multimedia instruction.},
	number = {1},
	urldate = {2021-02-26},
	journal = {Educational Psychologist},
	author = {Mayer, Richard E. and Moreno, Roxana},
	month = mar,
	year = {2003},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/S15326985EP3801\_6},
	pages = {43--52},
}

@inproceedings{lemke_multiplying_1998,
	title = {Multiplying meaning: {Visual} and verbal semiotics in scientific text},
	shorttitle = {Multiplying meaning},
	author = {Lemke, Jay L.},
	year = {1998},
	keywords = {Semiotics},
}

@incollection{linAlgRepProblem,
	address = {Dordrecht},
	series = {Mathematics {Education} {Library}},
	title = {Modes of {Description} and the {Problem} of {Representation} in {Linear} {Algebra}},
	isbn = {978-0-306-47224-4},
	url = {https://doi.org/10.1007/0-306-47224-4_7},
	language = {en},
	urldate = {2019-05-13},
	booktitle = {On the {Teaching} of {Linear} {Algebra}},
	publisher = {Springer Netherlands},
	author = {Hillel, Joel},
	editor = {Dorier, Jean-Luc},
	year = {2000},
	doi = {10.1007/0-306-47224-4_7},
	keywords = {Coordinate Vector, Linear Algebra, Linear Operator, Matrix Representation, Scalar Multiplication},
	pages = {191--207},
}

@article{disessa_metarepresentation_2004,
	title = {Metarepresentation: {Native} {Competence} and {Targets} for {Instruction}},
	volume = {22},
	issn = {0737-0008},
	shorttitle = {Metarepresentation},
	url = {https://doi.org/10.1207/s1532690xci2203_2},
	doi = {10.1207/s1532690xci2203_2},
	abstract = {The premise of this article is that the study of representation is valuable and important for mathematics and science students. Learning about representation should go beyond learning specific, sanctioned representations emphasized in standard curricula (graphs, tables, etc.) to include principles and design strategies that apply to any scientific representation, including novel variations and even completely new representations. The article explores what it means to understand representation, what we believe students already know about the topic, and what they can profitably learn about it. The discussion includes learning difficulties-goals for instruction that appear challenging for students and may need particular attention.},
	number = {3},
	urldate = {2019-11-05},
	journal = {Cognition and Instruction},
	author = {diSessa, Andrea A.},
	month = sep,
	year = {2004},
	pages = {293--331},
}

@article{lowe_mental_1987,
	title = {Mental representation and diagram interpretation},
	volume = {14},
	number = {1},
	journal = {The Australian Educational Researcher},
	author = {Lowe, Richard K.},
	year = {1987},
	pages = {37--50},
}

@book{sen_machine_2018,
	title = {Machine {Beats} {Human} at {Sequencing} {Visuals} for {Perceptual}-{Fluency} {Practice}},
	url = {https://eric.ed.gov/?id=ED593113},
	abstract = {In STEM domains, students are expected to acquire domain knowledge from visual representations that they may not yet be able to interpret. Such learning requires perceptual fluency: the ability to intuitively and rapidly see which concepts visuals show and to translate among multiple visuals. Instructional problems that engage students in nonverbal, implicit learning processes enhance perceptual fluency. Such processes are highly influenced by sequence effects. Thus far, we lack a principled approach for identifying a sequence of perceptual-fluency problems that promote robust learning. Here, we describe a novel educational data mining approach that uses machine learning to generate an optimal sequence of visuals for perceptual-fluency problems. In a human experiment, we show that a machine-generated sequence outperforms both a random sequence and a sequence generated by a human domain expert. Interestingly, the machine-generated sequence resulted in significantly lower accuracy during training, but higher posttest accuracy. This suggests that the machine-generated sequence induced desirable difficulties. To our knowledge, our study is the first to show that an educational data mining approach can induce desirable difficulties for perceptual learning. [For the full proceedings, see ED593090.]},
	language = {en},
	urldate = {2020-10-02},
	publisher = {International Educational Data Mining Society},
	author = {Sen, Ayon and Patel, Purav and Rau, Martina A. and Mason, Blake and Nowak, Robert and Rogers, Timothy T. and Zhu, Xiaojin},
	month = jul,
	year = {2018},
	note = {Publication Title: International Educational Data Mining Society},
	keywords = {Accuracy, Artificial Intelligence, Data Analysis, Difficulty Level, Instructional Effectiveness, Perceptual Development, STEM Education, Sequential Learning, Visual Aids, Visual Perception},
}

@misc{noauthor_learn_nodate,
	title = {Learn to {Code} with {Interactive} {Tutorials}},
	url = {https://scrimba.com/},
	abstract = {Scrimba is a fun and fast way of learning to code! Our interactive courses and tutorials will teach you React, Vue, Angular, JavaScript, HTML, CSS, and more.},
	urldate = {2019-07-21},
	journal = {Scrimba},
}

@article{meiers_language_2010,
	title = {Language in the mathematics classroom},
	url = {https://works.bepress.com/marion_meiers/41/},
	abstract = {Berkeley Electronic Press Selected Works, This Digest is focused on research studies about language in the mathematics classroom. A selection of websites is listed and a full reference list provided. Links to those references for which full-text online access is freely available are also included.},
	language = {en},
	number = {2},
	urldate = {2018-11-07},
	author = {Meiers, Marion},
	year = {2010},
	keywords = {Second Language},
}

@article{gigerenzer_how_1995,
	title = {How to improve {Bayesian} reasoning without instruction: {Frequency} formats},
	volume = {102},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	shorttitle = {How to improve {Bayesian} reasoning without instruction},
	doi = {10.1037/0033-295X.102.4.684},
	abstract = {Is the mind, by design, predisposed against performing Bayesian inference? Previous research on base rate neglect suggests that the mind lacks the appropriate cognitive algorithms. However, any claim against the existence of an algorithm, Bayesian or otherwise, is impossible to evaluate unless one specifies the information format in which it is designed to operate. The authors show that Bayesian algorithms are computationally simpler in frequency formats than in the probability formats used in previous research. Frequency formats correspond to the sequential way information is acquired in natural sampling, from animal foraging to neural networks. By analyzing several thousand solutions to Bayesian problems, the authors found that when information was presented in frequency formats, statistically naive participants derived up to 50\% of all inferences by Bayesian algorithms. Non-Bayesian algorithms included simple versions of Fisherian and Neyman-Pearsonian inference. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Psychological Review},
	author = {Gigerenzer, Gerd and Hoffrage, Ulrich},
	year = {1995},
	keywords = {Algorithms, Cognitive Processes, Frequency Distribution, Inference, Reasoning, Statistical Probability},
	pages = {684--704},
}

@article{nathan_expert_2001,
	title = {Expert blind spot: {When} content knowledge eclipses pedagogical content knowledge. {Paper} presented at the {Annual} {Meeting} of the {American} {Educational} {Research} {Association}},
	shorttitle = {Expert blind spot},
	url = {http://citeseerx.ist.psu.edu/viewdoc/citations;jsessionid=3733E4D0B18D59C9FFC3B012B2E3799C?doi=10.1.1.352.8217},
	abstract = {The importance of content knowledge on proficiency in teaching practices is well documented (Borko et al., 1992; Shulman, 1986). But is this statement completely unimpeachable? Are there drawbacks for teaching that are specifically due to subject matter expertise? In this paper we draw on evidence from mathematics and language arts education to show ways that advanced knowledge in a content area can lead to notions about learning that are in conflict with students ’ actual developmental processes. This underscores the need for empirically based theories of instruction, and for teachers to integrate assessment practices in their classroom curricula that have the potential to challenge their assumptions about mathematical development in their students. THE NATURE OF EXPERTISE Before the launching of the cognitive science research program in the 1950’s, experts were considered to be a different breed from others. They were regarded as more intelligent, with greater memory capacity, and superior intellectual resources (Ericsson \& Smith, 1991). However, careful research into},
	language = {en},
	urldate = {2018-11-12},
	journal = {The Proceedings of the Third International Conference on Cognitive Science},
	author = {Nathan, Mitchell J. and Koedinger, Kenneth R. and Alibali, Martha W.},
	year = {2001},
	pages = {644--648},
}

@article{aleven_example-tracing_2016,
	title = {Example-{Tracing} {Tutors}: {Intelligent} {Tutor} {Development} for {Non}-programmers},
	volume = {26},
	issn = {1560-4306},
	shorttitle = {Example-{Tracing} {Tutors}},
	url = {https://doi.org/10.1007/s40593-015-0088-2},
	doi = {10.1007/s40593-015-0088-2},
	abstract = {In 2009, we reported on a new Intelligent Tutoring Systems (ITS) technology, example-tracing tutors, that can be built without programming using the Cognitive Tutor Authoring Tools (CTAT). Creating example-tracing tutors was shown to be 4–8 times as cost-effective as estimates for ITS development from the literature. Since 2009, CTAT and its associated learning management system, the Tutorshop, have been extended and have been used for both research and real-world instruction. As evidence that example-tracing tutors are an effective and mature ITS paradigm, CTAT-built tutors have been used by approximately 44,000 students and account for 40 \% of the data sets in DataShop, a large open repository for educational technology data sets. We review 18 example-tracing tutors built since 2009, which have been shown to be effective in helping students learn in real educational settings, often with large pre/post effect sizes. These tutors support a variety of pedagogical approaches, beyond step-based problem solving, including collaborative learning, educational games, and guided invention activities. CTAT and other ITS authoring tools illustrate that non-programmer approaches to building ITS are viable and useful and will likely play a key role in making ITS widespread.},
	language = {en},
	number = {1},
	urldate = {2020-10-02},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Aleven, Vincent and McLaren, Bruce M. and Sewall, Jonathan and van Velsen, Martin and Popescu, Octav and Demi, Sandra and Ringenberg, Michael and Koedinger, Kenneth R.},
	month = mar,
	year = {2016},
	pages = {224--269},
}

@article{cuevas_mathematics_1984,
	title = {Mathematics {Learning} in {English} as a {Second} {Language}},
	volume = {15},
	issn = {0021-8251},
	url = {https://www.jstor.org/stable/748889},
	doi = {10.2307/748889},
	abstract = {When the language of instruction is English, the learning of mathematics by students for whom English is a second language raises some important issues. The complex process of learning a second language becomes especially difficult when the language forms learned first are those of the classroom. The learning of mathematics requires a variety of linguistic skills that second-language learners may not have mastered. Furthermore, special problems of reliability and validity arise in assessing the mathematics achievement of students from a language minority. A mathematics curriculum is needed that would develop second-language skills, and more research is needed into the relation between second-language learning and mathematics learning.},
	number = {2},
	urldate = {2018-11-07},
	journal = {Journal for Research in Mathematics Education},
	author = {Cuevas, Gilberto J.},
	year = {1984},
	keywords = {Second Language},
	pages = {134--144},
}

@article{electrifyDiagrams,
	title = {Electrifying diagrams for learning: principles for complex representational systems},
	volume = {26},
	issn = {0364-0213},
	shorttitle = {Electrifying diagrams for learning},
	url = {http://www.sciencedirect.com/science/article/pii/S0364021302000861},
	doi = {10.1016/S0364-0213(02)00086-1},
	abstract = {Six characteristics of effective representational systems for conceptual learning in complex domains have been identified. Such representations should: (1) integrate levels of abstraction; (2) combine globally homogeneous with locally heterogeneous representation of concepts; (3) integrate alternative perspectives of the domain; (4) support malleable manipulation of expressions; (5) possess compact procedures; and (6) have uniform procedures. The characteristics were discovered by analysing and evaluating a novel diagrammatic representation that has been invented to support students’ comprehension of electricity—AVOW diagrams (Amps, Volts, Ohms, Watts). A task analysis is presented that demonstrates that problem solving using a conventional algebraic approach demands more effort than AVOW diagrams. In an experiment comparing two groups of learners using the alternative approaches, the group using AVOW diagrams learned more than the group using equations and were better able to solve complex transfer problems and questions involving multiple constraints. Analysis of verbal protocols and work scratchings showed that the AVOW diagram group, in contrast to the equations group, acquired a coherently organised network of concepts, learnt effective problem solving procedures, and experienced more positive learning events. The six principles of effective representations were proposed on the basis of these findings. AVOW diagrams are Law Encoding Diagrams, a general class of representations that have been shown to support learning in other scientific domains.},
	number = {6},
	urldate = {2019-05-16},
	journal = {Cognitive Science},
	author = {Cheng, Peter C. -H.},
	month = nov,
	year = {2002},
	keywords = {Conceptual learning, Diagrams, Electricity, Problem solving, Representations, Science education, Task analysis},
	pages = {685--736},
}

@article{ainsworth_drawing_2011,
	title = {Drawing to learn in science},
	volume = {333},
	issn = {1095-9203(Electronic),0036-8075(Print)},
	doi = {10.1126/science.1204153},
	abstract = {Making visualizations is integral to scientific thinking. Scientists do not use words only but rely on diagrams, graphs, videos, photographs, and other images to make discoveries, explain findings, and excite public interest. However, in the science classroom, learners mainly focus on interpreting others' visualizations; when drawing does occur, it is rare that learners are systematically encouraged to create their own visual forms to develop and show understanding. Drawing includes constructing a line graph from a table of values, sketching cells observed through a microscope, or inventing a way to show a scientific phenomenon (e.g., evaporation). In this article, we suggest five reasons why student drawing should be explicitly recognized alongside writing, reading, and talking as a key element in science education. We offer distinct rationales, although in practice any single drawing activity will likely rest upon multiple justifications. Both old and new technologies offer exciting opportunities. We conclude by highlighting important questions yet to be answered and key future research to extend teachers' and learners' use of drawing. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
	number = {6046},
	journal = {Science},
	author = {Ainsworth, Shaaron and Prain, Vaughan and Tytler, Russell},
	year = {2011},
	keywords = {Classrooms, Drawing, Imagery, Learning, Science Education, Teaching},
	pages = {1096--1097},
}

@book{lehrer_designing_1998,
	title = {Designing {Learning} {Environments} for {Developing} {Understanding} of {Geometry} and {Space}},
	isbn = {978-0-8058-1948-9},
	abstract = {This volume reflects an appreciation of the interactive roles of subject matter, teacher, student, and technologies in designing classrooms that promote understanding of geometry and space. Although these elements of geometry education are mutually constituted, the book is organized to highlight, first, the editors' vision of a general geometry education; second, the development of student thinking in everyday and classroom contexts; and third, the role of technologies.  Rather than looking to high school geometry as the locus--and all too often, the apex--of geometric reasoning, the contributors to this volume suggest that reasoning about space can and should be successfully integrated with other forms of mathematics, starting at the elementary level and continuing through high school. Reintegrating spatial reasoning into the mathematical mainstream--indeed, placing it at the core of K-12 mathematics environments that promote learning with understanding--will mean increased attention to problems in modeling, structure, and design and reinvigoration of traditional topics such as measure, dimension, and form. Further, the editors' position is that the teaching of geometry and spatial visualization in school should not be compressed into a characterization of Greek geometry, but should include attention to contributions to the mathematics of space that developed subsequent to those of the Greeks.  This volume is essential reading for those involved in mathematics education at all levels, including university faculty, researchers, and graduate students.},
	language = {en},
	publisher = {Routledge},
	author = {Lehrer, Richard and Chazan, Daniel},
	year = {1998},
	note = {Google-Books-ID: 7sAb\_3WeAUMC},
	keywords = {Mathematics / Geometry / General},
}

@article{wiese_designing_2017,
	title = {Designing {Grounded} {Feedback}: {Criteria} for {Using} {Linked} {Representations} to {Support} {Learning} of {Abstract} {Symbols}},
	volume = {27},
	issn = {1560-4306},
	shorttitle = {Designing {Grounded} {Feedback}},
	url = {https://doi.org/10.1007/s40593-016-0133-9},
	doi = {10.1007/s40593-016-0133-9},
	abstract = {This paper proposes grounded feedback as a way to provide implicit verification when students are working with a novel representation. In grounded feedback, students’ responses are in the target, to-be-learned representation, and those responses are reflected in a more-accessible linked representation that is intrinsic to the domain. By examining the accessible feedback representation, students can infer if their work with the novel representation is correct. This paper presents the criteria for grounded feedback, provides examples of systems that implement grounded feedback, contrasts grounded feedback with similar feedback types, and discusses the evidence for grounded feedback’s effectiveness. Controlled experiments with random assignment that compare grounded feedback to other approaches are limited in number and scope (i.e., comparisons to explicit verification with and without text hints, linked representations, and no feedback). The two experiments we found with full implementation of grounded feedback and a sample size larger than 20 found robust learning benefits of grounded feedback over explicit verification feedback. These results are promising and indicate that grounded feedback warrants further investigation.},
	language = {en},
	number = {3},
	urldate = {2019-05-11},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Wiese, Eliane S. and Koedinger, Kenneth R.},
	month = sep,
	year = {2017},
	keywords = {Designing interactive learning environments, Feedback, Grounded feedback, Multiple representations},
	pages = {448--474},
}

@article{representationalFlexibility,
	title = {Conceptualising, investigating and stimulating representational flexibility in mathematical problem solving and learning: a critical review},
	volume = {41},
	issn = {1863-9704},
	shorttitle = {Conceptualising, investigating and stimulating representational flexibility in mathematical problem solving and learning},
	url = {https://doi.org/10.1007/s11858-009-0189-1},
	doi = {10.1007/s11858-009-0189-1},
	language = {en},
	number = {5},
	urldate = {2019-05-11},
	journal = {ZDM},
	author = {Acevedo Nistal, Ana and Van Dooren, W. and Clarebout, G. and Elen, J. and Verschaffel, L.},
	month = oct,
	year = {2009},
	keywords = {Adaptivity, Choice, Flexibility, Multiple external representations},
	pages = {627--636},
}

@article{de_freitas_diagram_2012,
	title = {Diagram, gesture, agency: theorizing embodiment in the mathematics classroom},
	volume = {80},
	issn = {1573-0816},
	shorttitle = {Diagram, gesture, agency},
	url = {https://doi.org/10.1007/s10649-011-9364-8},
	doi = {10.1007/s10649-011-9364-8},
	abstract = {In this paper, we use the work of philosopher Gilles Châtelet to rethink the gesture/diagram relationship and to explore the ways mathematical agency is constituted through it. We argue for a fundamental philosophical shift to better conceptualize the relationship between gesture and diagram, and suggest that such an approach might open up new ways of conceptualizing the very idea of mathematical embodiment. We draw on contemporary attempts to rethink embodiment, such as Rotman’s work on a “material semiotics,” Radford’s work on “sensuous cognition”, and Roth’s work on “material phenomenology”. After discussing this work and its intersections with that of Châtelet, we discuss data collected from a research experiment as a way to demonstrate the viability of this new theoretical framework.},
	language = {en},
	number = {1},
	urldate = {2019-09-24},
	journal = {Educational Studies in Mathematics},
	author = {de Freitas, Elizabeth and Sinclair, Nathalie},
	month = may,
	year = {2012},
	keywords = {Agency, Diagram, Embodiment, Gesture},
	pages = {133--152},
}

@inproceedings{aleven_bringing_2016,
	address = {New York, NY, USA},
	series = {L@{S} '16},
	title = {Bringing {Non}-programmer {Authoring} of {Intelligent} {Tutors} to {MOOCs}},
	isbn = {978-1-4503-3726-7},
	url = {https://doi.org/10.1145/2876034.2893442},
	doi = {10.1145/2876034.2893442},
	abstract = {Learning-by-doing in MOOCs may be enhanced by embedding intelligent tutoring systems (ITSs). ITSs support learning-by-doing by guiding learners through complex practice problems while adapting to differences among learners. We extended the Cognitive Tutor Authoring Tools (CTAT), a widely-used non-programmer tool kit for building intelligent tutors, so that CTAT-built tutors can be embedded in MOOCs and e-learning platforms. We demonstrated the technical feasibility of this integration by adding simple CTAT-built tutors to an edX MOOC, "Big Data in Education." To the best of our knowledge, this integration is the first occasion that material created through an open-access non-programmer authoring tool for full-fledged ITS has been integrated in a MOOC. The work offers examples of key steps that may be useful in other ITS-MOOC integration efforts, together with reflections on strengths, weaknesses, and future possibilities.},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the {Third} (2016) {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {Association for Computing Machinery},
	author = {Aleven, Vincent and Baker, Ryan and Wang, Yuan and Sewall, Jonathan and Popescu, Octav},
	month = apr,
	year = {2016},
	keywords = {feasibility study, intelligent tutoring systems, interoperability, itss, log data analysis, moocs},
	pages = {313--316},
}

@inproceedings{weitekamp_interaction_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {An {Interaction} {Design} for {Machine} {Teaching} to {Develop} {AI} {Tutors}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376226},
	doi = {10.1145/3313831.3376226},
	abstract = {Intelligent tutoring systems (ITSs) have consistently been shown to improve the educational outcomes of students when used alone or combined with traditional instruction. However, building an ITS is a time-consuming process which requires specialized knowledge of existing tools. Extant authoring methods, including the Cognitive Tutor Authoring Tools' (CTAT) example-tracing method and SimStudent's Authoring by Tutoring, use programming-by-demonstration to allow authors to build ITSs more quickly than they could by hand programming with model-tracing. Yet these methods still suffer from long authoring times or difficulty creating complete models. In this study, we demonstrate that Simulated Learners built with the Apprentice Learner (AL) Framework can be combined with a novel interaction design that emphasizes model transparency, input flexibility, and problem solving control to enable authors to achieve greater model completeness in less time than existing authoring methods.},
	urldate = {2020-10-06},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Weitekamp, Daniel and Harpstead, Erik and Koedinger, Ken R.},
	month = apr,
	year = {2020},
	keywords = {intelligent tutoring systems, interaction design, machine teaching, programming-by-demonstration, \{\vphantom{\}}simulated learners},
	pages = {1--11},
}

@article{zambo_adding_2002,
	title = {Adding it {UP}: {Helping} {Children} {Learn} {Mathematics}},
	volume = {9},
	copyright = {Copyright National Council of Teachers of Mathematics Oct 2002},
	issn = {10735836},
	shorttitle = {Adding it {UP}},
	url = {https://search.proquest.com/docview/214136843/abstract/18B1F325AA204009PQ/1},
	abstract = {"Adding It Up: Helping Children Learn Mathematics," edited by Jeremy Kilpatrick, Jane Swafford and Bradford Findell, is reviewed.},
	language = {English},
	number = {2},
	urldate = {2019-02-14},
	journal = {Teaching Children Mathematics; Reston},
	author = {Zambo, Ron},
	month = oct,
	year = {2002},
	keywords = {Education--Teaching Methods And Curriculum, Educators, Mathematics, Mathematics education, Nonfiction},
	pages = {126--127},
}

@article{gagatsis_ability_2004,
	title = {Ability to {Translate} from {One} {Representation} of the {Concept} of {Function} to {Another} and {Mathematical} {Problem} {Solving}},
	volume = {24},
	issn = {0144-3410},
	abstract = {Representations are used extensively in mathematics and translation ability is highly correlated with success in mathematics education. The authors investigate the translation ability of university students as far as the concept of function is concerned. The research focuses on the relationship between success in, solving direct translation tasks and success in solving problems by articulating different representations of the concept of function. Furthermore, it examines the relationship between student performance and the nature of the representation included in the translation task. The ability to pass from one representation to another was associated with success in problem solving. These results indicate that translation ability should be considered as an important factor in problem solving. Percentages are lower when an iconic representation is included in the translation task. This could be partly attributed to the holistic nature of iconic representations and to the way the concept of function is taught at secondary schools.},
	language = {en},
	number = {5},
	urldate = {2019-05-11},
	journal = {Educational Psychology},
	author = {Gagatsis, Athanasios and Shiakalli, Myria},
	month = oct,
	year = {2004},
	keywords = {Mathematics Achievement, Mathematics Education, Problem Solving},
	pages = {645--657},
}

@inproceedings{andersen_trace-based_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {A trace-based framework for analyzing and synthesizing educational progressions},
	isbn = {978-1-4503-1899-0},
	url = {https://doi.org/10.1145/2470654.2470764},
	doi = {10.1145/2470654.2470764},
	abstract = {A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.},
	urldate = {2020-10-14},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Andersen, Erik and Gulwani, Sumit and Popovic, Zoran},
	month = apr,
	year = {2013},
	keywords = {education, execution traces, games, problem generation},
	pages = {773--782},
}

@misc{noauthor_tour_nodate,
	title = {A {Tour} of {Go}},
	url = {https://tour.golang.org/welcome/1},
	urldate = {2019-07-21},
}

@inproceedings{nguyen_graph-based_2019,
	title = {Graph-{Based} {Mining} of {In}-the-{Wild}, {Fine}-{Grained}, {Semantic} {Code} {Change} {Patterns}},
	doi = {10.1109/ICSE.2019.00089},
	abstract = {Prior research exploited the repetitiveness of code changes to enable several tasks such as code completion, bug-fix recommendation, library adaption, etc. These and other novel applications require accurate detection of semantic changes, but the state-of-the-art methods are limited to algorithms that detect specific kinds of changes at the syntactic level. Existing algorithms relying on syntactic similarity have lower accuracy, and cannot effectively detect semantic change patterns. We introduce a novel graph-based mining approach, CPatMiner, to detect previously unknown repetitive changes in the wild, by mining fine-grained semantic code change patterns from a large number of repositories. To overcome unique challenges such as detecting meaningful change patterns and scaling to large repositories, we rely on fine-grained change graphs to capture program dependencies. We evaluate CPatMiner by mining change patterns in a diverse corpus of 5,000+ open-source projects from GitHub across a population of 170,000+ developers. We use three complementary methods. First, we sent the mined patterns to 108 open-source developers. We found that 70\% of respondents recognized those patterns as their meaningful frequent changes. Moreover, 79\% of respondents even named the patterns, and 44\% wanted future IDEs to automate such repetitive changes. We found that the mined change patterns belong to various development activities: adaptive (9\%), perfective (20\%), corrective (35\%) and preventive (36\%, including refactorings). Second, we compared our tool with the state-of-the-art, AST-based technique, and reported that it detects 2.1x more meaningful patterns. Third, we use CPatMiner to search for patterns in a corpus of 88 GitHub projects with longer histories consisting of 164M SLOCs. It constructed 322K fine-grained change graphs containing 3M nodes, and detected 17K instances of change patterns from which we provide unique insights on the practice of change patterns among individuals and teams. We found that a large percentage (75\%) of the change patterns from individual developers are commonly shared with others, and this holds true for teams. Moreover, we found that the patterns are not intermittent but spread widely over time. Thus, we call for a community-based change pattern database to provide important resources in novel applications.},
	booktitle = {2019 {IEEE}/{ACM} 41st {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Nguyen, H. A. and Nguyen, T. N. and Dig, D. and Nguyen, S. and Tran, H. and Hilton, M.},
	month = may,
	year = {2019},
	note = {ISSN: 1558-1225},
	keywords = {AST-based technique, Computer science, Data mining, GitHub projects, Open source software, Semantic Change Pattern Mining, Graph Mining, Semantics, Syntactics, Task analysis, Tools, code changes, community-based change pattern database, data mining, fine-grained change, fine-grained semantic code change patterns, graph theory, graph-based mining, mined change patterns, program diagnostics, semantic change patterns, software engineering},
	pages = {819--830},
}

@misc{noauthor_toward_nodate,
	title = {Toward an exploratory medium for mathematics},
	url = {http://cognitivemedium.com/emm/emm.html},
	urldate = {2021-03-02},
}

@misc{noauthor_expressive_nodate,
	title = {On the expressive power of programming languages - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/016764239190036W},
	urldate = {2021-02-20},
}

@misc{noauthor_are_nodate,
	title = {Are diagrams always helpful tools? {Developmental} and individual differences in the effect of presentation format on student problem solving - {Booth} - 2012 - {British} {Journal} of {Educational} {Psychology} - {Wiley} {Online} {Library}},
	url = {https://bpspsychub.onlinelibrary.wiley.com/doi/full/10.1111/j.2044-8279.2011.02041.x?casa_token=bhfbt1ToGpQAAAAA%3AnyYUhdj9VLMUR2ZKOj7GgwVhSdZx6hHkYBfHcGjC01B6DXxxMiHyRCFHJTd7Wby-zYzTeIz7ClaXToI},
	urldate = {2021-01-27},
}

@misc{noauthor_emina_nodate,
	title = {Emina {Torlak}: {About}},
	url = {https://homes.cs.washington.edu/~emina/index.html},
	urldate = {2020-09-22},
}

@inproceedings{tao_how_2012,
	address = {Cary, North Carolina},
	series = {{FSE} '12},
	title = {How do software engineers understand code changes? an exploratory study in industry},
	isbn = {9781450316149},
	shorttitle = {How do software engineers understand code changes?},
	url = {https://doi.org/10.1145/2393596.2393656},
	doi = {10.1145/2393596.2393656},
	abstract = {Software evolves with continuous source-code changes. These code changes usually need to be understood by software engineers when performing their daily development and maintenance tasks. However, despite its high importance, such change-understanding practice has not been systematically studied. Such lack of empirical knowledge hinders attempts to evaluate this fundamental practice and improve the corresponding tool support. To address this issue, in this paper, we present a large-scale quantitative and qualitative study at Microsoft. The study investigates the role of understanding code changes during software-development process, explores engineers' information needs for understanding changes and their requirements for the corresponding tool support. The study results reinforce our beliefs that understanding code changes is an indispensable task performed by engineers in software-development process. A number of insufficiencies in the current practice also emerge from the study results. For example, it is difficult to acquire important information needs such as a change's completeness, consistency, and especially the risk imposed by it on other software components. In addition, for understanding a composite change, it is valuable to decompose it into sub-changes that are aligned with individual development issues; however, currently such decomposition lacks tool support.},
	urldate = {2020-07-08},
	booktitle = {Proceedings of the {ACM} {SIGSOFT} 20th {International} {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Tao, Yida and Dang, Yingnong and Xie, Tao and Zhang, Dongmei and Kim, Sunghun},
	month = nov,
	year = {2012},
	keywords = {code change, code review, information needs, tool support},
	pages = {1--11},
}

@misc{noauthor_write-only_2019,
	title = {Write-only language},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Write-only_language&oldid=916551648},
	abstract = {In computer humor, a write-only language is a pejorative term for a programming language alleged to have syntax or semantics sufficiently dense and bizarre that any routine of significant size is too difficult to understand by other programmers and cannot be safely edited. Similarly, write-only code is source code so arcane, complex, or ill-structured that it cannot be reliably modified or even comprehended by anyone with the possible exception of the author. Write-only code is also referred to as line noise, suggesting that the code looks like spurious characters from signal noise in the communication line. In such a language it would be more difficult to read, understand, and modify existing source code than to start over and rewrite it from scratch.A more rarely used term is read-only language, which refers to systems with so many boundary conditions that the code can only be written through constant experimentation and not from first principles. The resulting code is perfectly readable by other programmers, but any attempt to duplicate it in another context will fail.},
	language = {en},
	urldate = {2020-07-07},
	journal = {Wikipedia},
	month = sep,
	year = {2019},
	note = {Page Version ID: 916551648},
}

@inproceedings{jemerov_implementing_2008,
	address = {Nashville, Tennessee},
	series = {{WRT} '08},
	title = {Implementing refactorings in {IntelliJ} {IDEA}},
	isbn = {978-1-60558-339-6},
	url = {https://doi.org/10.1145/1636642.1636655},
	doi = {10.1145/1636642.1636655},
	abstract = {IntelliJ IDEA was one of the first Java IDEs to cross the Refactoring Rubicon [1], by implementing the Extract Method refactoring for Java in early 2001. Since that time, IntelliJ IDEA has evolved greatly to support a wide array of refactorings for Java, cross-language refactoring and other advanced features. This paper gives an overview of the key architectural components of IntelliJ IDEA involved in implementing refactorings. It also describes some of the problems we're facing when implementing refactorings and possible directions for future development.},
	urldate = {2020-06-01},
	booktitle = {Proceedings of the 2nd {Workshop} on {Refactoring} {Tools}},
	publisher = {Association for Computing Machinery},
	author = {Jemerov, Dmitry},
	month = oct,
	year = {2008},
	pages = {1--2},
}

@misc{noauthor_interactive_nodate,
	title = {Interactive ambient visualizations for soft advice - {Emerson} {Murphy}-{Hill}, {Titus} {Barik}, {Andrew} {P}. {Black}, 2013},
	url = {https://journals.sagepub.com/doi/full/10.1177/1473871612469020?casa_token=UuyB6tzZ9a0AAAAA%3Akkq7oCHRyfZ5Dgylm5NqJHXklv7ZUNDa48A4XaXP3qsAHreFAE1zilv05jKCjAJtj6WM369W6S_C},
	urldate = {2020-06-01},
}

@inproceedings{maayan_how_2020,
	address = {Honolulu, HI, USA},
	series = {{CHI} '20},
	title = {How {Domain} {Experts} {Create} {Conceptual} {Diagrams} and {Implications} for {Tool} {Design}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376253},
	doi = {10.1145/3313831.3376253},
	abstract = {Conceptual diagrams are used extensively to understand abstract relationships, explain complex ideas, and solve difficult problems. To illustrate concepts effectively, experts find appropriate visual representations and translate concepts into concrete shapes. This translation step is not supported explicitly by current diagramming tools. This paper investigates how domain experts create conceptual diagrams via semi-structured interviews with 18 participants from diverse backgrounds. Our participants create, adapt, and reuse visual representations using both sketches and digital tools. However, they had trouble using current diagramming tools to transition from sketches and reuse components from earlier diagrams. Our participants also expressed frustration with the slow feedback cycles and barriers to automation of their tools. Based on these results, we suggest four opportunities of diagramming tools — exploration support, representation salience, live engagement, and vocabulary correspondence — that together enable a natural diagramming experience. Finally, we discuss possibilities to leverage recent research advances to develop natural diagramming tools.},
	urldate = {2020-05-26},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ma'ayan, Dor and Ni, Wode and Ye, Katherine and Kulkarni, Chinmay and Sunshine, Joshua},
	month = apr,
	year = {2020},
	keywords = {conceptual diagramming, diagram authoring, information visualization},
	pages = {1--14},
}

@article{chen_multi-modal_2020,
	title = {Multi-modal {Synthesis} of {Regular} {Expressions}},
	url = {http://arxiv.org/abs/1908.03316},
	abstract = {In this paper, we propose a multi-modal synthesis technique for automatically constructing regular expressions (regexes) from a combination of examples and natural language. Using multiple modalities is useful in this context because natural language alone is often highly ambiguous, whereas examples in isolation are often not sufficient for conveying user intent. Our proposed technique first parses the English description into a so-called hierarchical sketch that guides our programming-by-example (PBE) engine. Since the hierarchical sketch captures crucial hints, the PBE engine can leverage this information to both prioritize the search as well as make useful deductions for pruning the search space. We have implemented the proposed technique in a tool called Regel and evaluate it on over three hundred regexes. Our evaluation shows that Regel achieves 80\% accuracy whereas the NLP-only and PBE-only baselines achieve 43\% and 26\% respectively. We also compare our proposed PBE engine against an adaptation of AlphaRegex, a state-of-the-art regex synthesis tool, and show that our proposed PBE engine is an order of magnitude faster, even if we adapt the search algorithm of AlphaRegex to leverage the sketch. Finally, we conduct a user study involving 20 participants and show that users are twice as likely to successfully come up with the desired regex using Regel compared to without it.},
	urldate = {2020-05-26},
	journal = {arXiv:1908.03316 [cs]},
	author = {Chen, Qiaochu and Wang, Xinyu and Ye, Xi and Durrett, Greg and Dillig, Isil},
	month = mar,
	year = {2020},
	note = {arXiv: 1908.03316},
	keywords = {Computer Science - Programming Languages},
}

@article{ye_benchmarking_2020,
	title = {Benchmarking {Multimodal} {Regex} {Synthesis} with {Complex} {Structures}},
	url = {http://arxiv.org/abs/2005.00663},
	abstract = {Existing datasets for regular expression (regex) generation from natural language are limited in complexity; compared to regex tasks that users post on StackOverflow, the regexes in these datasets are simple, and the language used to describe them is not diverse. We introduce StructuredRegex, a new regex synthesis dataset differing from prior ones in three aspects. First, to obtain structurally complex and realistic regexes, we generate the regexes using a probabilistic grammar with pre-defined macros observed from real-world StackOverflow posts. Second, to obtain linguistically diverse natural language descriptions, we show crowdworkers abstract depictions of the underlying regex and ask them to describe the pattern they see, rather than having them paraphrase synthetic language. Third, we augment each regex example with a collection of strings that are and are not matched by the ground truth regex, similar to how real users give examples. Our quantitative and qualitative analysis demonstrates the advantages of StructuredRegex over prior datasets. Further experimental results using various multimodal synthesis techniques highlight the challenge presented by our dataset, including non-local constraints and multi-modal inputs.},
	urldate = {2020-05-26},
	journal = {arXiv:2005.00663 [cs]},
	author = {Ye, Xi and Chen, Qiaochu and Dillig, Isil and Durrett, Greg},
	month = may,
	year = {2020},
	note = {arXiv: 2005.00663},
	keywords = {Computer Science - Computation and Language},
}

@misc{noauthor_190803316_nodate,
	title = {[1908.03316] {Multi}-modal {Synthesis} of {Regular} {Expressions}},
	url = {https://arxiv.org/abs/1908.03316},
	urldate = {2020-05-26},
}

@article{lee_synthesizing_2016,
	title = {Synthesizing regular expressions from examples for introductory automata assignments},
	volume = {52},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/3093335.2993244},
	doi = {10.1145/3093335.2993244},
	abstract = {We present a method for synthesizing regular expressions for introductory automata assignments. Given a set of positive and negative examples, the method automatically synthesizes the simplest possible regular expression that accepts all the positive examples while rejecting all the negative examples. The key novelty is the search-based synthesis algorithm that leverages ideas from over- and under-approximations to effectively prune out a large search space. We have implemented our technique in a tool and evaluated it with non-trivial benchmark problems that students often struggle with. The results show that our system can synthesize desired regular expressions in 6.7 seconds on the average, so that it can be interactively used by students to enhance their understanding of regular expressions.},
	number = {3},
	urldate = {2020-05-20},
	journal = {ACM SIGPLAN Notices},
	author = {Lee, Mina and So, Sunbeom and Oh, Hakjoo},
	month = oct,
	year = {2016},
	keywords = {Regular expression, program synthesis, programming by example},
	pages = {70--80},
}

@misc{noauthor_metarepresentation_nodate,
	title = {Metarepresentation: {Native} {Competence} and {Targets} for {Instruction}: {Cognition} and {Instruction}: {Vol} 22, {No} 3},
	url = {https://www.tandfonline.com/doi/abs/10.1207/s1532690xci2203_2},
	urldate = {2020-02-18},
}

@article{rivers_data-driven_2017,
	title = {Data-{Driven} {Hint} {Generation} in {Vast} {Solution} {Spaces}: a {Self}-{Improving} {Python} {Programming} {Tutor}},
	volume = {27},
	issn = {1560-4306},
	shorttitle = {Data-{Driven} {Hint} {Generation} in {Vast} {Solution} {Spaces}},
	url = {https://doi.org/10.1007/s40593-015-0070-z},
	doi = {10.1007/s40593-015-0070-z},
	abstract = {To provide personalized help to students who are working on code-writing problems, we introduce a data-driven tutoring system, ITAP (Intelligent Teaching Assistant for Programming). ITAP uses state abstraction, path construction, and state reification to automatically generate personalized hints for students, even when given states that have not occurred in the data before. We provide a detailed description of the system’s implementation and perform a technical evaluation on a small set of data to determine the effectiveness of the component algorithms and ITAP’s potential for self-improvement. The results show that ITAP is capable of producing hints for almost any given state after being given only a single reference solution, and that it can improve its performance by collecting data over time.},
	language = {en},
	number = {1},
	urldate = {2019-10-07},
	journal = {International Journal of Artificial Intelligence in Education},
	author = {Rivers, Kelly and Koedinger, Kenneth R.},
	month = mar,
	year = {2017},
	keywords = {Automatic hint generation, Data-driven tutoring, Programming tutors, Solution space},
	pages = {37--64},
}

@article{li_integrating_2015,
	title = {Integrating representation learning and skill learning in a human-like intelligent agent},
	volume = {219},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370214001349},
	doi = {10.1016/j.artint.2014.11.002},
	abstract = {Building an intelligent agent that simulates human learning of math and science could potentially benefit both cognitive science, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledge-encoding is both time-consuming and error-prone. Previous research has shown that one of the key factors that differentiates experts and novices is their different representations of knowledge. Experts view the world in terms of deep functional features, while novices view it in terms of shallow perceptual features. Moreover, since the performance of learning algorithms is sensitive to representation, the deep features are also important in achieving effective machine learning. In this paper, we present an efficient algorithm that acquires representation knowledge in the form of “deep features”, and demonstrate its effectiveness in the domain of algebra as well as synthetic domains. We integrate this algorithm into a machine-learning agent, SimStudent, which learns procedural knowledge by observing a tutor solve sample problems, and by getting feedback while actively solving problems on its own. We show that learning “deep features” reduces the requirements for knowledge engineering. Moreover, we propose an approach that automatically discovers student models using the extended SimStudent. By fitting the discovered model to real student learning curve data, we show that it is a better student model than human-generated models, and demonstrate how the discovered model may be used to improve a tutoring system's instructional strategy.},
	urldate = {2019-10-07},
	journal = {Artificial Intelligence},
	author = {Li, Nan and Matsuda, Noboru and Cohen, William W. and Koedinger, Kenneth R.},
	month = feb,
	year = {2015},
	keywords = {Agent learning, Representation learning, Student modeling},
	pages = {67--91},
}

@article{heer_agency+automation_nodate,
	title = {Agency+{Automation}},
	abstract = {Much contemporary rhetoric regards the prospects and pitfalls of using artificial intelligence techniques to automate an ever-increasing range of tasks, especially those once considered the purview of people alone. These accounts are often wildly optimistic, understating outstanding challenges while turning a blind eye to the human labor that undergirds and sustains ostensibly “automated” services. This long-standing focus on purely automated methods unnecessarily cedes a promising design space: one in which computational assistance augments and enriches, rather than replaces, people’s intellectual work. This tension between agency and automation poses vital challenges for design and engineering. In this article we consider the design of interactive systems that enable rich, adaptive collaboration among people and computational agents. We seek to balance the often complementary strengths and weaknesses of each, while promoting human control and skillful action. We review case studies in three arenas—data wrangling, exploratory analysis, and natural language translation—that integrate proactive computational support into interactive systems. To improve outcomes and support continuous learning by both people and machines, we describe the use of shared task representations and corresponding predictive models of human capabilities and actions. We conclude with a discussion of future prospects and promising scientific frontiers for intelligence augmentation research.},
	language = {en},
	author = {Heer, Jeffrey},
	pages = {12},
}

@article{heer_agency_2019,
	title = {Agency plus automation: {Designing} artificial intelligence into interactive systems},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Agency plus automation},
	url = {https://www.pnas.org/content/116/6/1844},
	doi = {10.1073/pnas.1807184115},
	abstract = {Much contemporary rhetoric regards the prospects and pitfalls of using artificial intelligence techniques to automate an increasing range of tasks, especially those once considered the purview of people alone. These accounts are often wildly optimistic, understating outstanding challenges while turning a blind eye to the human labor that undergirds and sustains ostensibly “automated” services. This long-standing focus on purely automated methods unnecessarily cedes a promising design space: one in which computational assistance augments and enriches, rather than replaces, people’s intellectual work. This tension between human agency and machine automation poses vital challenges for design and engineering. In this work, we consider the design of systems that enable rich, adaptive interaction between people and algorithms. We seek to balance the often-complementary strengths and weaknesses of each, while promoting human control and skillful action. We share case studies of interactive systems we have developed in three arenas—data wrangling, exploratory analysis, and natural language translation—that integrate proactive computational support into interactive systems. To improve outcomes and support learning by both people and machines, we describe the use of shared representations of tasks augmented with predictive models of human capabilities and actions. We conclude with a discussion of future prospects and scientific frontiers for intelligence augmentation research.},
	language = {en},
	number = {6},
	urldate = {2019-10-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Heer, Jeffrey},
	month = feb,
	year = {2019},
	pmid = {30718389},
	keywords = {artificial intelligence, automation, data science, human–computer interaction, visualization},
	pages = {1844--1850},
}

@article{cai_human-centered_2019,
	title = {Human-{Centered} {Tools} for {Coping} with {Imperfect} {Algorithms} {During} {Medical} {Decision}-{Making}},
	doi = {10.1145/3290605.3300234},
	author = {Cai, Carrie J. and Stumpe, Martin C. and Terry, Michael and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S.},
	year = {2019},
	pages = {1--14},
}

@article{hegarty_types_1999,
	title = {Types of visual–spatial representations and mathematical problem solving},
	volume = {91},
	issn = {1939-2176(Electronic),0022-0663(Print)},
	doi = {10.1037/0022-0663.91.4.684},
	abstract = {Although visual-spatial representations are used extensively in mathematics and spatial ability is highly correlated with success in mathematics education, research to date has not demonstrated a clear relationship between use of visual-spatial representations and success in mathematical problem solving. The authors distinguished 2 types of visual-spatial representations: schematic representations that encode the spatial relations described in a problem and pictorial representations that encode the visual appearance of the objects described in the problem. Participants solved mathematical problems and reported on their solution strategies. The authors were able to reliably classify their visual-spatial representations as primarily schematic or primarily pictorial. Use of schematic spatial representations was associated with success in mathematical problem solving, whereas use of pictorial representations was negatively correlated with success. Use of schematic representations was also significantly correlated with one measure of spatial ability. The research therefore helps clarify the relationship between visual imagery, spatial ability, and mathematical problem solving. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Educational Psychology},
	author = {Hegarty, Mary and Kozhevnikov, Maria},
	year = {1999},
	keywords = {Conceptual Imagery, Mathematical Ability, Mathematics Achievement, Mathematics Education, Pictorial Stimuli, Problem Solving, Schema, Spatial Ability},
	pages = {684--689},
}

@article{disessa_meta-representation:_2000,
	title = {Meta-representation: an introduction},
	volume = {19},
	issn = {0732-3123},
	shorttitle = {Meta-representation},
	url = {http://www.sciencedirect.com/science/article/pii/S0732312301000517},
	doi = {10.1016/S0732-3123(01)00051-7},
	abstract = {This paper presents an introduction to Project MaRC. The goal of Project MaRC is to study, in very broad terms, what students know about scientific representations and what is possible for them to learn. We use the term meta-representational competence (MRC) to describe the full range of capabilities that students (and others) have concerning the construction and use of external representations. As part of our project, we are engaging in an analysis of the nature of MRC, and we have begun to explore instructional implications. This introductory paper provides an overview of that work, including its goals and results, and it also provides an introduction to the four following papers in the issue.},
	number = {4},
	urldate = {2019-04-08},
	journal = {The Journal of Mathematical Behavior},
	author = {diSessa, Andrea A and Sherin, Bruce L},
	month = oct,
	year = {2000},
	keywords = {Collaborative design, Constructivism, Representations},
	pages = {385--398},
}

@article{kaminski_advantage_2008,
	title = {The {Advantage} of {Abstract} {Examples} in {Learning} {Math}},
	volume = {320},
	copyright = {© 2008 American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/320/5875/454},
	doi = {10.1126/science.1154659},
	abstract = {Undergraduate students may benefit more from learning mathematics through a single abstract, symbolic representation than from learning multiple concrete examples.
Undergraduate students may benefit more from learning mathematics through a single abstract, symbolic representation than from learning multiple concrete examples.},
	language = {en},
	number = {5875},
	urldate = {2019-02-25},
	journal = {Science},
	author = {Kaminski, Jennifer A. and Sloutsky, Vladimir M. and Heckler, Andrew F.},
	month = apr,
	year = {2008},
	pmid = {18436760},
	pages = {454--455},
}

@inproceedings{wiese_toward_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Toward {Sense} {Making} with {Grounded} {Feedback}},
	isbn = {9783319072210},
	abstract = {Grounded feedback aims to facilitate sense making by reflecting students’ symbolic input in a linked concrete representation that is easier to reason with. Initial studies led to explorations of what prior knowledge is necessary to support that reasoning. Specifically, we tested if it is obvious to students that a sum is larger than its two positive addends. It is not! Thus, concrete representations for sense making may fail because students lack prerequisite knowledge we may assume they have. More generally, these results suggest that skilled qualitative reasoning may often come after, not before, quantitative reasoning.},
	language = {en},
	booktitle = {Intelligent {Tutoring} {Systems}},
	publisher = {Springer International Publishing},
	author = {Wiese, Eliane Stampfer and Koedinger, Kenneth R.},
	editor = {Trausan-Matu, Stefan and Boyer, Kristy Elizabeth and Crosby, Martha and Panourgia, Kitty},
	year = {2014},
	keywords = {fraction addition , graphical representations , grounded feedback },
	pages = {695--697},
}

@article{ni_substance_nodate,
	title = {{SUBSTANCE} and {STYLE}: domain-specific languages for mathematical diagrams},
	copyright = {All rights reserved},
	shorttitle = {{SUBSTANCE} and {STYLE}},
	author = {Ni, Wode and Ye, Katherine and Sunshine, Joshua and Aldrich, Jonathan and Crane, Keenan},
}

@article{ni_whiteboard_2016,
	title = {Whiteboard {Scanning} {Using} {Super}-{Resolution}},
	copyright = {All rights reserved},
	url = {https://scholar.dickinson.edu/student_honors/221},
	journal = {Student Honors Theses By Year},
	author = {Ni, Wode},
	month = may,
	year = {2016},
}

@inproceedings{koedinger_emergent_1992,
	title = {Emergent properties and structural constraints: {Advantages} of diagrammatic representations for reasoning and learning},
	shorttitle = {Emergent properties and structural constraints},
	booktitle = {Proc. {AAAI} {Spring} {Symposium} on {Reasoning} with {Diagrammatic} {Representations}},
	author = {Koedinger, Kenneth R.},
	year = {1992},
	pages = {154--169},
}
